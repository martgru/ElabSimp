{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91e1cd32-a2a1-4261-92a3-ab7406792dc3",
   "metadata": {},
   "source": [
    "# Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b049368-bc1e-485c-b2f2-1512e8715585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "GPU Name: NVIDIA H100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "gpu_available = torch.cuda.is_available()\n",
    "print(f\"GPU Available: {gpu_available}\")\n",
    "\n",
    "if gpu_available:\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"GPU Name: {gpu_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a256a43-5e01-41c0-b5ad-cbae7c569965",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5f6960-17d5-406b-a641-300603ac8c0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## SWiPE - full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bfb8a8d-d9fb-41e1-baef-44aa5932c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_json('../data/swipe/swipe_train.json')\n",
    "val_df = pd.read_json('../data/swipe/swipe_val.json')\n",
    "test_id_df = pd.read_json('../data/swipe/swipe_test_id.json')\n",
    "test_ood_df = pd.read_json('../data/swipe/swipe_test_ood.json')\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df[['r_content', 's_content','annotations','edits']])\n",
    "val_dataset = Dataset.from_pandas(val_df[['r_content', 's_content','annotations','edits']])\n",
    "test_id_dataset = Dataset.from_pandas(test_id_df[['r_content', 's_content','annotations','edits']])\n",
    "test_ood_dataset = Dataset.from_pandas(test_ood_df[['r_content', 's_content','annotations','edits']])\n",
    "\n",
    "swipe_full_dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test_id': test_id_dataset,\n",
    "    'test_ood': test_ood_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d3f4c1-0ad8-4dfa-99d4-b9856f5f883f",
   "metadata": {},
   "source": [
    "## SWiPE - cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ca6cee-c8eb-46cc-b270-7b6de04d8c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "swipe_clean_dataset = load_from_disk(\"../data/swipe_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c38e4e4b-6814-48a2-9a70-3a428055401f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['r_content', 's_content'],\n",
       "        num_rows: 3847\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['r_content', 's_content'],\n",
       "        num_rows: 479\n",
       "    })\n",
       "    test_id: Dataset({\n",
       "        features: ['r_content', 's_content'],\n",
       "        num_rows: 483\n",
       "    })\n",
       "    test_ood: Dataset({\n",
       "        features: ['r_content', 's_content'],\n",
       "        num_rows: 368\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swipe_clean_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a07818e-6234-4201-b0eb-5f91a585b06f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Shuffle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c42ee91-9799-44c2-88fa-ee52f6c3c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "def shuffle_dataset_splits(dataset_dict):\n",
    "    shuffled_datasets = DatasetDict()\n",
    "    \n",
    "    for split, dataset in dataset_dict.items():\n",
    "        shuffled_datasets[split] = dataset.shuffle(seed=42)  \n",
    "\n",
    "    return shuffled_datasets\n",
    "\n",
    "shuffled_swipe_clean_dataset = shuffle_dataset_splits(swipe_clean_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "313856d2-e722-4526-9c47-67c6fd3c72cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['r_content', 's_content'],\n",
       "        num_rows: 3847\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['r_content', 's_content'],\n",
       "        num_rows: 479\n",
       "    })\n",
       "    test_id: Dataset({\n",
       "        features: ['r_content', 's_content'],\n",
       "        num_rows: 483\n",
       "    })\n",
       "    test_ood: Dataset({\n",
       "        features: ['r_content', 's_content'],\n",
       "        num_rows: 368\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_swipe_clean_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18b315d-38ac-400c-90ee-164ba42f39cd",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "affa730c-ad55-4a0f-8d88-e3e20bef26a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizerFast, BartForConditionalGeneration # BartTokenizer AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "tokenizer = BartTokenizerFast.from_pretrained('facebook/bart-large') #use_fast=True) # BartTokenizerFast.from_pretrained('facebook/bart-large')\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large', device_map ={'':torch.cuda.current_device()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cef8096-36a3-4235-91d5-676f91b5bb6c",
   "metadata": {},
   "source": [
    "## Adjust model's config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99dd3880-ebee-41c7-9958-34af0d5234bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "print(model.config.dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "555a5ea3-9f44-4796-b379-ab84436e5430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "model.config.dropout = 0.2\n",
    "print(model.config.dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b010416-9929-4a18-b2a6-c62d378bae77",
   "metadata": {},
   "source": [
    "## Adjust the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bff10cbf-db05-4093-aab0-19f239916264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AddedToken\n",
    "\n",
    "special_tokens_dict = {\n",
    "    'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True)\n",
    "}\n",
    "\n",
    "# add the special tokens to the tokenizer\n",
    "tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c5c3388-5fbf-4d5d-bf62-34503c84afb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.special_tokens_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79023be6-1513-4a64-86b6-33f4dd909f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean up tokenization spaces: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Clean up tokenization spaces:\", tokenizer.clean_up_tokenization_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d72db9cf-855d-4446-b5ee-d1a397ec2118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BartTokenizerFast(name_or_path='facebook/bart-large', vocab_size=50265, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4291fabf-f746-4c33-b411-fe9fb88027f8",
   "metadata": {},
   "source": [
    "# Tokenize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "575e9eb8-e8df-487d-b179-18e1dd155521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(examples):\n",
    "    # inputs\n",
    "    inputs = tokenizer(examples['r_content'], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    # labels\n",
    "    labels = tokenizer(examples['s_content'],truncation=True, padding=\"max_length\", max_length=512)\n",
    "    # set the labels in the input dictionary\n",
    "    inputs['labels'] = labels['input_ids']\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd4cd3-e6fb-43cc-a6b6-51d398623279",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Swipe-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "762f06f9-fc8f-413a-be88-67a0da806b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d5c8d2557c40a298f0c4e2e63c5993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3861 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21fb2b8999444ddea7a78c2e2bf2c097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/482 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34fbec115536489e8b8d82ac31176d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/484 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8307f1fd8deb48e197b077e7d933ab19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_swipe_full_dataset = swipe_full_dataset.map(tokenize_func, batched=True)\n",
    "tokenized_swipe_full_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262b4b8f-7182-4a0c-bf8c-4a9236117d23",
   "metadata": {},
   "source": [
    "## Swipe-clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cfee667-3b1c-4b51-8c6c-a6750b20a218",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_swipe_clean_dataset = swipe_clean_dataset.map(tokenize_func, batched=True)\n",
    "tokenized_swipe_clean_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb82db7e-ce43-4cbe-bb00-8e3936b8a1dc",
   "metadata": {},
   "source": [
    "# Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb6f5d17-c027-40e4-830a-2be9717a2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = swipe_clean_dataset \n",
    "tokenized_dataset = tokenized_swipe_clean_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "695712c8-94fe-43e2-9ccc-43694b4ff80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max input length: 512\n",
      "Max label length: 512\n"
     ]
    }
   ],
   "source": [
    "max_input_length = max([len(i) for i in tokenized_dataset['train']['input_ids']])\n",
    "max_label_length = max([len(l) for l in tokenized_dataset['train']['labels']])\n",
    "\n",
    "print(f\"Max input length: {max_input_length}\")\n",
    "print(f\"Max label length: {max_label_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53d32466-c48a-4973-b2ea-e420e9861e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adc42df3-e6b4-4aa5-aac3-19061efaefba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# disable parallelism warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe35916e-925c-493e-a0f5-91bfe2c24e47",
   "metadata": {},
   "source": [
    "## Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5f3ee86-9742-4dec-9180-82893b91df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    bos_token_id = 0, \n",
    "    decoder_start_token_id = 2,\n",
    "    early_stopping = True,\n",
    "    eos_token_id = 2, \n",
    "    forced_bos_token_id = 0,\n",
    "    forced_eos_token_id = 2,\n",
    "    no_repeat_ngram_size = 3,\n",
    "    num_beams = 4,\n",
    "    pad_token_id = 1,\n",
    "    max_length = 200,\n",
    "    temperature = 1.5,\n",
    "    num_return_sequences=1, \n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "model.generation_config = generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c13604fb-4e63-4e40-aa9a-f4d7f4050684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, EarlyStoppingCallback\n",
    "import numpy as np\n",
    "from easse.sari import corpus_sari\n",
    "\n",
    "def compute_sari(pred):\n",
    "    \n",
    "    predictions = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "    \n",
    "    # decode the predictions and labels into text\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # source texts \n",
    "    sources = tokenized_dataset['validation']['r_content']\n",
    "\n",
    "    # SARI scores\n",
    "    sari_scores = []\n",
    "    for pred, label, source in zip(decoded_preds, decoded_labels, sources):\n",
    "        sari_score = corpus_sari(\n",
    "            orig_sents=[source],  # original source sentence\n",
    "            sys_sents=[pred],     # system's generated sentence\n",
    "            refs_sents=[[label]]  # reference simplified sentence\n",
    "        )\n",
    "        sari_scores.append(sari_score)\n",
    "    \n",
    "    # average SARI score across all examples\n",
    "    avg_sari = np.mean(sari_scores)\n",
    "    return {\"sari\": avg_sari}\n",
    "\n",
    "model.train()\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"../models/bart-swipe-ft/results/results-swipe-clean-bart-tokenizer-fast-512-seq2seqtrainer-pred-with-gen-best-loss_dropout0.2\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=150,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=6,\n",
    "    per_device_eval_batch_size=6, \n",
    "    num_train_epochs=3,\n",
    "    save_total_limit=3,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps = 2,\n",
    "    #gradient_accumulation_steps=2,\n",
    "    optim = \"paged_adamw_8bit\",\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    logging_dir=\"../models/bart-swipe-ft/logs/logs-swipe-clean-bart-tokenizer-fast-512-seq2seqtrainer-pred-with-gen-best-loss_dropout0.2\",\n",
    "    predict_with_generate=True,\n",
    "    metric_for_best_model='loss'\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_sari,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0be0940-c626-4f9c-b556-8b352896565b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1926' max='1926' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1926/1926 11:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Sari</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.211200</td>\n",
       "      <td>0.181588</td>\n",
       "      <td>40.261900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.156200</td>\n",
       "      <td>0.175187</td>\n",
       "      <td>42.490640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.175931</td>\n",
       "      <td>42.015964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1926, training_loss=0.6303604498335382, metrics={'train_runtime': 668.5668, 'train_samples_per_second': 17.262, 'train_steps_per_second': 2.881, 'total_flos': 1.2505277106487296e+16, 'train_loss': 0.6303604498335382, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f850b3d1-75c0-4d7e-a5bf-d400608a8197",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ac9687-3e10-4b3d-adb0-5dfc1d60da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "\n",
    "model.train()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../models/bart-swipe-ft/results/results-swipe-clean-bart-tokenizer-fast-512-best-metric-loss-6epochs\",\n",
    "    eval_strategy=\"epoch\", \n",
    "    save_strategy = \"epoch\", \n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5, \n",
    "    per_device_train_batch_size=6, \n",
    "    per_device_eval_batch_size=6, \n",
    "    num_train_epochs=6, \n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3, \n",
    "    #gradient_accumulation_steps=6, # reduce memory\n",
    "    load_best_model_at_end=True, # based on valid loss\n",
    "    metric_for_best_model='loss',\n",
    "    warmup_steps = 2,\n",
    "    optim = \"paged_adamw_8bit\", # optimizer for quantization\n",
    "    fp16=True, # enable half-precision\n",
    "    logging_dir='../models/bart-swipe-ft/logs/logs-swipe-clean-bart-tokenizer-fast-512-best-metric-loss-6epochs'\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    #data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1ad1efd-de82-495f-ae4b-fb30eed738a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3210' max='3852' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3210/3852 06:00 < 01:12, 8.89 it/s, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>0.183244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>0.178688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.128100</td>\n",
       "      <td>0.179753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.182407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.093200</td>\n",
       "      <td>0.186235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
      "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
      "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
      "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
      "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n",
      "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n",
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3210, training_loss=0.41969726685422976, metrics={'train_runtime': 361.1736, 'train_samples_per_second': 63.908, 'train_steps_per_second': 10.665, 'total_flos': 2.084212851081216e+16, 'train_loss': 0.41969726685422976, 'epoch': 5.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd8d07-9cfa-4be1-a04e-0cde9b3efc61",
   "metadata": {},
   "source": [
    "# Visualize training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a95bad79-a2c8-4f36-8500-adc250ee7110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch:  641\n",
      "Logging steps:  4\n"
     ]
    }
   ],
   "source": [
    "num_samples = len(swipe_clean_dataset['train'])\n",
    "batch_size= 6\n",
    "logging_steps = 150\n",
    "print(\"Steps per epoch: \", num_samples//batch_size )\n",
    "print(\"Logging steps: \" ,num_samples//batch_size//logging_steps )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd255cca-8e9a-4656-84d7-eacc986b67ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 0.17518660426139832\n",
      "Epoch of the best model: 2.0\n",
      "Sari score:  42.490639715645266\n"
     ]
    }
   ],
   "source": [
    "log_history = trainer.state.log_history\n",
    "eval_logs = [log for log in log_history if \"eval_loss\" in log]\n",
    "\n",
    "# the best (lowest) validation loss\n",
    "best_eval_log = min(eval_logs, key=lambda x: x[\"eval_loss\"])\n",
    "\n",
    "print(f\"Best validation loss: {best_eval_log['eval_loss']}\")\n",
    "print(f\"Epoch of the best model: {best_eval_log['epoch']}\")\n",
    "print(\"Sari score: \", best_eval_log['eval_sari'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ae5e53a-c44f-421b-b529-3145ab06cc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loss values from the log history\n",
    "train_loss = [log['loss'] for log in trainer.state.log_history if 'loss' in log]\n",
    "eval_loss = [log['eval_loss'] for log in trainer.state.log_history if 'eval_loss' in log]\n",
    "steps = range(len(train_loss))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(steps, train_loss, label='Training Loss')\n",
    "plt.plot(steps[:len(eval_loss)], eval_loss, label='Validation Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd20648-c8a2-4bd0-90a9-27e90c8ca8fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Load model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a5e7d2a-c0c1-4324-99e9-170d6fcffea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = \"../models/bart-swipe-ft/results-swipe-clean-bart-tokenizer-fast-512-use-fast/checkpoint-1284\"\n",
    "\n",
    "loaded_model = BartForConditionalGeneration.from_pretrained(checkpoint_dir, device_map={'': torch.cuda.current_device()})\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92be1362-b20d-43c2-abf7-131eff626df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "loaded_model.config.use_cache = True\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    bos_token_id = 0, \n",
    "    decoder_start_token_id = 2,\n",
    "    early_stopping = True,\n",
    "    eos_token_id = 2, \n",
    "    forced_bos_token_id = 0,\n",
    "    forced_eos_token_id = 2,\n",
    "    no_repeat_ngram_size = 3,\n",
    "    num_beams = 4,\n",
    "    pad_token_id = 1\n",
    ")\n",
    "\n",
    "loaded_model.generation_config = generation_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3defc408-8b76-4263-a032-0a9930994b40",
   "metadata": {},
   "source": [
    "# Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7131d9c-a9f3-436d-9a43-02132c090bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def highlight_diff(sentence1, sentence2):\n",
    "    diff = difflib.ndiff(sentence1, sentence2)\n",
    "    highlighted = []\n",
    "    \n",
    "    for char in diff:\n",
    "        if char.startswith('-'):\n",
    "            highlighted.append(f\"<span style='color:red'>{char[2:]}</span>\")\n",
    "        elif char.startswith('+'):\n",
    "            highlighted.append(f\"<span style='color:green'>{char[2:]}</span>\")\n",
    "        else:\n",
    "            highlighted.append(char[2:])\n",
    "    \n",
    "    return ''.join(highlighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168498be-3fba-48ce-a26b-67bb818dfb26",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3de594cb-fa35-4c14-8d66-a85b4a2462fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "\n",
    "model.config.use_cache = True\n",
    "\n",
    "generation_config = GenerationConfig(\n",
    "    bos_token_id = 0, \n",
    "    decoder_start_token_id = 2,\n",
    "    early_stopping = True,\n",
    "    eos_token_id = 2, \n",
    "    forced_bos_token_id = 0,\n",
    "    forced_eos_token_id = 2,\n",
    "    no_repeat_ngram_size = 3,\n",
    "    num_beams = 4,\n",
    "    pad_token_id = 1\n",
    ")\n",
    "\n",
    "model.generation_config = generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1f2f824-d15d-4248-886f-84f62902e443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Russian (Russkij yazyk, Русский язык) is the most widely spoken of the Slavic languages. It is primarily spoken in Russia and other nations of the former Soviet Union, and was also widely taught in schools in member countries of the Warsaw Pact. In Soviet times, Russian was often strongly promoted to the detriment of other local languages. While many of the countries of the former Soviet Union are now promoting their local languages rather than Russian, Russian remains widely spoken in these areas and is often used for intercommunication between these countries. Russian is one of the official languages of the United Nations. Russian is written using the Cyrillic alphabet. Russenorsk is a pidgin language combining Russian and Norwegian. See also: Common phrases in different languages See also: Languages of China --\n",
      "\n",
      "Simplified: \n",
      "Russian (Russkij yazyk, Русский язык) is the most widely spoken of the Slavic languages. It is primarily spoken in Russia and other nations of the former Soviet Union, and was also widely taught in schools in member countries of the Warsaw Pact. In Soviet times, Russian was often strongly promoted to the detriment of other local languages. While many of the countries of Russia and Ukraine are now promoting their local languages rather than Russian, Russian remains widely spoken in these areas and is often used for intercommunication between these countries. Russian is one of the official languages of the United Nations.\n",
      "\n",
      "Simplified (highlighted): \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Russian (Russkij yazyk, Русский язык) is the most widely spoken of the Slavic languages. It is primarily spoken in Russia and other nations of the former Soviet Union, and was also widely taught in schools in member countries of the Warsaw Pact. In Soviet times, Russian was often strongly promoted to the detriment of other local languages. While many of the countries of <span style='color:green'>R</span><span style='color:green'>u</span><span style='color:green'>s</span><span style='color:green'>s</span><span style='color:red'>t</span><span style='color:red'>h</span><span style='color:red'>e</span><span style='color:red'> </span><span style='color:red'>f</span><span style='color:red'>o</span><span style='color:red'>r</span><span style='color:red'>m</span><span style='color:red'>e</span><span style='color:red'>r</span><span style='color:red'> </span><span style='color:red'>S</span><span style='color:red'>o</span><span style='color:red'>v</span>i<span style='color:red'>e</span><span style='color:red'>t</span><span style='color:green'>a</span><span style='color:green'> </span><span style='color:green'>a</span><span style='color:green'>n</span><span style='color:green'>d</span> U<span style='color:red'>n</span><span style='color:green'>k</span><span style='color:green'>r</span><span style='color:green'>a</span>i<span style='color:red'>o</span>n<span style='color:green'>e</span> are now promoting their local languages rather than Russian, Russian remains widely spoken in these areas and is often used for intercommunication between these countries. Russian is one of the official languages of the United Nations.<span style='color:red'> </span><span style='color:red'>R</span><span style='color:red'>u</span><span style='color:red'>s</span><span style='color:red'>s</span><span style='color:red'>i</span><span style='color:red'>a</span><span style='color:red'>n</span><span style='color:red'> </span><span style='color:red'>i</span><span style='color:red'>s</span><span style='color:red'> </span><span style='color:red'>w</span><span style='color:red'>r</span><span style='color:red'>i</span><span style='color:red'>t</span><span style='color:red'>t</span><span style='color:red'>e</span><span style='color:red'>n</span><span style='color:red'> </span><span style='color:red'>u</span><span style='color:red'>s</span><span style='color:red'>i</span><span style='color:red'>n</span><span style='color:red'>g</span><span style='color:red'> </span><span style='color:red'>t</span><span style='color:red'>h</span><span style='color:red'>e</span><span style='color:red'> </span><span style='color:red'>C</span><span style='color:red'>y</span><span style='color:red'>r</span><span style='color:red'>i</span><span style='color:red'>l</span><span style='color:red'>l</span><span style='color:red'>i</span><span style='color:red'>c</span><span style='color:red'> </span><span style='color:red'>a</span><span style='color:red'>l</span><span style='color:red'>p</span><span style='color:red'>h</span><span style='color:red'>a</span><span style='color:red'>b</span><span style='color:red'>e</span><span style='color:red'>t</span><span style='color:red'>.</span><span style='color:red'> </span><span style='color:red'>R</span><span style='color:red'>u</span><span style='color:red'>s</span><span style='color:red'>s</span><span style='color:red'>e</span><span style='color:red'>n</span><span style='color:red'>o</span><span style='color:red'>r</span><span style='color:red'>s</span><span style='color:red'>k</span><span style='color:red'> </span><span style='color:red'>i</span><span style='color:red'>s</span><span style='color:red'> </span><span style='color:red'>a</span><span style='color:red'> </span><span style='color:red'>p</span><span style='color:red'>i</span><span style='color:red'>d</span><span style='color:red'>g</span><span style='color:red'>i</span><span style='color:red'>n</span><span style='color:red'> </span><span style='color:red'>l</span><span style='color:red'>a</span><span style='color:red'>n</span><span style='color:red'>g</span><span style='color:red'>u</span><span style='color:red'>a</span><span style='color:red'>g</span><span style='color:red'>e</span><span style='color:red'> </span><span style='color:red'>c</span><span style='color:red'>o</span><span style='color:red'>m</span><span style='color:red'>b</span><span style='color:red'>i</span><span style='color:red'>n</span><span style='color:red'>i</span><span style='color:red'>n</span><span style='color:red'>g</span><span style='color:red'> </span><span style='color:red'>R</span><span style='color:red'>u</span><span style='color:red'>s</span><span style='color:red'>s</span><span style='color:red'>i</span><span style='color:red'>a</span><span style='color:red'>n</span><span style='color:red'> </span><span style='color:red'>a</span><span style='color:red'>n</span><span style='color:red'>d</span><span style='color:red'> </span><span style='color:red'>N</span><span style='color:red'>o</span><span style='color:red'>r</span><span style='color:red'>w</span><span style='color:red'>e</span><span style='color:red'>g</span><span style='color:red'>i</span><span style='color:red'>a</span><span style='color:red'>n</span><span style='color:red'>.</span><span style='color:red'> </span><span style='color:red'>S</span><span style='color:red'>e</span><span style='color:red'>e</span><span style='color:red'> </span><span style='color:red'>a</span><span style='color:red'>l</span><span style='color:red'>s</span><span style='color:red'>o</span><span style='color:red'>:</span><span style='color:red'> </span><span style='color:red'>C</span><span style='color:red'>o</span><span style='color:red'>m</span><span style='color:red'>m</span><span style='color:red'>o</span><span style='color:red'>n</span><span style='color:red'> </span><span style='color:red'>p</span><span style='color:red'>h</span><span style='color:red'>r</span><span style='color:red'>a</span><span style='color:red'>s</span><span style='color:red'>e</span><span style='color:red'>s</span><span style='color:red'> </span><span style='color:red'>i</span><span style='color:red'>n</span><span style='color:red'> </span><span style='color:red'>d</span><span style='color:red'>i</span><span style='color:red'>f</span><span style='color:red'>f</span><span style='color:red'>e</span><span style='color:red'>r</span><span style='color:red'>e</span><span style='color:red'>n</span><span style='color:red'>t</span><span style='color:red'> </span><span style='color:red'>l</span><span style='color:red'>a</span><span style='color:red'>n</span><span style='color:red'>g</span><span style='color:red'>u</span><span style='color:red'>a</span><span style='color:red'>g</span><span style='color:red'>e</span><span style='color:red'>s</span><span style='color:red'> </span><span style='color:red'>S</span><span style='color:red'>e</span><span style='color:red'>e</span><span style='color:red'> </span><span style='color:red'>a</span><span style='color:red'>l</span><span style='color:red'>s</span><span style='color:red'>o</span><span style='color:red'>:</span><span style='color:red'> </span><span style='color:red'>L</span><span style='color:red'>a</span><span style='color:red'>n</span><span style='color:red'>g</span><span style='color:red'>u</span><span style='color:red'>a</span><span style='color:red'>g</span><span style='color:red'>e</span><span style='color:red'>s</span><span style='color:red'> </span><span style='color:red'>o</span><span style='color:red'>f</span><span style='color:red'> </span><span style='color:red'>C</span><span style='color:red'>h</span><span style='color:red'>i</span><span style='color:red'>n</span><span style='color:red'>a</span><span style='color:red'> </span><span style='color:red'>-</span><span style='color:red'>-</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = dataset['test_id'][1]  \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "inputs = tokenizer(example['r_content'], return_tensors=\"pt\")\n",
    "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "\n",
    "output_ids = model.generate(\n",
    "    **inputs, \n",
    "    max_length=200, \n",
    "    num_beams=5,\n",
    "    temperature=1.5,\n",
    "    num_return_sequences=1, \n",
    "    do_sample=True\n",
    ")\n",
    "simplified_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Original: {example['r_content']}\", end='\\n\\n')\n",
    "print(f\"Simplified: \")\n",
    "print(simplified_text, end='\\n\\n')\n",
    "print(f\"Simplified (highlighted): \")\n",
    "display(HTML(highlight_diff(example['r_content'],simplified_text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f42e12c-7b80-4d45-bee1-051cf5d4b9eb",
   "metadata": {},
   "source": [
    "# SARI score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "405719db-9a95-488f-a267-dc5a9545636b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 483/483 [06:46<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "predictions = []\n",
    "\n",
    "model.eval()\n",
    "model.config.use_cache = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for example in tqdm(dataset['test_id']):\n",
    "        # tokenize the text\n",
    "        input_ids = tokenizer(example['r_content'], return_tensors=\"pt\") # , truncation=True, padding=\"max_length\", max_length=512)\n",
    "        # move input_ids to the same device as the model\n",
    "        input_ids = {key: value.to(device) for key, value in input_ids.items()}\n",
    "        \n",
    "        # generate prediction\n",
    "        output_ids = model.generate(**input_ids, max_length=200, temperature=1.5, num_beams=4, num_return_sequences=1, do_sample=True) # ,max_length = 512, min_length=50, length_penalty=1.0) \n",
    "        simplified_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        predictions.append(simplified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48bbff1e-05e5-4291-8e61-9f633a0d0ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82315cab4f14ab1a35bc137ecde00b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from easse.sari import corpus_sari\n",
    "\n",
    "\n",
    "sari_scores_easse = []\n",
    "\n",
    "for index, row in tqdm(enumerate(dataset[\"test_id\"]), total=len(dataset[\"test_id\"])):\n",
    "    r_content = row['r_content'] \n",
    "    s_content = row['s_content']\n",
    "    prediction = predictions[index] \n",
    "    \n",
    "    sari_score_easse = corpus_sari(\n",
    "        orig_sents=[r_content],\n",
    "        sys_sents=[prediction],\n",
    "        refs_sents=[[s_content]]\n",
    "    )\n",
    "    \n",
    "    sari_scores_easse.append(sari_score_easse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4a4dfad-9c9d-47a4-a10f-948187c01f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean SARI score:\n",
      "BART-large-swipe: 42.98783900997205\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Mean SARI score:\")\n",
    "print(f\"BART-large-swipe: {np.mean(sari_scores_easse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5466892-1b66-45ec-bc1b-e8bd6cbe62eb",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ca35569-6604-4b24-bb3e-9054759c98b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
     ]
    }
   ],
   "source": [
    "generation_config.save_pretrained(\"../models/bart-swipe-ft/model-swipe-clean-bart-tokenizer-512\")\n",
    "#tokenizer.save_pretrained(\"../models/bart-swipe-ft/model-swipe-clean\")\n",
    "model.save_pretrained(\"../models/bart-swipe-ft/model-swipe-clean-bart-tokenizer-512\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
