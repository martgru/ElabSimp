{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d64ebf-f0ca-4096-ad2b-4347ae5065f1",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d83499ca-d22e-4bd0-83e0-1ca3abb98f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_num', 'source_text', 'label_text', 'elaboration_sentence', 'contextual_specificity_rating'],\n",
      "        num_rows: 1049\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_num', 'source_text', 'label_text', 'elaboration_sentence', 'contextual_specificity_rating'],\n",
      "        num_rows: 134\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['doc_num', 'source_text', 'label_text', 'elaboration_sentence', 'contextual_specificity_rating'],\n",
      "        num_rows: 116\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from dataset_utils import load_dataset_from_csv\n",
    "\n",
    "ds_type = \"c2s\"\n",
    "setting = \"masked\"\n",
    "num_examples = \"n6\"\n",
    "output_name = f\"{ds_type}-{setting}\"\n",
    "\n",
    "dataset = load_dataset_from_csv(ds_type, setting)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6b6f6-b982-4cf2-8b0a-d2357ed4ea9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8177410-3aa9-44fa-84f7-66c2d7f375a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35eeaf0796a422f8cc094f5e92e6861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "# LLAMA 3.2 3B\n",
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', cache_dir=\"../models/llama/\") \n",
    "model =  AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', cache_dir=\"../models/llama/\", device_map ={'':torch.cuda.current_device()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9062c07-ee30-4b0b-bbd9-98e2f64f55c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZERO_SHOT_SYSTEM_PROMPT = \"\"\"You are an expert in generating exactly one short explanatory sentence (made up of around 10 words or fewer) in a plain English for a given context text. \n",
    "Your task is to provide additional information related to the complex statement, term, action, or concept that is semantically missing from the context text.\n",
    "You may do this by offering a definition, examples, background knowledge, general statements, a description of the flow of actions, or an explanation of the reason or result of the target action.\n",
    "The tone should be plain and simple!\n",
    "Return only ONE short concise explanatory sentence!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f51472-05c5-43e7-b6d9-83576a1d732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text with elaboration sentence masked -> elaboration sentence\n",
    "SYSTEM_PROMPT_MASKED = \"\"\"You are an expert in generating exactly one short explanatory sentence (made up of around 10 words or fewer) in a plain English for a given context text. \n",
    "Your task is to provide additional information related to the complex statement, term, action, or concept that is semantically missing from the context text.\n",
    "You may do this by offering a definition, examples, background knowledge, general statements, a description of the flow of actions, or an explanation of the reason or result of the target action.\n",
    "Your task is to replace the `<explanatory sentence>` tag in the provided text with the explanation sentence you generate.\n",
    "Return only the explanation sentence itself, without any tags, formatting, or additional text.\n",
    "The tone should be plain and simple!\n",
    "Return only ONE short concise explanatory sentence!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e6539b-9475-40c9-aed3-e9b54584a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text with elaboration sentence masked -> text with filled-out elaboration sentence\n",
    "SYSTEM_PROMPT_MASKED2 = \"\"\"You are an expert in generating exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. \n",
    "Your task is to replace the `<explanatory sentence>` tag in the provided text with an explanation sentence that adds relevant information to clarify a complex statement, term, action, or concept that is semantically missing from the text.\n",
    "The tone should be plain and simple!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c9262f8-8fd8-4e81-a050-03f96a988a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_SHORT = \"\"\"You are an expert in generating exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. \n",
    "The tone should be plain and simple!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92029d21-5798-42d5-bb40-9adc2af65c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "formatting_func = conversations_formatting_function(tokenizer, \"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d453b47-f98c-4955-aa56-fe15c877bcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are an expert in generating exactly one short explanatory sentence (made up of around 10 words or fewer) in a plain English for a given context text. \n",
      "Your task is to provide additional information related to the complex statement, term, action, or concept that is semantically missing from the context text.\n",
      "You may do this by offering a definition, examples, background knowledge, general statements, a description of the flow of actions, or an explanation of the reason or result of the target action.\n",
      "Your task is to replace the `<explanatory sentence>` tag in the provided text with the explanation sentence you generate.\n",
      "Return only the explanation sentence itself, without any tags, formatting, or additional text.\n",
      "The tone should be plain and simple!\n",
      "Return only ONE short concise explanatory sentence!\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "Context: A watermark is an image that can be seen in the paper when you hold it up to the light. Investigators say Kellogg tried to copy the watermark. <explanatory sentence> First he printed the front side of the money on one piece of paper. He printed the back of the bill on a separate sheet.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Here's how they say he did it.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formatted_example = formatting_func(formatted_train_dataset[0])\n",
    "print(formatted_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0af7e840-2264-45ff-a5aa-e4c1698f0617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'You are an expert in generating exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. \\nThe tone should be plain and simple!',\n",
       "  'role': 'system'},\n",
       " {'content': \": Return the explanation sentence for the following context text: 'A watermark is an image that can be seen in the paper when you hold it up to the light. Investigators say Kellogg tried to copy the watermark.'. The subject of the explanation sentence should be: 'Investigators'.\",\n",
       "  'role': 'user'},\n",
       " {'content': \"Here's how they say he did it.\", 'role': 'assistant'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_train_dataset[0][\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9402afb9-7925-4046-a7b8-dfc05774e50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "243b6ff8-4f7c-49ad-bdd9-4cfd7f8e7bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2269396b346400b906c60fdd945290f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1046 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97ce3f05e8b4fd0a6abab572db69aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/132 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa80adc1ba3440d998c2fdc5d34fd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_user_message_subject(example):\n",
    "    return f\": Return the explanation sentence for the following context text: '{example['source_text']}'. The subject of the explanation sentence should be: '{example['subject']}'.\"\n",
    "\n",
    "\n",
    "def format_example(example):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT_SHORT},\n",
    "            {\"role\": \"user\", \"content\": create_user_message_subject(example)}, # Context or Text\n",
    "            {\"role\": \"assistant\", \"content\":  f\"{example['elaboration_sentence']}\"}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "\n",
    "def format_test_example(example):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT_SHORT},\n",
    "            {\"role\": \"user\", \"content\": create_user_message_subject(example)},\n",
    "             {\"role\": \"assistant\", \"content\":\"\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "formatted_train_dataset = dataset[\"train\"].map(format_example)\n",
    "formatted_validation_dataset = dataset[\"validation\"].map(format_example)\n",
    "formatted_test_dataset = dataset[\"test\"].map(format_test_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba143790-1f66-4aa2-9056-ebbe482dd684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length of messages: 28.91459528362014\n"
     ]
    }
   ],
   "source": [
    "def calculate_mean_message_length(dataset):\n",
    "    total_length = 0\n",
    "    message_count = 0\n",
    "\n",
    "    for entry in dataset:\n",
    "        messages = entry.get('messages', [])\n",
    "        for message in messages:\n",
    "            content = message.get('content', \"\")\n",
    "            total_length += len(content.split())  # Count words in the content\n",
    "            message_count += 1\n",
    "\n",
    "    return total_length / message_count if message_count > 0 else 0\n",
    "\n",
    "mean_length = calculate_mean_message_length(formatted_train_dataset)\n",
    "print(f\"Mean length of messages: {mean_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a2e794-dcce-419c-aa59-f89be8377bd0",
   "metadata": {},
   "source": [
    "# Alpaca format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0736d75-8462-4a65-92a5-287bb509ae3a",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4384157-c4db-4161-999d-674f10373ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Definition', 'Example', 'Analogy', 'Background', 'Reason', 'Contrast', 'Result', 'Speculation', 'Supplementation'])\n"
     ]
    }
   ],
   "source": [
    "from prompt_utils import examples_dict\n",
    "print(examples_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0202c25c-6cac-4323-a03c-990fc4716cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User: You are an expert in clarifying unclear or complex terms and concepts in a given text. Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
      "For example:\n",
      "\n",
      "context text: 'She teaches at the University of Utah. In 1974, Wiessner recorded conversations among the Ju/'hoansi Bushmen. <explanatory sentence> They live in a vast area of 124 miles in southwestern Africa. Their lives have changed since the 1970s.'\n",
      "Assistant: 'The Bushmen are a group of people who hunt animals and gather wild berries and plants to eat.'\n",
      "\n",
      "context text: 'There are differences in how the increases would work. The differences have to do with how the cost of living would be measured. <explanatory sentence> The minimum wage in Alaska would be based on prices in Alaska. South Dakota would raise the minimum wage based on changes to a national measure of the cost of living.'\n",
      "Assistant: 'The cost of living looks at prices for things like food, clothes and housing.'\n",
      "\n",
      "context text: 'When Border first started doing art, he worked with paper and clay. A few years ago, he found a dead elk. <explanatory sentence> He loaded the elk into his car, Borders said, laughing. 'I almost got arrested doing this.''\n",
      "Assistant: 'Elk are similar to deer, but larger.'\n",
      "\n",
      "context text: 'The light of the fire changed how their bodies made a chemical called melatonin. <explanatory sentence> Firelight let people stay awake after the sun went down.'\n",
      "Assistant: 'Melatonin makes people feel sleepy when it gets dark.'\n",
      "\n",
      "context text: 'He works at the hospital where Emily was treated. Less government money could mean less experimental therapies and research. <explanatory sentence> The number of specialists in children's hospitals across the country has dropped, he added.'\n",
      "Assistant: 'And that could hurt patients, he said.'\n",
      "\n",
      "context text: 'She is mystery writer Agatha Christie. J.K. Rowling is the best-selling author of recent memory. <explanatory sentence>  Yet no woman has been chosen to be put on British money.'\n",
      "Assistant: 'She created Harry Potter.'\n",
      "\n",
      "Return the explanation sentence that could replace the `<explanatory sentence>` tag in the following text: 'New companies have come that need skilled workers with more education. New Haven youth want those jobs, but they do not have the education or the skills. <explanatory sentence>'.\n",
      "### Assistant:\n"
     ]
    }
   ],
   "source": [
    "from prompt_utils import formatting_prompt_func \n",
    "\n",
    "formatted_test_dataset = formatting_prompt_func(dataset[\"test\"], setting, num_examples)\n",
    "print(formatted_test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b18901e-b3a3-4253-9817-5842eb2e92f0",
   "metadata": {},
   "source": [
    "### BASE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c504e9-8b74-48b8-8215-a7a9814d0537",
   "metadata": {},
   "source": [
    "#### Short version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb88a33f-34fe-4205-bbc8-78b0e64839d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_utils import examples_dict, base_prompt, insert_examples, create_user_message\n",
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "\"\"\"def create_user_message(context):\n",
    "    return f\"Return an explanation sentence for the following context text: '{context}'.\" \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: You are an expert in clarifying unclear or complex terms and concepts in a given text. Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
    "For example: \n",
    "context text: 'The environment is essential for sustaining life, providing clean air, water, and fertile soil. Protecting it ensures a healthier planet for future generations. '\n",
    "assistant: 'This includes reducing pollution and conserving resources.'\n",
    "\n",
    "context text: 'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from serene cherry blossom gardens to towering Mount Fuji.'\n",
    "assistant: 'Mount Fuji is the tallest mountain in Japan.'\n",
    "\n",
    "{}\\n### Assistant:\"\"\"\n",
    "\n",
    "versions = {\n",
    "    \"n3\":['Definition','Example','Background'],\n",
    "    \"n6\":['Definition','Example','Background', 'Supplementation', 'Analogy', 'Speculation'],\n",
    "    \"n9\":['Definition', 'Example', 'Analogy', 'Background', 'Reason', 'Contrast', 'Result', 'Speculation', 'Supplementation']\n",
    "}\n",
    "\n",
    "filtered_dict = {key: value for key, value in examples_dict.items() if key in versions[num_examples]}\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    \n",
    "    contexts = examples[\"source_text\"]\n",
    "    texts = []\n",
    "    for context in contexts:\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = base_prompt.format(insert_examples(filtered_dict, setting),create_user_message(context, setting)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b866120e-12a0-407a-9b1e-2779f88fb9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User: You are an expert in clarifying unclear or complex terms and concepts in a given text. Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
      "For example:\n",
      "\n",
      "context text: 'She teaches at the University of Utah. In 1974, Wiessner recorded conversations among the Ju/'hoansi Bushmen. They live in a vast area of 124 miles in southwestern Africa. Their lives have changed since the 1970s.'\n",
      "target_phrase='Bushmen'\n",
      "Assistant: 'The Bushmen are a group of people who hunt animals and gather wild berries and plants to eat.'\n",
      "\n",
      "context text: 'There are differences in how the increases would work. The differences have to do with how the cost of living would be measured. The minimum wage in Alaska would be based on prices in Alaska. South Dakota would raise the minimum wage based on changes to a national measure of the cost of living.'\n",
      "target_phrase='the cost of living'\n",
      "Assistant: 'The cost of living looks at prices for things like food, clothes and housing.'\n",
      "\n",
      "context text: 'The light of the fire changed how their bodies made a chemical called melatonin. Firelight let people stay awake after the sun went down.'\n",
      "target_phrase='a chemical called melatonin'\n",
      "Assistant: 'Melatonin makes people feel sleepy when it gets dark.'\n",
      "\n",
      "Return an explanation sentence for the following context text: 'New companies have come that need skilled workers with more education. New Haven youth want those jobs, but they do not have the education or the skills.'.\n",
      "### Assistant:\n"
     ]
    }
   ],
   "source": [
    "print(formatted_test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e931b774-cbba-44e8-8ce4-edeee9ad0cef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Long version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2aeb8144-a668-475a-9339-7a278ca94735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User: You are an expert in clarifying unclear or complex terms and concepts in a given text. Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
      "For example:\n",
      "\n",
      "context text: 'Together they slowed down the large group of trucks carrying the machine parts. They were not able to stop the trucks for long, though. This one was carrying a giant water evaporator. After being blocked, it continued on its way when police arrested 20 of the protesters.'\n",
      "Assistant: 'Trucks that travel in groups are known as a convoy.'\n",
      "\n",
      "context text: 'There are differences in how the increases would work. The differences have to do with how the cost of living would be measured. The minimum wage in Alaska would be based on prices in Alaska. South Dakota would raise the minimum wage based on changes to a national measure of the cost of living.'\n",
      "Assistant: 'The cost of living looks at prices for things like food, clothes and housing.'\n",
      "\n",
      "context text: 'Scientists studied the birds, called bar-headed geese. They were on their way south for the winter. The scientists followed the birds across the world's tallest mountains. They found that the geese do not fly in a straight line.'\n",
      "Assistant: 'Geese often spend the summer in one place and then move on for the winter so they can stay warm.'\n",
      "\n",
      "context text: 'Three days later, he became sicker and was rushed back to Texas Health Presbyterian Hospital Dallas. He was in a room by himself in the hospital. Duncan was extremely ill. Because doctors did not realize Duncan had Ebola, many are afraid.'\n",
      "Assistant: 'He must be kept away from the other patients because the disease could spread.'\n",
      "\n",
      "context text: 'We can talk to each other and share our problems. Some are wondering why China's leaders made the law. Or, are they worried about how much money it costs to care for all the old people? Chen Honglin is a college teacher.'\n",
      "Assistant: 'Are they worried about loneliness?'\n",
      "\n",
      "context text: 'Emily was suffering from leukemia, a form of cancer. Emily's parents were desperate to save their only child. The treatment meant removing millions of Emily's T-cells. A T-cell is a type of white blood cell.'\n",
      "Assistant: 'So they decided to send her for an experimental treatment.'\n",
      "\n",
      "context text: 'St. Paul's coach, Steve Mask, warns players about what not to do. He tells them not to write about injuries. Colleges looking for athletes want to make sure their players can win. Promising to play for a college on Twitter is also a bad idea.'\n",
      "Assistant: 'Players who get hurt might not be as good after they heal.'\n",
      "\n",
      "Return an explanation sentence for the following context text: 'WASHINGTON – At least four people died in Midwest floods this Spring. But the death toll could have been higher. Forecasters said more people could have died if there were no river gauges. It sits in the water. The United States has 8,000 gauges to quickly track the rise of rivers. But that number may shrink. The reason is that lawmakers in Washington are in the middle of a fight.'.\n",
      "### Assistant:\n"
     ]
    }
   ],
   "source": [
    "from prompt_utils import examples_dict, base_prompt, insert_examples, examples_dict_from_validation_dataset\n",
    "\n",
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def create_user_message(context):\n",
    "    return f\"Return an explanation sentence for the following context text: '{context}'.\"\n",
    "\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    texts = []\n",
    "    for context in contexts:\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = base_prompt.format(insert_examples(examples_dict_from_validation_dataset),create_user_message(context))\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])\n",
    "print(formatted_test_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6bb90f-44c5-4eb6-a10f-e659a837aed5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Random version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66f51d2d-d9e0-4ae6-b07d-4643a05e7724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User: You are an expert in clarifying unclear or complex terms and concepts in a given text. Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
      "For example:\n",
      "\n",
      "context text: 'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from cherry blossom gardens to towering Mount Fuji.'\n",
      "Assistant: 'Mount Fuji is the tallest mountain in Japan.'\n",
      "\n",
      "context text: 'One of the most thrilling events in winter sports is ski jumping. Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
      "Assistant: 'As they glide down, they gain speed, which helps them jump higher into the air.'\n",
      "\n",
      "Return an explanation sentence for the following context text: 'WASHINGTON – At least four people died in Midwest floods this Spring. But the death toll could have been higher. Forecasters said more people could have died if there were no river gauges. A gauge is a kind of measuring stick. The United States has 8,000 gauges to quickly track the rise of rivers. But that number may shrink. The reason is that lawmakers in Washington are in the middle of a fight. They cannot agree over how much money the government should spend.'.\n",
      "### Assistant:\n"
     ]
    }
   ],
   "source": [
    "from prompt_utils import examples_dict, base_prompt, insert_random_examples\n",
    "\n",
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def create_user_message(context):\n",
    "    return f\"Return an explanation sentence for the following context text: '{context}'.\"\n",
    "\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    texts = []\n",
    "    for context in contexts:\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = base_prompt.format(insert_random_examples(examples_dict,num_examples=2),create_user_message(context)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])\n",
    "print(formatted_test_dataset[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92129a-7f46-426d-9782-54be33bd78db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Masked version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "097819d9-92cb-4eb7-9b7d-45afb2b4c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def create_user_message(context):\n",
    "    return f\"Return the explanation sentence that could replace the `<explanatory sentence>` tag in the following text: '{context}'.\"\n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English that could replace the <explanatory sentence> tag in a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
    "For example: \n",
    "context text: 'The environment is essential for sustaining life, providing clean air, water, and fertile soil. <explanatory sentence> Protecting the environment ensures a healthier planet for future generations. '\n",
    "assistant: 'Fertile soil is ideal for growing plants.'\n",
    "\n",
    "context text: 'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from serene cherry blossom gardens to towering Mount Fuji. <explanatory sentence>'\n",
    "assistant: 'Mount Fuji is the tallest mountain in Japan.'\n",
    "\n",
    "{}\\n### Assistant:\"\"\"\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    texts = []\n",
    "    for context in contexts:\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = test_alpaca_prompt.format(create_user_message(context)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f7deab73-bc2a-4381-838a-485e7c54f315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English that could replace the <explanatory sentence> tag in a given context text. The tone should be plain and simple! Do not add any comments to your answer! \\nFor example: \\ncontext text: \\'The environment is essential for sustaining life, providing clean air, water, and fertile soil. <explanatory sentence> Protecting the environment ensures a healthier planet for future generations. \\'\\nassistant: \\'Fertile soil is ideal for growing plants.\\'\\n\\ncontext text: \\'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from serene cherry blossom gardens to towering Mount Fuji. <explanatory sentence>\\'\\nassistant: \\'Mount Fuji is the tallest mountain in Japan.\\'\\n\\nReturn the explanation sentence that could replace the `<explanatory sentence>` tag in the following text: \\'They did not need special skills or a college education to work there. Those factories are gone now. New companies have come that need skilled workers with more education. New Haven youth want those jobs, but they do not have the education or the skills. <explanatory sentence> That is where New Haven Promise comes in. It will make a difference by paying for college. New Haven Promise is no one-way street. The students have to sign a pledge to \"do their best.\"\\'.\\n### Assistant:'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f0762-c9e4-4a5e-ad9a-b356b79ad05e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Specifying subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "42af8e4f-6fd8-47f6-a995-b04cb8d07357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def create_user_message_subject(context, subject):\n",
    "    return f\"Return the explanation sentence for the following context text: '{context}'. The explanation sentence should refer to the {subject}.\"\n",
    "print(tokenizer.eos_token )\n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
    "For example: \n",
    "context text: 'The environment is essential for sustaining life, providing clean air, water, and fertile soil. Protecting it ensures a healthier planet for future generations. '\n",
    "subject='protecting the environment'\n",
    "assistant: 'This includes reducing pollution and conserving resources.'\n",
    "\n",
    "context text: 'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from serene cherry blossom gardens to towering Mount Fuji.'\n",
    "subject='Mount Fuji'\n",
    "assistant: 'Mount Fuji is the tallest mountain in Japan.'\n",
    "\n",
    "{}\\n### Assistant:\"\"\"\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    subjects = examples[\"subject\"]\n",
    "    texts = []\n",
    "    for context, subject in zip(contexts, subjects):\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = test_alpaca_prompt.format(create_user_message_subject(context, subject)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f1b41f91-b3ca-424b-b5ce-3f9adc50a9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \\nFor example: \\ncontext text: \\'The environment is essential for sustaining life, providing clean air, water, and fertile soil. Protecting it ensures a healthier planet for future generations. \\'\\nsubject=\\'protecting the environment\\'\\nassistant: \\'This includes reducing pollution and conserving resources.\\'\\n\\ncontext text: \\'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from serene cherry blossom gardens to towering Mount Fuji.\\'\\nsubject=\\'Mount Fuji\\'\\nassistant: \\'Mount Fuji is the tallest mountain in Japan.\\'\\n\\nReturn the explanation sentence for the following context text: \\'Factories have closed and their low-skill manufacturing jobs are long gone. The new companies in town require workers with a college degree or advanced training. But the turnaround will take more than just new companies moving to town; New Haven needs to invest in educating its youth so they will be qualified to do those high-skilled jobs when they become adults. The New Haven Promise is no one-way street. Although the scholarship is available to all students, they must sign a pledge to \"do their best\" in certain vital areas of achievement. The goal is to create an expectation that all students can and will attend college.\\'. The explanation sentence should refer to the subject=\\'Many people in New Haven\\'.\\n### Assistant:'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c6525d-4d22-484e-bb65-897d8065674d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Specifying the target phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "078aedb1-8ac3-4029-bd70-b12baf9c2f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_utils import examples_dict, base_prompt, insert_examples, create_user_message\n",
    "\n",
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def create_user_message_target(context, target):\n",
    "    return f\"Return the explanation sentence for the following context text: '{context}'. The explanation sentence should specifically clarify the {target}.\"\n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: You are an expert in clarifying unclear or complex terms and concepts in a given text. Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
    "For example: \n",
    "context text: 'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from cherry blossom gardens to towering Mount Fuji.'\n",
    "target_phrase='cultural heritage'\n",
    "Assistant: This heritage includes traditional arts like tea ceremony or calligraphy. \n",
    "\n",
    "context text: 'One of the most thrilling events in winter sports is ski jumping. Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
    "target_phrase='glide down'\n",
    "Assistant: As they glide down, they gain speed, which helps them jump higher into the air.\n",
    "\n",
    "{}\\n### Assistant:\"\"\"\n",
    "\n",
    "versions = {\n",
    "    \"n3\":['Definition','Example','Background'],\n",
    "    \"n6\":['Definition','Example','Background', 'Supplementation', 'Analogy', 'Speculation'],\n",
    "    \"n9\":['Definition', 'Example', 'Analogy', 'Background', 'Reason', 'Contrast', 'Result', 'Speculation', 'Supplementation']\n",
    "}\n",
    "\n",
    "filtered_dict = {key: value for key, value in examples_dict.items() if key in versions[num_examples]}\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    targets = examples[\"target_sentence_target\"]\n",
    "    texts = []\n",
    "    for context, target in zip(contexts, targets):\n",
    "        # must add EOS_TOKEN, otherwise the generation won't stop\n",
    "        text = base_prompt.format(insert_examples(filtered_dict, setting), create_user_message(context, setting, target)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "391ec16b-c476-4c9d-93e5-d3f500f580db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User: You are an expert in clarifying unclear or complex terms and concepts in a given text. Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
      "For example:\n",
      "\n",
      "context text: 'She teaches at the University of Utah. In 1974, Wiessner recorded conversations among the Ju/'hoansi Bushmen. They live in a vast area of 124 miles in southwestern Africa. Their lives have changed since the 1970s.'\n",
      "target_phrase='Bushmen'\n",
      "Assistant: 'The Bushmen are a group of people who hunt animals and gather wild berries and plants to eat.'\n",
      "\n",
      "context text: 'There are differences in how the increases would work. The differences have to do with how the cost of living would be measured. The minimum wage in Alaska would be based on prices in Alaska. South Dakota would raise the minimum wage based on changes to a national measure of the cost of living.'\n",
      "target_phrase='the cost of living'\n",
      "Assistant: 'The cost of living looks at prices for things like food, clothes and housing.'\n",
      "\n",
      "context text: 'The light of the fire changed how their bodies made a chemical called melatonin. Firelight let people stay awake after the sun went down.'\n",
      "target_phrase='a chemical called melatonin'\n",
      "Assistant: 'Melatonin makes people feel sleepy when it gets dark.'\n",
      "\n",
      "Return the explanation sentence for the following context text: 'New companies have come that need skilled workers with more education. New Haven youth want those jobs, but they do not have the education or the skills.'. The explanation sentence should specifically clarify the target_phrase=''do not have the education or the skills''.\n",
      "### Assistant:\n"
     ]
    }
   ],
   "source": [
    "print(formatted_test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec81b72e-6aa7-41b9-8532-9e2bb9518809",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Specifying the target sentence for clarification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11f1b2c3-58f8-4d85-a82c-e868d092e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def create_user_message_target(context, target):\n",
    "    return f\"Return the explanation sentence for the following context text: '{context}'. The explanation sentence should specifically clarify the target_sentence={target}\"\n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: You are an expert in clarifying unclear or complex terms and concepts in a given text. Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
    "For example: \n",
    "context text: 'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from cherry blossom gardens to towering Mount Fuji.'\n",
    "target_sentence='Japan is known for its rich cultural heritage and advanced technology.'\n",
    "Assistant: This heritage includes traditional arts like tea ceremony or calligraphy. \n",
    "\n",
    "context text: 'One of the most thrilling events in winter sports is ski jumping. Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
    "target_sentence='Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
    "Assistant: As they glide down, they gain speed, which helps them jump higher into the air.\n",
    "\n",
    "{}\\n### Assistant:\"\"\"\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    targets = examples[\"target_sentence_4o\"]\n",
    "    texts = []\n",
    "    for context, target in zip(contexts, targets):\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = test_alpaca_prompt.format(create_user_message_target(context, target)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f2e3a61-6a56-4a5e-8f10-904b94cef3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User: You are an expert in clarifying unclear or complex terms and concepts in a given text. Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
      "For example: \n",
      "context text: 'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from cherry blossom gardens to towering Mount Fuji.'\n",
      "target_sentence='Japan is known for its rich cultural heritage and advanced technology.'\n",
      "Assistant: This heritage includes traditional arts like tea ceremony or calligraphy. \n",
      "\n",
      "context text: 'One of the most thrilling events in winter sports is ski jumping. Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
      "target_sentence='Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
      "Assistant: As they glide down, they gain speed, which helps them jump higher into the air.\n",
      "\n",
      "Return the explanation sentence for the following context text: 'WASHINGTON –Spring is off to a soggy and sometimes deadly start in the Midwest, where floodwaters have driven thousands of people from their homes and killed at least four. But forecasters say the death toll could have been even higher, if they could not quickly track the rise of the rain-swollen Mississippi, Illinois and other rivers that  spilled over their banks. A network of gauges provides that information to officials in states that are prone to flooding. The gauges record the rise and fall of waters across the United States. But that 8,000-gauge network, called the National Streamflow Information Program, may shrink due to paralysis in Congress. As many as 375 gauges could shut down in the coming months, according to the U.S. Geological Research Survey (USGS), the agency that oversees the program. That is unless Congress passes a budget to undo major spending cuts known as sequestration.'. The explanation sentence should specifically clarify the target_sentence=A network of gauges provides that information to officials in states that are prone to flooding.\n",
      "### Assistant:\n"
     ]
    }
   ],
   "source": [
    "print(formatted_test_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff533823-631a-4975-ba34-cbf7670cade1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Specifying both the target phrase/ subject and the target sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03d92cb0-23c4-4cfd-b4af-82e2681310e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def create_user_message_target(context, target,target_sentence):\n",
    "    return f\"Return the explanation sentence for the following context text: '{context}'. The explanation sentence should specifically clarify the target_sentence='{target_sentence}' by referring to the {target}.\"\n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: You are an expert in clarifying unclear or complex terms and concepts in a given text. Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
    "For example: \n",
    "context text: 'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from cherry blossom gardens to towering Mount Fuji.'\n",
    "target_sentence='Japan is known for its rich cultural heritage and advanced technology.'\n",
    "target_phrase='cultural heritage'\n",
    "Assistant: This heritage includes traditional arts like tea ceremony or calligraphy. \n",
    "\n",
    "context text: 'One of the most thrilling events in winter sports is ski jumping. Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
    "target_sentence='Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
    "target_phrase='glide down'\n",
    "Assistant: As they glide down, they gain speed, which helps them jump higher into the air.\n",
    "\n",
    "{}\\n### Assistant:\"\"\"\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    targets = examples[\"target_sentence_target\"] # target_sentence_target subject\n",
    "    target_sents = examples[\"target_sentence_4o\"]\n",
    "    texts = []\n",
    "    for context, target, target_sent in zip(contexts, targets, target_sents):\n",
    "        text = test_alpaca_prompt.format(create_user_message_target(context, target, target_sent)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5f3828e-894a-4210-97e0-9bdfcfb00d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User: You are an expert in clarifying unclear or complex terms and concepts in a given text. Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
      "For example: \n",
      "context text: 'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from cherry blossom gardens to towering Mount Fuji.'\n",
      "target_sentence='Japan is known for its rich cultural heritage and advanced technology.'\n",
      "target_phrase='cultural heritage'\n",
      "Assistant: This heritage includes traditional arts like tea ceremony or calligraphy. \n",
      "\n",
      "context text: 'One of the most thrilling events in winter sports is ski jumping. Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
      "target_sentence='Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
      "target_phrase='glide down'\n",
      "Assistant: As they glide down, they gain speed, which helps them jump higher into the air.\n",
      "\n",
      "Return the explanation sentence for the following context text: 'New Haven Promise is offering workshops for parents on how to make sense of the college application process, which can be confusing. New Haven has pledged to have all students reading proficiently by the end of third grade, putting them on track for college readiness by high school. The Promise program will be considered a success if students are able to do well enough in college to finish with a 2-year or 4-year degree. Educators are tracking students who enter college on a Promise scholarship and finding that many do not enroll for a second year after finishing the first. Many are unable to keep up the minimum grade average. The ability to not just start college, but stay with it is called \"college persistence.\" Middle-class students on the Promise Scholarships tend to do better than their lower-income peers. That goes to show that there are big barriers to achieving success, even when there is money pointed at the problem. For example, in Kalamazoo, the success rate for middle-income students was about twice that for poor students, with the low-income students either losing their scholarships or being put on probation.'. The explanation sentence should specifically clarify the target_sentence='Many are unable to keep up the minimum grade average.' by referring to the target_phrase='unable to keep up the minimum grade average'.\n",
      "### Assistant:\n"
     ]
    }
   ],
   "source": [
    "print(formatted_test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd2e69e-4875-4ef6-b975-f1c9c0a6b40c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Specifying both the target phrase (from the target sentence) and the target sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a3ffba-9b3a-47f1-9839-687218469c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "alpaca_prompt = \"\"\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! {}\\n### Assistant: {}\"\"\"\n",
    "\n",
    "def create_user_message_target(context, target, target_sentence):\n",
    "    return f\"Return the explanation sentence for the following context text: '{context}'. The explanation sentence should specifically clarify the {target_sentence} by referring to the {target}.\"\n",
    "print(tokenizer.eos_token )\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    targets = examples[\"target_sentence_target\"]\n",
    "    target_sents = examples[\"target_sentence_4o\"]\n",
    "    elab_sentences = examples[\"elaboration_sentence\"]\n",
    "    texts = []\n",
    "    for context, target, target_sent, elab_sent in zip(contexts, targets, target_sents, elab_sentences):\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = alpaca_prompt.format(create_user_message_target(context, target, target_sent), elab_sent) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! {}\\n### Assistant:\"\"\"\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    targets = examples[\"target_sentence_target\"]\n",
    "    target_sents = examples[\"target_sentence_4o\"]\n",
    "    texts = []\n",
    "    for context, target, target_sent in zip(contexts, targets, target_sents):\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = test_alpaca_prompt.format(create_user_message_target(context, target, target_sent)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "596825aa-a5f4-4613-80f8-4ec8a6475116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! Return the explanation sentence for the following context text: 'New companies have come that need skilled workers with more education. New Haven youth want those jobs, but they do not have the education or the skills.'. The explanation sentence should specifically clarify the target_sentence='New Haven youth want those jobs, but they do not have the education or the skills.' by referring to the target_phrase='do not have the education or the skills'.\\n### Assistant:\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b125b1-9f2b-4d2b-97ef-cc8a35f9752d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Target sentence -> elaboration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad575a39-e350-45af-b4e7-081e084bc7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def create_user_message(context):\n",
    "    return f\"Return the clarification sentence for the {context}. \"\n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: Your task is to generate exactly ONE short concise clarification sentence (made up of around 10 words or fewer) in a plain English for a given sentence. The tone should be plain and simple! Do not add any comments to your answer! \n",
    "For example:\n",
    "target_sentence='Japan\\'slandscapes range from serene cherry blossom gardens to towering Mount Fuji.'\n",
    "Assistant: Mount Fuji is the tallest mountain in Japan.\n",
    "\n",
    "target_sentence='Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
    "Assistant: As they glide down, they gain speed, which helps them jump higher into the air.\n",
    "\n",
    "{}\\n### Assistant:\"\"\"\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"target_sentence_4o\"]\n",
    "    texts = []\n",
    "    for context in contexts:\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = test_alpaca_prompt.format(create_user_message(context)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "22a700af-2493-4f5a-9552-78ce6ff0f8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### User: Your task is to generate exactly ONE short concise clarification sentence (made up of around 10 words or fewer) in a plain English for a given sentence. The tone should be plain and simple! Do not add any comments to your answer! \\nFor example:\\ntarget_sentence='Japan'slandscapes range from serene cherry blossom gardens to towering Mount Fuji.'\\nAssistant: Mount Fuji is the tallest mountain in Japan.\\n\\ntarget_sentence='Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\\nAssistant: As they glide down, they gain speed, which helps them jump higher into the air.\\n\\nReturn the clarification sentence for the target_sentence='New Haven needs to invest in educating its youth so they will be qualified to do those high-skilled jobs when they become adults.'. \\n### Assistant:\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f254e-e425-43f6-a4fa-1dcd59de1eb0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Target sentence + target phrase/subject -> elaboration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7914c481-72d0-434d-af4d-68636774cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def create_user_message(context, target):\n",
    "    return f\"Return the clarification sentence for the {context}. The explanation sentence should refer to the {target}.\" \n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: Your task is to generate exactly ONE short concise clarification sentence (made up of around 10 words or fewer) in a plain English for a given sentence. The tone should be plain and simple! Do not add any comments to your answer! \n",
    "For example:\n",
    "target_sentence='Japan\\'slandscapes range from serene cherry blossom gardens to towering Mount Fuji.'\n",
    "target_phrase='Mount Fuji'\n",
    "Assistant: Mount Fuji is the tallest mountain in Japan.\n",
    "\n",
    "target_sentence='Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
    "target_phrase='glide down'\n",
    "Assistant: As they glide down, they gain speed, which helps them jump higher into the air.\n",
    "\n",
    "{}\\n### Assistant:\"\"\"\n",
    "\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"target_sentence_4o\"]\n",
    "    targets = examples[\"target_sentence_target\"] # target_sentence_target subject\n",
    "    texts = []\n",
    "    for context, target in zip(contexts,targets):\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = test_alpaca_prompt.format(create_user_message(context, target)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f49aaa8d-82f3-4617-9c01-460ad7508c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### User: Your task is to generate exactly ONE short concise clarification sentence (made up of around 10 words or fewer) in a plain English for a given sentence. The tone should be plain and simple! Do not add any comments to your answer! \\nFor example:\\ntarget_sentence='Japan'slandscapes range from serene cherry blossom gardens to towering Mount Fuji.'\\ntarget_phrase='Mount Fuji'\\nAssistant: Mount Fuji is the tallest mountain in Japan.\\n\\ntarget_sentence='Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\\ntarget_phrase='glide down'\\nAssistant: As they glide down, they gain speed, which helps them jump higher into the air.\\n\\nReturn the clarification sentence for the target_sentence='New Haven needs to invest in educating its youth so they will be qualified to do those high-skilled jobs when they become adults.'. The explanation sentence should refer to the target_phrase='educating its youth'.\\n### Assistant:\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c520e3-867f-43a5-89cd-e2891ad05e84",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### For testing the model trained with the subject or target info  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76507e12-1f19-4099-862e-07847aeccb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_message(context):\n",
    "    return f\"Return the explanation sentence for the following context text: '{context}'.\"\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    texts = []\n",
    "    for context in contexts:\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = test_alpaca_prompt.format(create_user_message(context)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "412c4275-58f7-445c-8e21-23c7bb6b2b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. \\nThe tone should be plain and simple! Return the explanation sentence for the following context text: 'They did not need special skills or a college education to work there. Those factories are gone now. New companies have come that need skilled workers with more education. New Haven youth want those jobs, but they do not have the education or the skills.'.\\n### Assistant:\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb732d3c-51c3-4780-914f-441e5faf7044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('###', 14711), ('ĠUser', 2724), (':', 25), ('ĠYour', 4718), ('Ġtask', 3465), ('Ġis', 374), ('Ġto', 311), ('Ġgenerate', 7068), ('Ġexactly', 7041), ('ĠONE', 25002), ('Ġshort', 2875), ('Ġconcise', 64694), ('Ġexplanation', 16540), ('Ġsentence', 11914), ('Ġ(', 320), ('made', 28010), ('Ġup', 709), ('Ġof', 315), ('Ġaround', 2212), ('Ġ', 220), ('10', 605), ('Ġwords', 4339), ('Ġor', 477), ('Ġfewer', 17162), (')', 8), ('Ġin', 304), ('Ġa', 264), ('Ġplain', 14733), ('ĠEnglish', 6498), ('Ġfor', 369), ('Ġa', 264), ('Ġgiven', 2728), ('Ġcontext', 2317), ('Ġtext', 1495), ('.', 13), ('ĠThe', 578), ('Ġtone', 16630), ('Ġshould', 1288), ('Ġbe', 387), ('Ġplain', 14733), ('Ġand', 323), ('Ġsimple', 4382), ('!', 0), ('ĠReturn', 3494), ('Ġthe', 279), ('Ġexplanation', 16540), ('Ġsentence', 11914), ('Ġfor', 369), ('Ġthe', 279), ('Ġfollowing', 2768), ('Ġcontext', 2317), ('Ġtext', 1495), (':', 25), (\"Ġ'\", 364), ('A', 32), ('Ġwatermark', 89106), ('Ġis', 374), ('Ġan', 459), ('Ġimage', 2217), ('Ġthat', 430), ('Ġcan', 649), ('Ġbe', 387), ('Ġseen', 3970), ('Ġin', 304), ('Ġthe', 279), ('Ġpaper', 5684), ('Ġwhen', 994), ('Ġyou', 499), ('Ġhold', 3412), ('Ġit', 433), ('Ġup', 709), ('Ġto', 311), ('Ġthe', 279), ('Ġlight', 3177), ('.', 13), ('ĠInvestigators', 96852), ('Ġsay', 2019), ('ĠKel', 28263), ('logg', 94469), ('Ġtried', 6818), ('Ġto', 311), ('Ġcopy', 3048), ('Ġthe', 279), ('Ġwatermark', 89106), ('.', 13), ('ĠFirst', 5629), ('Ġhe', 568), ('Ġprinted', 17124), ('Ġthe', 279), ('Ġfront', 4156), ('Ġside', 3185), ('Ġof', 315), ('Ġthe', 279), ('Ġmoney', 3300), ('Ġon', 389), ('Ġone', 832), ('Ġpiece', 6710), ('Ġof', 315), ('Ġpaper', 5684), ('.', 13), ('ĠHe', 1283), ('Ġprinted', 17124), ('Ġthe', 279), ('Ġback', 1203), ('Ġof', 315), ('Ġthe', 279), ('Ġbill', 4121), ('Ġon', 389), ('Ġa', 264), ('Ġseparate', 8821), ('Ġsheet', 11071), (\".'.\", 37049), ('ĠThe', 578), ('Ġsubject', 3917), ('Ġof', 315), ('Ġthe', 279), ('Ġexplanation', 16540), ('Ġsentence', 11914), ('Ġshould', 1288), ('Ġrefer', 8464), ('Ġto', 311), ('Ġ:', 551), (\"Ġ'\", 364), ('Investigators', 88280), (\"'.Ċ\", 24482), ('###', 14711), ('ĠAssistant', 22103), (':', 25), ('ĠHere', 5810), (\"'s\", 596), ('Ġhow', 1268), ('Ġthey', 814), ('Ġsay', 2019), ('Ġhe', 568), ('Ġdid', 1550), ('Ġit', 433), ('.', 13), ('<|end_of_text|>', 128001)]\n"
     ]
    }
   ],
   "source": [
    "def print_tokens_with_ids(txt):\n",
    "    tokens = tokenizer.tokenize(txt, add_special_tokens=False)\n",
    "    token_ids = tokenizer.encode(txt, add_special_tokens=False)\n",
    "    print(list(zip(tokens, token_ids)))\n",
    "\n",
    "formatted_ds = formatting_prompts_func(dataset[\"train\"])\n",
    "prompt = formatted_ds[0]\n",
    "print_tokens_with_ids(prompt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ec86548-bf9d-474a-ba83-3ac8ac702f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('###', 14711), ('ĠAssistant', 22103), (':', 25)]\n"
     ]
    }
   ],
   "source": [
    "response_template = \"### Assistant:\"\n",
    "print_tokens_with_ids(response_template) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d28e00-7289-4b1a-a145-e0b28b712807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. \\nThe tone should be plain and simple! Return the explanation sentence for the following context text: 'New companies have come that need skilled workers with more education. New Haven youth want those jobs, but they do not have the education or the skills. That is where New Haven Promise comes in. It will make a difference by paying for college.'. The subject of the explanation sentence should refer to : 'Many (youth)'.\\n### Assistant:\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])\n",
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc09ce-cea6-42ac-923f-ee4439ef2098",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d8114a3-d6ac-4018-b525-9adfffcd6f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory does not exist: ../models/llama3.2-news-ft/logs/logs-c2osp\n"
     ]
    }
   ],
   "source": [
    "from model_utils import clear_directory\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "del model, trainer, tokenizer, data_collator\n",
    "clear_directory(logs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14720cf-289f-4966-a7fe-fb7c44cba331",
   "metadata": {},
   "source": [
    "# Generate predictions\n",
    "\n",
    "https://github.com/NielsRogge/Transformers-Tutorials/blob/master/Mistral/Supervised_fine_tuning_(SFT)_of_an_LLM_using_Hugging_Face_tooling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b0b34c5-94cf-4f1e-97ee-0f4345f78b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, StoppingCriteria, StoppingCriteriaList\n",
    "import torch\n",
    "\n",
    "class RefinedEndSentenceStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, tokenizer, sentence_end_tokens):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sentence_end_token_ids = [\n",
    "            self.tokenizer.convert_tokens_to_ids(token) for token in sentence_end_tokens\n",
    "        ]\n",
    "        self.eos_token_id = tokenizer.eos_token_id  # Include eos_token_id\n",
    "\n",
    "    def is_valid_stop(self, input_ids):\n",
    "        # Get the last token and the one before it\n",
    "        if len(input_ids[0]) < 2:\n",
    "            return False  # Not enough tokens to decide\n",
    "        last_token_id = input_ids[0, -1].item()\n",
    "        second_last_token_id = input_ids[0, -2].item()\n",
    "\n",
    "        # Decode tokens to check context\n",
    "        last_token = self.tokenizer.decode([last_token_id])\n",
    "        second_last_token = self.tokenizer.decode([second_last_token_id])\n",
    "\n",
    "        # Stop if it's a sentence-ending token and not part of an abbreviation\n",
    "        if (\n",
    "            last_token in [\".\", \"!\", \"?\"]  # Check if it's a sentence-ending token\n",
    "            and len(second_last_token) > 1  # Ensure not part of an abbreviation\n",
    "            and not second_last_token.isupper()  # Ensure it's not \"U.S.\" or similar\n",
    "        ):\n",
    "            return True\n",
    "\n",
    "        # Include end-of-sequence token\n",
    "        return last_token_id == self.eos_token_id\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        return self.is_valid_stop(input_ids)\n",
    "\n",
    "\n",
    "sentence_end_tokens = [\".\",\"\\n\",\"!\", \"?\"]\n",
    "stopping_criteria = StoppingCriteriaList([RefinedEndSentenceStoppingCriteria(tokenizer, sentence_end_tokens)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c77de2-c8d2-489e-a4ad-e375f5df8fff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Generate with alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b3bb735-03e5-4475-a260-36926ca2a5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. \n",
      "The tone should be plain and simple! Return the explanation sentence for the following context text: 'Brown was a black teenager without a weapon who was shot by a white police officer. He was killed in August in Ferguson, Missouri, near St. Louis. The shooting set off nearly nightly protests and violence. The black community felt that Brown wouldn't have been killed if he was white.'.\n",
      "### Assistant: The officer was not charged with a crime.\n",
      "Extracted Response: The officer was not charged with a crime.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "example = random.choice(formatted_test_dataset)\n",
    "\n",
    "inputs = tokenizer(\n",
    "    example, #input_text,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512  # Adjust max_length as needed\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=32,  # 32 for elaboration-only generation\n",
    "        min_length=10,\n",
    "        do_sample=False,  # Greedy decoding\n",
    "        temperature=None,  # not used in greedy decoding\n",
    "        top_p=None,  # not used in greedy decoding\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=3,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        stopping_criteria=stopping_criteria\n",
    "    )\n",
    "\n",
    "generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(generated_text)\n",
    "response = extract_response(generated_text)\n",
    "print(\"Extracted Response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7357a1-1764-4a16-bc66-2a0865bc0dae",
   "metadata": {},
   "source": [
    "## Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37f6c412-85de-4d35-bb7f-d3f754eb0a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6df5044b-d2e2-42f5-ac8a-1152449e425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from dataset_utils import create_results_df\n",
    "\n",
    "def extract_response(text, prefix = \"### Assistant:\"):\n",
    "    if prefix in text:\n",
    "        return text.split(prefix, 1)[1].strip()\n",
    "    return None\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.config.use_cache = True\n",
    "\n",
    "sentence_end_tokens = [\".\",\"\\n\",\"!\", \"?\"]\n",
    "stopping_criteria = StoppingCriteriaList([RefinedEndSentenceStoppingCriteria(tokenizer, sentence_end_tokens)])\n",
    "\n",
    "def generate_predictions(dataset, formatted_test_dataset, ds_type, setting, num_examples):\n",
    "\n",
    "    output_name = f\"{ds_type}-{setting}\"\n",
    "    search_type = {\"beam-search\":{\"num_beams\":4, \"early_stopping\":True, \n",
    "                              \"filename\":f\"../data/gen_predictions/predictions_llama-instruct-few-shot-{output_name}-{num_examples}.csv\"},\n",
    "              \"greedy\":{\"num_beams\":1, \"early_stopping\":False,\n",
    "                        \"filename\":f\"../data/gen_predictions/predictions_llama-instruct-few-shot-{output_name}-greedy-{num_examples}.csv\"}\n",
    "    }\n",
    "\n",
    "    for search_t in search_type.keys():\n",
    "    \n",
    "        df_results = create_results_df(dataset)\n",
    "    \n",
    "        for idx, row in tqdm(df_results.iterrows(),total=len(df_results)):\n",
    "            if row[\"pred_elaboration\"]==\"\":\n",
    "                inputs = tokenizer(\n",
    "                    formatted_test_dataset[idx], #input_text,\n",
    "                    return_tensors=\"pt\",\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=2500 # 1024 for short, 2500 for long\n",
    "                ).to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    output_ids = model.generate(\n",
    "                        input_ids=inputs[\"input_ids\"],\n",
    "                        attention_mask=inputs[\"attention_mask\"],\n",
    "                        max_new_tokens=32,  # 32 for elaboration-only generation\n",
    "                        min_length=10,\n",
    "                        do_sample=False, \n",
    "                        temperature=None,  # not used in greedy decoding\n",
    "                        top_p=None,# not used in greedy decoding\n",
    "                        num_beams = search_type[search_t][\"num_beams\"],\n",
    "                        early_stopping = search_type[search_t][\"early_stopping\"],\n",
    "                        num_return_sequences=1,\n",
    "                        no_repeat_ngram_size=3,\n",
    "                        eos_token_id=tokenizer.eos_token_id,\n",
    "                        pad_token_id=tokenizer.eos_token_id,\n",
    "                        stopping_criteria=stopping_criteria\n",
    "                    )\n",
    "                \n",
    "                generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "                response = extract_response(generated_text) #extract_assistant_response(generated_text) -> chatML\n",
    "                df_results.at[idx,\"pred_elaboration\"] = response\n",
    "        \n",
    "        df_results.to_csv(search_type[search_t][\"filename\"], index=False)\n",
    "        print(f\"Saved {search_type[search_t]['filename']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f20b9b-a53c-4dd9-a456-cf58e5272c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dataset_utils import load_dataset_from_csv\n",
    "from prompt_utils import formatting_prompt_func\n",
    "\n",
    "setting_ds_dict = {\n",
    "    \"base\": [\"c2o\",\"c2op\"],\n",
    "    \"masked\": [\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"],\n",
    "    \"target-phrase\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"c2o\",\"c2op\"],\n",
    "    \"target-sent\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"c2o\",\"c2op\"],\n",
    "    \"target-sent-target\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"c2o\",\"c2op\"],\n",
    "}\n",
    "\n",
    "example_num_versions = [\"n3\",\"n6\"]\n",
    "\n",
    "for setting, ds_types in setting_ds_dict.items():\n",
    "    for ds_type in ds_types:\n",
    "        dataset = load_dataset_from_csv(ds_type, setting)\n",
    "        for num_examples in example_num_versions:\n",
    "            formatted_test_dataset = formatting_prompt_func(dataset[\"test\"], setting, num_examples)  \n",
    "            generate_predictions(dataset, formatted_test_dataset, ds_type, setting, num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b046be5-500a-4c97-8325-819c3675067b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: llama-instruct\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.62s/it]\n",
      "Processing setting: base, dataset type: c2o\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2o-base-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2o-base-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2o-base-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2o-base-greedy-n6.csv\n",
      "Processing setting: base, dataset type: c2op\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2op-base-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2op-base-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2op-base-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2op-base-greedy-n6.csv\n",
      "Processing setting: masked, dataset type: c2s\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2s-masked-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2s-masked-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2s-masked-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2s-masked-greedy-n6.csv\n",
      "Processing setting: masked, dataset type: c2sp\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2sp-masked-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2sp-masked-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2sp-masked-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2sp-masked-greedy-n6.csv\n",
      "Processing setting: masked, dataset type: c4s\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4s-masked-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4s-masked-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4s-masked-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4s-masked-greedy-n6.csv\n",
      "Processing setting: masked, dataset type: c4sp\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4sp-masked-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4sp-masked-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4sp-masked-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4sp-masked-greedy-n6.csv\n",
      "Processing setting: target-phrase, dataset type: c2s\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2s-target-phrase-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2s-target-phrase-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2s-target-phrase-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2s-target-phrase-greedy-n6.csv\n",
      "Processing setting: target-phrase, dataset type: c2sp\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2sp-target-phrase-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2sp-target-phrase-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2sp-target-phrase-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2sp-target-phrase-greedy-n6.csv\n",
      "Processing setting: target-phrase, dataset type: c4s\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4s-target-phrase-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4s-target-phrase-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4s-target-phrase-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4s-target-phrase-greedy-n6.csv\n",
      "Processing setting: target-phrase, dataset type: c4sp\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4sp-target-phrase-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4sp-target-phrase-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4sp-target-phrase-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4sp-target-phrase-greedy-n6.csv\n",
      "Processing setting: target-phrase, dataset type: c2o\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2o-target-phrase-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2o-target-phrase-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2o-target-phrase-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2o-target-phrase-greedy-n6.csv\n",
      "Processing setting: target-phrase, dataset type: c2op\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2op-target-phrase-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2op-target-phrase-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2op-target-phrase-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2op-target-phrase-greedy-n6.csv\n",
      "Processing setting: target-sent, dataset type: c2s\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2s-target-sent-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2s-target-sent-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2s-target-sent-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2s-target-sent-greedy-n6.csv\n",
      "Processing setting: target-sent, dataset type: c2sp\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2sp-target-sent-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2sp-target-sent-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2sp-target-sent-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2sp-target-sent-greedy-n6.csv\n",
      "Processing setting: target-sent, dataset type: c4s\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4s-target-sent-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4s-target-sent-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4s-target-sent-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4s-target-sent-greedy-n6.csv\n",
      "Processing setting: target-sent, dataset type: c4sp\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4sp-target-sent-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4sp-target-sent-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4sp-target-sent-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4sp-target-sent-greedy-n6.csv\n",
      "Processing setting: target-sent, dataset type: c2o\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2o-target-sent-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2o-target-sent-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2o-target-sent-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2o-target-sent-greedy-n6.csv\n",
      "Processing setting: target-sent, dataset type: c2op\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2op-target-sent-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2op-target-sent-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2op-target-sent-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2op-target-sent-greedy-n6.csv\n",
      "Processing setting: target-sent-target, dataset type: c2s\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2s-target-sent-target-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2s-target-sent-target-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2s-target-sent-target-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2s-target-sent-target-greedy-n6.csv\n",
      "Processing setting: target-sent-target, dataset type: c2sp\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2sp-target-sent-target-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2sp-target-sent-target-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2sp-target-sent-target-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2sp-target-sent-target-greedy-n6.csv\n",
      "Processing setting: target-sent-target, dataset type: c4s\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4s-target-sent-target-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4s-target-sent-target-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4s-target-sent-target-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4s-target-sent-target-greedy-n6.csv\n",
      "Processing setting: target-sent-target, dataset type: c4sp\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4sp-target-sent-target-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4sp-target-sent-target-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4sp-target-sent-target-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c4sp-target-sent-target-greedy-n6.csv\n",
      "Processing setting: target-sent-target, dataset type: c2o\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2o-target-sent-target-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2o-target-sent-target-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2o-target-sent-target-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2o-target-sent-target-greedy-n6.csv\n",
      "Processing setting: target-sent-target, dataset type: c2op\n",
      "Formatting prompts with n3 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2op-target-sent-target-n3.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2op-target-sent-target-greedy-n3.csv\n",
      "Formatting prompts with n6 examples.\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2op-target-sent-target-n6.csv\n",
      "  0%|          | 0/116 [00:00<?, ?it/s]\n",
      "Saved ../data/gen_predictions/predictions_llama-instruct-few-shot-c2op-target-sent-target-greedy-n6.csv\n"
     ]
    }
   ],
   "source": [
    "!python generate_elaborations.py --model llama-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b3ce1e-f357-4678-b7ed-3b4683108b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
