{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3f68764-bac7-43e7-b702-aa1978735aeb",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea470e18-5094-4658-9101-f72635abe43c",
   "metadata": {},
   "source": [
    "## Original BART-SWiPE model (full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0f4219-e98c-4e3b-a708-26e3de2d791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, BartTokenizerFast\n",
    "\n",
    "# tokenizer_orig = AutoTokenizer.from_pretrained(\"Salesforce/bart-large-swipe\")\n",
    "tokenizer_ft = BartTokenizerFast.from_pretrained('facebook/bart-large') #use_fast = True)\n",
    "model_orig = AutoModelForSeq2SeqLM.from_pretrained(\"Salesforce/bart-large-swipe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55ce61e-afed-4280-9fff-963f81e92197",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Original BART-SWiPE-clean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f8ac152-4467-4d38-bd89-506a84f59153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, BartTokenizerFast\n",
    "\n",
    "tokenizer_ft = BartTokenizerFast.from_pretrained('facebook/bart-large') # , use_fast=True)\n",
    "#tokenizer_orig_clean = AutoTokenizer.from_pretrained(\"Salesforce/bart-large-swipe-clean\")\n",
    "model_orig_clean = AutoModelForSeq2SeqLM.from_pretrained(\"Salesforce/bart-large-swipe-clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b301e41-e956-4787-82da-55680a4f61cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Fine-tuned BART model (swipe-full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "352437e4-4231-466d-962c-660a4e949b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer, GenerationConfig\n",
    "\n",
    "# saved model\n",
    "model_ft_full = BartForConditionalGeneration.from_pretrained(\"../models/bart-swipe-ft/model-swipe-full\")\n",
    "# tokenizer\n",
    "tokenizer_ft_full = BartTokenizer.from_pretrained('facebook/bart-large')\n",
    "# generation config\n",
    "generation_config = GenerationConfig.from_pretrained(\"../models/bart-swipe-ft/model-swipe-full\")\n",
    "model_ft_full.generation_config = generation_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1841304-9d9c-4cdd-97f6-7c54c61a8905",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Fine-tuned BART model (swipe-cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f53eac6-25cf-43b4-a348-0ee7a0126c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizerFast, GenerationConfig, BartTokenizer\n",
    "\n",
    "# saved model\n",
    "model_ft = BartForConditionalGeneration.from_pretrained(\"../models/bart-swipe-ft/model-swipe-clean-bart-tokenizer-512\")\n",
    "# tokenizer\n",
    "tokenizer_ft = BartTokenizer.from_pretrained('facebook/bart-large', use_fast=True)\n",
    "# generation config\n",
    "generation_config = GenerationConfig.from_pretrained(\"../models/bart-swipe-ft/model-swipe-clean-bart-tokenizer-512\")\n",
    "model_ft.generation_config = generation_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef76449-d9b4-4e2c-9280-b5c8b34acb89",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d56d501-b42b-43d8-b922-19decf4fbfd9",
   "metadata": {},
   "source": [
    "## SWiPE - clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b93dcab0-e59c-447d-b2cd-b4fd774befe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, DatasetDict\n",
    "import pandas as pd\n",
    "\n",
    "swipe_clean_dataset = load_from_disk(\"../data/swipe_clean\")\n",
    "swipe_clean_dataset = DatasetDict({\n",
    "    'test': swipe_clean_dataset['test_id']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38325ef0-6b57-4474-a0fb-b901ffaeeffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['r_content', 's_content'],\n",
       "        num_rows: 483\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swipe_clean_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5160aba6-3bbf-43ac-a902-f4a69cad6919",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ASSET - test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df30397a-b932-4b36-a427-30b3ef9e6616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['original', 'simplifications'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['original', 'simplifications'],\n",
       "        num_rows: 359\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "asset_dataset = load_dataset(\"facebook/asset\", \"simplification\")\n",
    "asset_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b492b3b5-eaef-467b-91f6-9f908a7b1ff4",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a289e479-d5af-4fbc-b5ac-d4e87f46dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_ft\n",
    "model = model_orig\n",
    "dataset = swipe_clean_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05317b5d-c1ca-4c22-b111-1277d7106915",
   "metadata": {},
   "source": [
    "## Tokenizer adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab50c0b6-2573-4d0c-ab39-e14764373120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AddedToken\n",
    "\n",
    "special_tokens_dict = {\n",
    "    'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
    "    'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True)\n",
    "}\n",
    "\n",
    "# add the special tokens to the tokenizer\n",
    "tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b6023e-d81d-4837-b46a-ce7072555f2d",
   "metadata": {},
   "source": [
    "## SWiPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53294b56-53f2-4bc7-9bd6-0adc79afe1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 483/483 [03:13<00:00,  2.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "predictions = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for example in tqdm(dataset['test']):\n",
    "    # tokenize the text\n",
    "    input_ids = tokenizer(example['r_content'], return_tensors=\"pt\") # , truncation=True, padding=\"max_length\", max_length=512)\n",
    "    # move input_ids to the same device as the model\n",
    "    input_ids = {key: value.to(device) for key, value in input_ids.items()}\n",
    "    \n",
    "    # generate prediction\n",
    "    output_ids = model.generate(**input_ids, max_length=200, temperature=1.5, num_beams=4, num_return_sequences=1, do_sample=True) # ,max_length = 512, min_length=50, length_penalty=1.0) \n",
    "    simplified_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    predictions.append(simplified_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17398dac-c3b6-497e-9440-f6cf77281313",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ASSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "76563783-54bb-47f2-8a9b-9f10bd11d044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 359/359 [01:27<00:00,  4.12it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "predictions = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for example in tqdm(dataset['test']):\n",
    "    # tokenize the text\n",
    "    input_ids = tokenizer(example['original'], return_tensors=\"pt\") # , truncation=True, padding=\"max_length\", max_length=512)\n",
    "    # move input_ids to the same device as the model\n",
    "    input_ids = {key: value.to(device) for key, value in input_ids.items()}\n",
    "    \n",
    "    # generate prediction\n",
    "    output_ids = model.generate(**input_ids, max_length=200, temperature=1.5, num_beams=5, num_return_sequences=1, do_sample=True) # ,max_length = 512, min_length=50, length_penalty=1.0) \n",
    "    simplified_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    predictions.append(simplified_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f683e11-34c3-4eb7-aa8c-d73011360077",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b12af602-5958-411c-9e71-65fdcbf1891c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The term jargon may have the following meaning...</td>\n",
       "      <td>Jargon is a word that can mean many different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Russian (Russkij yazyk, Русский язык) is the m...</td>\n",
       "      <td>Russian (Russkij yazyk, Русский язык) is the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great Britain, also called Britain, is an isla...</td>\n",
       "      <td>Great Britain, also called Britain, is an isla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transport, or transportation (as it is called ...</td>\n",
       "      <td>Transport, or transportation (as it is called ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stockholm (help·info) (IPA: ['stɔkhɔlm]; UN/LO...</td>\n",
       "      <td>Stockholm is the capital city of Sweden. It is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  The term jargon may have the following meaning...   \n",
       "1  Russian (Russkij yazyk, Русский язык) is the m...   \n",
       "2  Great Britain, also called Britain, is an isla...   \n",
       "3  Transport, or transportation (as it is called ...   \n",
       "4  Stockholm (help·info) (IPA: ['stɔkhɔlm]; UN/LO...   \n",
       "\n",
       "                                          prediction  \n",
       "0  Jargon is a word that can mean many different ...  \n",
       "1  Russian (Russkij yazyk, Русский язык) is the m...  \n",
       "2  Great Britain, also called Britain, is an isla...  \n",
       "3  Transport, or transportation (as it is called ...  \n",
       "4  Stockholm is the capital city of Sweden. It is...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# r_content for Swipe\n",
    "# original for ASSET\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'text': dataset['test']['r_content'], \n",
    "    'prediction': predictions\n",
    "})\n",
    "\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc480f3b-128a-4f67-bfb5-4ddf59faa731",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc9ff033-8081-41e4-be47-4fa243875463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"../data/gen_predictions/predictions_bart-large-swipe-bart-tokenizer-fast-adjust-num-beams4-no-use-fast!_swipe-clean-test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
