{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a2be0bc-d97f-4c46-9a67-919c1c7c936b",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b2e70ca-6f23-4931-9222-5bf9440f5de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"llama-ft\",\"bart-ft\",\"llama-instruct-few-shot\"]\n",
    "\n",
    "setting_ds_dict = {\n",
    "    \"base\": [\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"cs\",\"c2spo\",\"c4spo\",\"cso\"],\n",
    "    \"masked\": [\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"],\n",
    "    \"subject\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"c2spo\",\"c4spo\"],\n",
    "    \"target-phrase\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"c2spo\",\"c4spo\"],\n",
    "    \"target-sent\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"c2spo\",\"c4spo\"],\n",
    "    \"target-sent-target\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"cs\",\"cso\",\"c2spo\",\"c4spo\"],\n",
    "    \"target-sent-subject\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"cs\",\"cso\",\"c2spo\",\"c4spo\"],\n",
    "}\n",
    "\n",
    "# for results inspection\n",
    "results_setting_ds_dict = {\n",
    "    \"base\": [\"cs\",\"c4s\"],\n",
    "    \"subject\":[\"c4s\"],\n",
    "    \"target-phrase\":[\"c4s\"],\n",
    "    \"target-sent\":[\"c4s\"],\n",
    "    \"target-sent-target\":[\"c4sp\"],\n",
    "    \"target-sent-subject\":[\"c2sp\",\"c4spo\"],\n",
    "}\n",
    "\n",
    "# additional calculation\n",
    "setting_ds_dict = {\n",
    "    \"base\": [\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"c2o\",\"c2op\"],\n",
    "    \"masked\": [\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"],\n",
    "    \"target-phrase\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"c2o\",\"c2op\"],\n",
    "    \"target-sent\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"c2o\",\"c2op\"],\n",
    "    \"target-sent-target\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"c2o\",\"c2op\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc34bc-1708-4887-9218-72243a75d666",
   "metadata": {},
   "source": [
    "# Load results df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c46aecf4-8edb-4071-8644-2f0d40b7b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bart_ft_res = pd.read_csv(\"../data/results/bart-ft-results.csv\")\n",
    "llama_ft_res = pd.read_csv(\"../data/results/llama-ft-results.csv\")\n",
    "llama_instr_res = pd.read_csv(\"../data/results/llama-instruct-few-shot-results.csv\")\n",
    "llama_instr_prompt_res = pd.read_csv(\"../data/results/llama-instruct-few-shot-prompt-results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9292df4c-a74c-4b57-8947-42cde012e562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dataset', 'base-b1', 'base-b2', 'masked-b1', 'masked-b2', 'subject-b1',\n",
       "       'subject-b2', 'target-phrase-b1', 'target-phrase-b2', 'target-sent-b1',\n",
       "       'target-sent-b2', 'target-sent-target-b1', 'target-sent-target-b2',\n",
       "       'target-sent-subject-b1', 'target-sent-subject-b2', 'base-bsprec',\n",
       "       'masked-bsprec', 'subject-bsprec', 'target-phrase-bsprec',\n",
       "       'target-sent-bsprec', 'target-sent-target-bsprec',\n",
       "       'target-sent-subject-bsprec', 'base-bsrec', 'masked-bsrec',\n",
       "       'subject-bsrec', 'target-phrase-bsrec', 'target-sent-bsrec',\n",
       "       'target-sent-target-bsrec', 'target-sent-subject-bsrec', 'base-bsf1',\n",
       "       'masked-bsf1', 'subject-bsf1', 'target-phrase-bsf1', 'target-sent-bsf1',\n",
       "       'target-sent-target-bsf1', 'target-sent-subject-bsf1', 'base-bartscore',\n",
       "       'masked-bartscore', 'subject-bartscore', 'target-phrase-bartscore',\n",
       "       'target-sent-bartscore', 'target-sent-target-bartscore',\n",
       "       'target-sent-subject-bartscore'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_instr_res.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb11724e-fb2e-46ae-8975-b7d0d6010d34",
   "metadata": {},
   "source": [
    "# Initialize columns in results dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cfebfd-0147-41f5-b5bf-fcbe304930cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "439234a1-51ef-4105-8be3-defc589f27f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>base-b1</th>\n",
       "      <th>base-b2</th>\n",
       "      <th>masked-b1</th>\n",
       "      <th>masked-b2</th>\n",
       "      <th>subject-b1</th>\n",
       "      <th>subject-b2</th>\n",
       "      <th>target-phrase-b1</th>\n",
       "      <th>target-phrase-b2</th>\n",
       "      <th>target-sent-b1</th>\n",
       "      <th>...</th>\n",
       "      <th>target-sent-bs-rec</th>\n",
       "      <th>target-sent-target-bs-rec</th>\n",
       "      <th>target-sent-subject-bs-rec</th>\n",
       "      <th>base-bs-f1</th>\n",
       "      <th>masked-bs-f1</th>\n",
       "      <th>subject-bs-f1</th>\n",
       "      <th>target-phrase-bs-f1</th>\n",
       "      <th>target-sent-bs-f1</th>\n",
       "      <th>target-sent-target-bs-f1</th>\n",
       "      <th>target-sent-subject-bs-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c2s</td>\n",
       "      <td>15.899</td>\n",
       "      <td>3.588</td>\n",
       "      <td>15.258</td>\n",
       "      <td>3.309</td>\n",
       "      <td>22.277</td>\n",
       "      <td>8.939</td>\n",
       "      <td>18.347</td>\n",
       "      <td>5.923</td>\n",
       "      <td>17.417</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c2sp</td>\n",
       "      <td>15.266</td>\n",
       "      <td>3.515</td>\n",
       "      <td>15.757</td>\n",
       "      <td>3.567</td>\n",
       "      <td>23.580</td>\n",
       "      <td>9.417</td>\n",
       "      <td>18.686</td>\n",
       "      <td>5.726</td>\n",
       "      <td>18.003</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c4s</td>\n",
       "      <td>15.712</td>\n",
       "      <td>2.912</td>\n",
       "      <td>14.908</td>\n",
       "      <td>4.157</td>\n",
       "      <td>22.771</td>\n",
       "      <td>8.681</td>\n",
       "      <td>17.560</td>\n",
       "      <td>5.348</td>\n",
       "      <td>18.005</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c4sp</td>\n",
       "      <td>15.233</td>\n",
       "      <td>1.652</td>\n",
       "      <td>16.923</td>\n",
       "      <td>4.930</td>\n",
       "      <td>23.323</td>\n",
       "      <td>9.918</td>\n",
       "      <td>18.652</td>\n",
       "      <td>5.758</td>\n",
       "      <td>16.861</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs</td>\n",
       "      <td>19.650</td>\n",
       "      <td>6.692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c2spo</td>\n",
       "      <td>13.904</td>\n",
       "      <td>2.192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c4spo</td>\n",
       "      <td>13.147</td>\n",
       "      <td>1.519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  base-b1  base-b2  masked-b1  masked-b2  subject-b1  subject-b2  \\\n",
       "0     c2s   15.899    3.588     15.258      3.309      22.277       8.939   \n",
       "1    c2sp   15.266    3.515     15.757      3.567      23.580       9.417   \n",
       "2     c4s   15.712    2.912     14.908      4.157      22.771       8.681   \n",
       "3    c4sp   15.233    1.652     16.923      4.930      23.323       9.918   \n",
       "4      cs   19.650    6.692        NaN        NaN         NaN         NaN   \n",
       "5   c2spo   13.904    2.192        NaN        NaN         NaN         NaN   \n",
       "6   c4spo   13.147    1.519        NaN        NaN         NaN         NaN   \n",
       "\n",
       "   target-phrase-b1  target-phrase-b2  target-sent-b1  ...  \\\n",
       "0            18.347             5.923          17.417  ...   \n",
       "1            18.686             5.726          18.003  ...   \n",
       "2            17.560             5.348          18.005  ...   \n",
       "3            18.652             5.758          16.861  ...   \n",
       "4               NaN               NaN             NaN  ...   \n",
       "5               NaN               NaN             NaN  ...   \n",
       "6               NaN               NaN             NaN  ...   \n",
       "\n",
       "   target-sent-bs-rec  target-sent-target-bs-rec  target-sent-subject-bs-rec  \\\n",
       "0                None                       None                        None   \n",
       "1                None                       None                        None   \n",
       "2                None                       None                        None   \n",
       "3                None                       None                        None   \n",
       "4                None                       None                        None   \n",
       "5                None                       None                        None   \n",
       "6                None                       None                        None   \n",
       "\n",
       "   base-bs-f1  masked-bs-f1 subject-bs-f1 target-phrase-bs-f1  \\\n",
       "0        None          None          None                None   \n",
       "1        None          None          None                None   \n",
       "2        None          None          None                None   \n",
       "3        None          None          None                None   \n",
       "4        None          None          None                None   \n",
       "5        None          None          None                None   \n",
       "6        None          None          None                None   \n",
       "\n",
       "  target-sent-bs-f1 target-sent-target-bs-f1 target-sent-subject-bs-f1  \n",
       "0              None                     None                      None  \n",
       "1              None                     None                      None  \n",
       "2              None                     None                      None  \n",
       "3              None                     None                      None  \n",
       "4              None                     None                      None  \n",
       "5              None                     None                      None  \n",
       "6              None                     None                      None  \n",
       "\n",
       "[7 rows x 36 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = pd.read_csv(f\"../data/results/{model}-results.csv\")\n",
    "settings = list(dict.fromkeys([\"-\".join(col.split(\"-\")[:-1]) for col in df_res.columns if \"-\" in col]))\n",
    "cols_to_add = [f\"{col_name}-bs-prec\" for col_name in settings] + \\\n",
    "              [f\"{col_name}-bs-rec\" for col_name in settings] + \\\n",
    "              [f\"{col_name}-bs-f1\" for col_name in settings]\n",
    "for col in cols_to_add:\n",
    "    df_res[col] = None \n",
    "\n",
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224bf50f-ee93-4a57-859f-005911f22bca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## BARTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "137228e8-9392-4815-9439-a8b7e9968269",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama-ft\"#\"llama-instruct-few-shot\"\n",
    "df_res = pd.read_csv(f\"data/results/{model}-results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22f048c0-d472-4431-a36f-baaff602b058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dataset', 'base-b1', 'base-b2', 'masked-b1', 'masked-b2', 'subject-b1',\n",
      "       'subject-b2', 'target-phrase-b1', 'target-phrase-b2', 'target-sent-b1',\n",
      "       'target-sent-b2', 'target-sent-target-b1', 'target-sent-target-b2',\n",
      "       'target-sent-subject-b1', 'target-sent-subject-b2', 'base-bsprec',\n",
      "       'masked-bsprec', 'subject-bsprec', 'target-phrase-bsprec',\n",
      "       'target-sent-bsprec', 'target-sent-target-bsprec',\n",
      "       'target-sent-subject-bsprec', 'base-bsrec', 'masked-bsrec',\n",
      "       'subject-bsrec', 'target-phrase-bsrec', 'target-sent-bsrec',\n",
      "       'target-sent-target-bsrec', 'target-sent-subject-bsrec', 'base-bsf1',\n",
      "       'masked-bsf1', 'subject-bsf1', 'target-phrase-bsf1', 'target-sent-bsf1',\n",
      "       'target-sent-target-bsf1', 'target-sent-subject-bsf1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# rename certain columns\n",
    "df_res.columns = [\n",
    "    col.replace('-bs-rec', '-bsrec').replace('-bs-prec', '-bsprec').replace('-bs-f1', '-bsf1')\n",
    "    if col.endswith(('-bs-rec', '-bs-prec', '-bs-f1')) else col\n",
    "    for col in df_res.columns\n",
    "]\n",
    "\n",
    "print(df_res.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67beec04-6164-42b9-bcc8-ed134bf8bfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['base', 'masked', 'subject', 'target-phrase', 'target-sent', 'target-sent-target', 'target-sent-subject']\n",
      "\n",
      "Index(['dataset', 'base-b1', 'base-b2', 'masked-b1', 'masked-b2', 'subject-b1',\n",
      "       'subject-b2', 'target-phrase-b1', 'target-phrase-b2', 'target-sent-b1',\n",
      "       'target-sent-b2', 'target-sent-target-b1', 'target-sent-target-b2',\n",
      "       'target-sent-subject-b1', 'target-sent-subject-b2', 'base-bsprec',\n",
      "       'masked-bsprec', 'subject-bsprec', 'target-phrase-bsprec',\n",
      "       'target-sent-bsprec', 'target-sent-target-bsprec',\n",
      "       'target-sent-subject-bsprec', 'base-bsrec', 'masked-bsrec',\n",
      "       'subject-bsrec', 'target-phrase-bsrec', 'target-sent-bsrec',\n",
      "       'target-sent-target-bsrec', 'target-sent-subject-bsrec', 'base-bsf1',\n",
      "       'masked-bsf1', 'subject-bsf1', 'target-phrase-bsf1', 'target-sent-bsf1',\n",
      "       'target-sent-target-bsf1', 'target-sent-subject-bsf1', 'base-bartscore',\n",
      "       'masked-bartscore', 'subject-bartscore', 'target-phrase-bartscore',\n",
      "       'target-sent-bartscore', 'target-sent-target-bartscore',\n",
      "       'target-sent-subject-bartscore'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "settings = list(dict.fromkeys([\"-\".join(col.split(\"-\")[:-1]) for col in df_res.columns if \"-\" in col]))\n",
    "print(settings, end=\"\\n\\n\")\n",
    "cols_to_add = [f\"{col_name}-bartscore\" for col_name in settings]\n",
    "for col in cols_to_add:\n",
    "    df_res[col] = None\n",
    "print(df_res.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ae5b4-331b-4df6-af1f-7eeb95d675cd",
   "metadata": {},
   "source": [
    "## Add/delete dataset row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b84a276-1a0c-4df7-9763-9a2c7ea05d09",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Add "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c61803c1-7b43-42c2-9b0b-ffccb11a14fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for model in models: \n",
    "    df_res = pd.read_csv(f\"../data/results/{model}-results.csv\")\n",
    "    df_res.loc[len(df_res), 'dataset'] = 'c2o'\n",
    "    df_res.to_csv(f\"../data/results/{model}-results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32e510b-f9e6-4492-994b-49e22ca3060e",
   "metadata": {},
   "source": [
    "### Del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21298926-bd21-4f52-a1f6-6f3eaa65bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models: \n",
    "    df_res = pd.read_csv(f\"../data/results/{model}-results.csv\")\n",
    "    df_res = df_res[df_res['dataset'] != 'cso']\n",
    "    df_res.to_csv(f\"../data/results/{model}-results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bfda7c-fed9-427f-b759-2ade351aa2ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Delete columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a16362-9708-4cbd-aa50-8563f59a8623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def delete_columns_with_substrings(df, substrings):\n",
    "    columns_to_keep = [\n",
    "        col for col in df.columns if not any(substring in col for substring in substrings)\n",
    "    ]\n",
    "    return df[columns_to_keep]\n",
    "\n",
    "model = \"llama-instruct-few-shot\"\n",
    "df_res = pd.read_csv(f\"../data/results/{model}-results.csv\")\n",
    "filtered_df = delete_columns_with_substrings(df_res, substrings=[\"\"])    \n",
    "    #df_res.to_csv(f\"../data/results/{model}-results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b13ee6-504f-43ce-a3b2-1fbeb98705e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Map values for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23aec249-1216-4be3-baf8-7060defed26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models: \n",
    "    df_res = pd.read_csv(f\"../data/results/{model}-results.csv\")\n",
    "    dss = [\"cso\",\"cs\"]\n",
    "    settings_map = {\"target-sent-subject\":\"subject\",\"target-sent-target\":\"target-phrase\", \"base\":\"target-sent\"}\n",
    "    for ds in dss:\n",
    "        idx = df_res.index[df_res[\"dataset\"] == ds].tolist()[0]\n",
    "        for current_setting_key, target_setting_key in settings_map.items():\n",
    "            df_res.at[idx, f\"{target_setting_key}-b1\"] = df_res.loc[idx, f\"{current_setting_key}-b1\"]\n",
    "            df_res.at[idx, f\"{target_setting_key}-b2\"] = df_res.loc[idx, f\"{current_setting_key}-b2\"]\n",
    "            df_res.at[idx, f\"{target_setting_key}-bsprec\"] = df_res.loc[idx, f\"{current_setting_key}-bsprec\"]\n",
    "            df_res.at[idx, f\"{target_setting_key}-bsrec\"] = df_res.loc[idx, f\"{current_setting_key}-bsrec\"]\n",
    "            df_res.at[idx, f\"{target_setting_key}-bsf1\"] = df_res.loc[idx, f\"{current_setting_key}-bsf1\"]\n",
    "            df_res.at[idx, f\"{target_setting_key}-bartscore\"] = df_res.loc[idx, f\"{current_setting_key}-bartscore\"]\n",
    "    df_res.to_csv(f\"../data/results/{model}-results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a721dc-ab96-4a59-b2e4-83675cf82cec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Rename datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f815cef4-4eaf-460c-9e13-b52e165cbb24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed: predictions_bart-c4s-target-sent-subject.csv -> predictions_bart-ft-c4s-target-sent-subject.csv\n",
      "Renamed: predictions_bart-c2spo-base.csv -> predictions_bart-ft-c2spo-base.csv\n",
      "Renamed: predictions_bart-c2sp-subject.csv -> predictions_bart-ft-c2sp-subject.csv\n",
      "Renamed: predictions_bart-c4sp-target-sent-subject.csv -> predictions_bart-ft-c4sp-target-sent-subject.csv\n",
      "Renamed: predictions_bart-c4sp-subject.csv -> predictions_bart-ft-c4sp-subject.csv\n",
      "Renamed: predictions_bart-test.csv -> predictions_bart-ft-test.csv\n",
      "Renamed: predictions_bart-c2sp-target-sent-target.csv -> predictions_bart-ft-c2sp-target-sent-target.csv\n",
      "Renamed: predictions_bart-c2sp-target-sent-subject.csv -> predictions_bart-ft-c2sp-target-sent-subject.csv\n",
      "Renamed: predictions_bart-c2s-target-phrase.csv -> predictions_bart-ft-c2s-target-phrase.csv\n",
      "Renamed: predictions_bart-c2sp-base.csv -> predictions_bart-ft-c2sp-base.csv\n",
      "Renamed: predictions_bart-c2sp-masked.csv -> predictions_bart-ft-c2sp-masked.csv\n",
      "Renamed: predictions_bart-c2s-target-sent.csv -> predictions_bart-ft-c2s-target-sent.csv\n",
      "Renamed: predictions_bart-c2sp-target-phrase.csv -> predictions_bart-ft-c2sp-target-phrase.csv\n",
      "Renamed: predictions_bart-cs-target-sent-target.csv -> predictions_bart-ft-cs-target-sent-target.csv\n",
      "Renamed: predictions_bart-c4spo-base.csv -> predictions_bart-ft-c4spo-base.csv\n",
      "Renamed: predictions_bart-c2s-base.csv -> predictions_bart-ft-c2s-base.csv\n",
      "Renamed: predictions_bart-c4sp-base.csv -> predictions_bart-ft-c4sp-base.csv\n",
      "Renamed: predictions_bart-c4s-masked.csv -> predictions_bart-ft-c4s-masked.csv\n",
      "Renamed: predictions_bart-c2s-target-sent-subject.csv -> predictions_bart-ft-c2s-target-sent-subject.csv\n",
      "Renamed: predictions_bart-c4s-target-sent-target.csv -> predictions_bart-ft-c4s-target-sent-target.csv\n",
      "Renamed: predictions_bart-c4sp-target-sent.csv -> predictions_bart-ft-c4sp-target-sent.csv\n",
      "Renamed: predictions_bart-c2s-target-sent-target.csv -> predictions_bart-ft-c2s-target-sent-target.csv\n",
      "Renamed: predictions_bart-c4sp-target-phrase.csv -> predictions_bart-ft-c4sp-target-phrase.csv\n",
      "Renamed: predictions_bart-c2sp-target-sent.csv -> predictions_bart-ft-c2sp-target-sent.csv\n",
      "Renamed: predictions_bart-c4sp-masked.csv -> predictions_bart-ft-c4sp-masked.csv\n",
      "Renamed: predictions_bart-c4s-base.csv -> predictions_bart-ft-c4s-base.csv\n",
      "Renamed: predictions_bart-c4s-target-phrase.csv -> predictions_bart-ft-c4s-target-phrase.csv\n",
      "Renamed: predictions_bart-c4s-target-sent.csv -> predictions_bart-ft-c4s-target-sent.csv\n",
      "Renamed: predictions_bart-c4s-subject.csv -> predictions_bart-ft-c4s-subject.csv\n",
      "Renamed: predictions_bart-c4sp-target-sent-target.csv -> predictions_bart-ft-c4sp-target-sent-target.csv\n",
      "Renamed: predictions_bart-cs-base.csv -> predictions_bart-ft-cs-base.csv\n",
      "Renamed: predictions_bart-cs-target-sent-subject.csv -> predictions_bart-ft-cs-target-sent-subject.csv\n",
      "Renamed: predictions_bart-c2s-subject.csv -> predictions_bart-ft-c2s-subject.csv\n",
      "Renamed: predictions_bart-c2s-masked.csv -> predictions_bart-ft-c2s-masked.csv\n"
     ]
    }
   ],
   "source": [
    "# rename files\n",
    "import os\n",
    "\n",
    "directory = \"data/gen_predictions\"\n",
    "\n",
    "old_part = \"predictions_bart-\"\n",
    "new_part = \"predictions_bart-ft-\"\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "\n",
    "    if old_part in filename:\n",
    "        # new filename by replacing the old part\n",
    "        new_filename = filename.replace(old_part, new_part)\n",
    "        \n",
    "        # full paths for renaming\n",
    "        old_file_path = os.path.join(directory, filename)\n",
    "        new_file_path = os.path.join(directory, new_filename)\n",
    "        \n",
    "        # rename the file\n",
    "        os.rename(old_file_path, new_file_path)\n",
    "        print(f\"Renamed: {filename} -> {new_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10110f52-275c-410d-9a66-5b1eff822fd9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SARI - Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf6017c1-5cc3-4970-9b74-959d1f8884c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d7b27ee24e4e3785eb09aae20a09ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evaluate import load\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "sari_metric = load(\"sari\")\n",
    "sari_scores = []\n",
    "\n",
    "for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "    r_content = row['text'] \n",
    "    s_content = dataset['test'][index] \n",
    "    prediction = row['prediction']  \n",
    "    \n",
    "    sari_score = sari_metric.compute(\n",
    "        sources=[r_content],\n",
    "        predictions=[prediction],\n",
    "        references=[s_content['simplifications']]\n",
    "    )\n",
    "    \n",
    "    sari_scores.append(sari_score['sari'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0344dde9-0b12-448a-880c-9e82df722695",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SARI - EASSE package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21c93079-9b0a-45f4-8446-d83fad341431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fe8728a5b84524acb2902f9f54b345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'label_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/nlp/lib64/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m tqdm(df_gen\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(df_gen)):\n\u001b[1;32m      8\u001b[0m     r_content \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[0;32m----> 9\u001b[0m     s_content \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m  \n\u001b[1;32m     10\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m]  \n\u001b[1;32m     12\u001b[0m     sari_score_easse \u001b[38;5;241m=\u001b[39m corpus_sari(\n\u001b[1;32m     13\u001b[0m         orig_sents\u001b[38;5;241m=\u001b[39m[r_content],\n\u001b[1;32m     14\u001b[0m         sys_sents\u001b[38;5;241m=\u001b[39m[prediction],\n\u001b[1;32m     15\u001b[0m         refs_sents\u001b[38;5;241m=\u001b[39m[[s_content]]\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m#refs_sents=[[simp] for simp in s_content['simplifications']]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     )\n",
      "File \u001b[0;32m~/nlp/lib64/python3.9/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/nlp/lib64/python3.9/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/nlp/lib64/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label_text'"
     ]
    }
   ],
   "source": [
    "from easse.sari import corpus_sari\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "sari_scores_easse = []\n",
    "\n",
    "for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "    r_content = row['source_text'] \n",
    "    s_content = row['label_text']  \n",
    "    prediction = row['prediction']  \n",
    "    \n",
    "    sari_score_easse = corpus_sari(\n",
    "        orig_sents=[r_content],\n",
    "        sys_sents=[prediction],\n",
    "        refs_sents=[[s_content]]\n",
    "        #refs_sents=[[simp] for simp in s_content['simplifications']]\n",
    "    )\n",
    "    \n",
    "    sari_scores_easse.append(sari_score_easse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2a4dc924-dcdf-4996-a704-bc8fa62f053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SARI score: 36.46781896155372\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Average SARI score:\", np.mean(sari_scores_easse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48b68e-8dad-4ca5-a0f4-3059c107d5c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Operation scores (add, keep, delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebda0d28-3b07-4479-810f-4f321c9ed5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f328a3975ef64892b8a5039c8e60ccbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from easse.sari import get_corpus_sari_operation_scores\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "add_scores = []\n",
    "keep_scores = []\n",
    "del_scores = []\n",
    "\n",
    "for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "    r_content = row['source_text'] \n",
    "    s_content = row['label_text'] #dataset['test'][index]  \n",
    "    prediction = row['prediction']  \n",
    "    \n",
    "    add_score, keep_score, del_score = get_corpus_sari_operation_scores(\n",
    "        orig_sents=[r_content],\n",
    "        sys_sents=[prediction],\n",
    "        refs_sents=[[s_content]]\n",
    "        #refs_sents=[[simp] for simp in s_content['simplifications']] \n",
    "    )\n",
    "    \n",
    "    add_scores.append(add_score)\n",
    "    keep_scores.append(keep_score)\n",
    "    del_scores.append(del_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb0cbf1-18d1-4243-8d97-1a6da6cc55aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# BLEU-4 (EASSE package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0422bbeb-5d1b-4060-abd5-e14a5a0f5789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfa32888f4f4039acffa9021cc37531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score: 4.965\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from easse.bleu import corpus_bleu\n",
    "import numpy as np\n",
    "\n",
    "bleu_scores_easse = []\n",
    "\n",
    "for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "    s_content = row['elaboration_sentence'] \n",
    "    prediction = row['pred_elaboration'] # \"prediction\" for BART\n",
    "    \n",
    "    bleu_score_easse = corpus_bleu(\n",
    "        sys_sents=[prediction],\n",
    "        refs_sents=[[s_content]]\n",
    "    )\n",
    "    \n",
    "    bleu_scores_easse.append(bleu_score_easse)\n",
    "\n",
    "print(f\"Average BLEU score: {np.mean(bleu_scores_easse):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423467a1-bd5b-45a5-9c81-c4cca2be66b9",
   "metadata": {},
   "source": [
    "# BLEU-1 & BLEU-2 (nltk + tokenizer-13A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7021e9d-90fa-4477-9c0d-ca7d046ef283",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Corpus bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db64be6b-4a29-444a-8fd6-1fc8e9f1f940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 116/116 [00:00<00:00, 10129.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2s-base-n6: 16.284\n",
      "llama-instruct-few-shot-c2s-base-n6: 5.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 116/116 [00:00<00:00, 16714.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2sp-base-n6: 16.451\n",
      "llama-instruct-few-shot-c2sp-base-n6: 5.631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 116/116 [00:00<00:00, 9579.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4s-base-n6: 15.158\n",
      "llama-instruct-few-shot-c4s-base-n6: 3.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 116/116 [00:00<00:00, 16469.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4sp-base-n6: 14.426\n",
      "llama-instruct-few-shot-c4sp-base-n6: 3.505\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from sacrebleu.tokenizers.tokenizer_13a import Tokenizer13a\n",
    "from dataset_utils import create_scores_df\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 13a tokenizer\n",
    "tokenizer = Tokenizer13a()\n",
    "smoothing_function = SmoothingFunction().method1\n",
    "\n",
    "for model in models: \n",
    "    df_res = pd.read_csv(f\"../data/results/{model}-results.csv\")\n",
    "    for setting_key, ds_values in setting_ds_dict.items():\n",
    "        for ds in ds_values:\n",
    "            \n",
    "            all_refs = []\n",
    "            all_preds = []\n",
    "            output_name = f\"{ds}-{setting_key}-{num_examples}\"\n",
    "            df_gen = pd.read_csv(f\"../data/gen_predictions/predictions_{model}-{output_name}.csv\")\n",
    " \n",
    "            for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "                ref = row['elaboration_sentence']\n",
    "                prediction = row['pred_elaboration'] # \"prediction\" for BART\n",
    "            \n",
    "                # Tokenize\n",
    "                tokenized_ref = tokenizer(ref).split()\n",
    "                tokenized_pred = tokenizer(prediction).split()\n",
    "                \n",
    "                all_refs.append([tokenized_ref]) \n",
    "                all_preds.append(tokenized_pred)\n",
    "            \n",
    "            bleu1_score = corpus_bleu(all_refs, all_preds, weights=(1.0, 0, 0, 0), smoothing_function=smoothing_function)  # 1-gram\n",
    "            bleu2_score = corpus_bleu(all_refs, all_preds, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothing_function)  # 2-gram\n",
    "            bleu4_score = corpus_bleu(all_refs, all_preds, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothing_function)  # 4-gram\n",
    "\n",
    "            idx = df_res.index[df_res[\"dataset\"] == ds].tolist()[0]\n",
    "            df_res.at[idx, f\"{setting_key}-{num_examples}-b1\"] = round(bleu1_score*100,3)\n",
    "            df_res.at[idx, f\"{setting_key}-{num_examples}-b2\"] = round(bleu2_score*100,3)\n",
    "            print(f\"{model}-{output_name}: {round(bleu1_score*100,3)}\")\n",
    "            print(f\"{model}-{output_name}: {round(bleu2_score*100,3)}\")\n",
    "    \n",
    "    df_res.to_csv(f\"../data/results/{model}-results.csv\",index=False)\n",
    "    print(f\"Results saved for {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c8c158-b794-4632-abab-f663775172fd",
   "metadata": {},
   "source": [
    "## Sentence bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb8fb3c-5bfc-4d81-8745-3153c048a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scores_df(df_gen):\n",
    "    df_scores = pd.DataFrame({\n",
    "        'source_text': df_gen['source_text'] if 'source_text' in df_gen else None,\n",
    "        'target_sentence': (\n",
    "            df_gen['target_sentence_4o'] if 'target_sentence_4o' in df_gen\n",
    "            else df_gen['target_sentence'] if 'target_sentence' in df_gen\n",
    "            else None\n",
    "        ),\n",
    "        'target_sentence_target': df_gen['target_sentence_target'] if 'target_sentence_target' in df_gen else None,\n",
    "        'subject': df_gen['subject'] if 'subject' in df_gen else None,\n",
    "        'target-phrase': df_gen['target-phrase'] if 'target-phrase' in df_gen else None,\n",
    "        'elaboration_sentence': df_gen['elaboration_sentence'],\n",
    "        'pred_elaboration': df_gen['pred_elaboration'],\n",
    "    })\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9afc752-4beb-4c50-afd4-a2375c16c867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e2cad69af1492080241faab56d2716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814155969f614ceeb3d0036be3aae342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f19fdfbb0f143f8a9e7bbffbc931ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba7ca90cb2445cd979e182a91c68ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb45311055d0412aa54d0f2457a8539f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21bef93167064cbf9033c677e16202d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2589cd0d22774101851413e853467dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49807b4363f45e58908cb8248ae95f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5348b3ba7a274ea39f30722d60b55bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69df92db3da482997a13fa79b5aac81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528036721b5449a9af2539d23fe68657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a5606c5e684625b812c84848885dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18052cc44eac4bec9f7dfefbb4a6a7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7ce9063cf445cab5a615c02a0a2cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2982a4545270465588fd0db6f5212df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a8bf6fe1214d139c451d0b0b2d0c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0990b84737c94097af9546e546aa4c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f46625a2d644427ba96fe81be85f495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595814a4ee194abbbcbb7e5aa631fda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb8d5d9822d400d887c20685c2e16d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2827a753b542f4acee163b5f42a136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20ab9fd2eb8456bb060c51de7247c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582df8704b8d4530b27b9c5a163bae65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8122e9e0a8a548588a2d87d2d1715587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b506da8d10a74e788b86394affe8218a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e0a28443dc451f814945a2e73bbf2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50873f36384e476fa1f7d34d125ca10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87186830adf4472e88b23a945feb8ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d5a37b059c4738a2c6477d4eaec50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b9acd539b34695a32e70cd3ac6fa38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be64497905dc4ff68f998be27a53c49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b50b7eeaa1468eb21fa76b429e6875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d2ddf562d245e19eb9566c10909b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e440522d9ca41f79c41c7c1ba0666d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5573c42ebba64029a8af2bd52f5262a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4f5b6947c5409395b95e1c49db686a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-instruct-few-shot\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from sacrebleu.tokenizers.tokenizer_13a import Tokenizer13a\n",
    "from transformers import BartTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# 13a tokenizer\n",
    "tokenizer = Tokenizer13a()\n",
    "# bart tokenizer\n",
    "#tokenizer_b = BartTokenizer.from_pretrained('facebook/bart-base',use_fast=False) \n",
    "\n",
    "smoothing_function = SmoothingFunction().method1\n",
    "\n",
    "setting_ds_dict = {\n",
    "    \"base\": [\"c2sp\",\"c4s\",\"c4sp\"],\n",
    "    \"masked\": [\"c2sp\",\"c4sp\",\"c4s\"],\n",
    "    \"target-phrase\":[\"c2sp\",\"c4sp\",\"c4s\"],\n",
    "    #\"target-sent\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"c2o\",\"c2op\"],\n",
    "    \"target-sent-target\":[\"c2sp\",\"c4sp\",\"c4s\"]\n",
    "}\n",
    "\n",
    "for model in models: \n",
    "    for setting_key, ds_values in setting_ds_dict.items():\n",
    "        for ds in ds_values:\n",
    "\n",
    "            bleu_scores_1 = []\n",
    "            bleu_scores_2 = []\n",
    "            \n",
    "            output_name = f\"{ds}-{setting_key}\"\n",
    "            df_gen = pd.read_csv(f\"../data/gen_predictions/predictions_{model}-{output_name}.csv\")\n",
    "            df_scores = create_scores_df(df_gen)\n",
    "            for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "                ref = row['elaboration_sentence']\n",
    "                prediction = row['pred_elaboration']\n",
    "            \n",
    "                # tokenize\n",
    "                tokenized_ref = tokenizer(ref).split()\n",
    "                tokenized_pred = tokenizer(prediction).split()\n",
    "                #tokenized_ref = tokenizer_b(ref)[\"input_ids\"]\n",
    "                #tokenized_pred = tokenizer_b(prediction)[\"input_ids\"]\n",
    "                    \n",
    "                bleu_score_1 = sentence_bleu([tokenized_ref],tokenized_pred,weights=(1, 0, 0, 0),smoothing_function=smoothing_function) # 1-gram\n",
    "                bleu_score_2 = sentence_bleu([tokenized_ref],tokenized_pred,weights=(0.5, 0.5, 0, 0), smoothing_function=smoothing_function) # 2-gram\n",
    "                bleu_scores_1.append(round(bleu_score_1,3))\n",
    "                bleu_scores_2.append(round(bleu_score_2,3))\n",
    "\n",
    "            df_scores[\"b1\"] = bleu_scores_1\n",
    "            df_scores[\"b2\"] = bleu_scores_2\n",
    "            df_scores.to_csv(f\"../data/bleu_scores/bleu_scores_{model}-{output_name}.csv\",index=False)\n",
    "            print(f\"Results saved for {model}\")\n",
    "\n",
    "#import numpy as np\n",
    "#print(f\"Average BLEU-1 score: {np.mean(bleu_scores_1)*100:.3f}\")\n",
    "#print(f\"Average BLEU-2 score: {np.mean(bleu_scores_2)*100:.3f}\")\n",
    "#print(f\"Average BLEU-4 score: {np.mean(bleu_scores_4)*100:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360d3f12-d76c-4a6a-b0c9-ecbd5b6f8680",
   "metadata": {},
   "source": [
    "# BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1be5f7b1-d0a0-4b93-9834-5b103dccb8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e995174ccf4479dad3c68d5e04ab83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e644cdc5bc0d46988152bbdac0f1cab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb05cb4fe9ba4601aa1dbd70f6b4ec3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf8d6047c844eecb35b219aa751f05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fdb7b733ac4851a0fbe14de0e8e706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ca66863d164664b0cde8b160f4f7c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc174dced22846668c4ab11cb6bb18da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cafa7b6d9e646e39830d5c1e3c792e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad0c6ec592d475281feb54f63bb7ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91ec6932d464349b88e39a1aa7ba81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ef4abc1da848418d0292ef77145b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084a5b1946db409d843362a9efb53b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed86ce0c242846e4b72846a6555aaf95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18dcfdb75bd6425eaeb2a199a2424065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6646b8cc59a446928f36ba5c2dac0a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0e47da26f74796a526e56ef466f175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92ff4248acc41c295aa2df4e920ea26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8a39af68da455ca596572bbbe73f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42a75786e8e4dcfa5604c4e67fe0d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9390e900b9a54cf88fb88ec04b95ac28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74dc39571aa4691b72615779c954885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20b52e915f246ffbe1f447ee18be05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f5d6988d2b48edb559371168c93a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d781a5a500b43ac9c91d04f502eca25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from bert_score import BERTScorer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import logging\n",
    "\n",
    "# suppress warnings\n",
    "#logging.set_verbosity_error()\n",
    "\n",
    "scorer = BERTScorer(model_type='bert-base-uncased',device='cuda:0')\n",
    "\n",
    "models = [\"bart-ft\",\"llama-ft\"]\n",
    "#num_examples = \"n6\"\n",
    "\n",
    "for model in models: \n",
    "    #df_res = pd.read_csv(f\"../data/results/{model}-results.csv\")\n",
    "    for setting_key, ds_values in setting_ds_dict.items():\n",
    "        for ds in ds_values:\n",
    "            \n",
    "            bert_scores_f1 = []\n",
    "            \n",
    "            output_name = f\"{ds}-{setting_key}\" #-{num_examples}\"\n",
    "            df_gen = pd.read_csv(f\"../data/gen_predictions/predictions_{model}-{output_name}.csv\")\n",
    "            df_scores = create_scores_df(df_gen)\n",
    "            \n",
    "            for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "                elaboration = row['elaboration_sentence']\n",
    "                prediction = row['pred_elaboration']\n",
    "                \n",
    "                #  BERTScore for this pair\n",
    "                P, R, F1 = scorer.score(\n",
    "                    cands=[prediction],  \n",
    "                    refs=[elaboration],              \n",
    "                )\n",
    "                \n",
    "                bert_scores_f1.append(F1.mean().item())\n",
    "\n",
    "            # save scores for each pair\n",
    "            df_scores[\"bsf1\"] = bert_scores_f1\n",
    "            df_scores.to_csv(f\"../data/bert_scores/bert_scores_{model}-{output_name}.csv\",index=False)\n",
    "            print(f\"Results saved for {model}\")\n",
    "            \n",
    "            \"\"\"# save average scores to models general results \n",
    "            avg_precision = np.mean(bert_scores_precision)\n",
    "            avg_recall = np.mean(bert_scores_recall)\n",
    "            avg_f1 = np.mean(bert_scores_f1)\n",
    "\n",
    "            idx = df_res.index[df_res[\"dataset\"] == ds].tolist()[0]\n",
    "            #df_res.at[idx, f\"{setting_key}-{num_examples}-bsprec\"] = round(avg_precision,3)\n",
    "            #df_res.at[idx, f\"{setting_key}-{num_examples}-bsrec\"] = round(avg_recall,3)\n",
    "            df_res.at[idx, f\"{setting_key}-bsf1\"] = round(avg_f1,3)\n",
    "            print(f\"{model}-{ds}-{setting_key}: {round(avg_f1,3)}\")\n",
    "\n",
    "    df_res.to_csv(f\"../data/results/{model}-results.csv\",index=False)\n",
    "    print(f\"Results saved for {model}\")\"\"\"\n",
    "#print(f\"Average BERTScore Precision: {avg_precision:.3f}\")\n",
    "#print(f\"Average BERTScore Recall: {avg_recall:.3f}\")\n",
    "#print(f\"Average BERTScore F1: {avg_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce7f11f-1b22-44da-a795-18d7c32ebf29",
   "metadata": {},
   "source": [
    "# BARTScore\n",
    "\n",
    "https://github.com/neulab/BARTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be4bdf9a-2abc-48d0-ae2f-bac7516bcc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27eb0f0882bc450a8e4e373fd0d43c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c2sp-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c70d22a952e4b77a0c433564ce0ecc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c4s-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332bccc2ea224d58ac203ef91c266a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c4sp-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30adf37c4744433e9aa50b25becccd9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c2sp-masked\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983612309b7a4581b94fdcb88553f612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c4sp-masked\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09882176941440049b0bf49f2b049b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c4s-masked\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530391b41c724d89978b5d03f9dc8e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c2sp-target-phrase\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef17042a78d4aa8b9b3a3b8d65c0063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c4sp-target-phrase\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c1df6c714445799457217a54b44686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c4s-target-phrase\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3d85a568ff40d086bc78100ef01ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c2sp-target-sent-target\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557a4b9946f4437e90f1e660cdda1e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c4sp-target-sent-target\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8100d491f8cb4916a07e678c4da41cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c4s-target-sent-target\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ccc0974efe47529b21f563be8d122a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c2sp-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9730ead4c0f84189821efd6ebc76e668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c4s-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4bee42fbf4411cbe0b7ec3b06e35ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c4sp-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a670ff7fe1a44c58a35bd08fe6432c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c2sp-masked\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361db56d586f4f5bbff675eb4d2d51e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c4sp-masked\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431b28f949d940c5b9988c689aeca7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c4s-masked\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d9b69a45b4424a9e1d64eca35f2e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c2sp-target-phrase\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba868347d5e04e4cb2e68794d86cbc4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c4sp-target-phrase\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee77786274484ef4801bf03b2b93402b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c4s-target-phrase\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7735a4dcc9945e2872a62f1dff379b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c2sp-target-sent-target\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ea99825ba84f029a6df1e05391fac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c4sp-target-sent-target\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29d207dbdbd40988af2a7dbe4d605d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c4s-target-sent-target\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from model_utils import BARTScorer\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "bart_scorer = BARTScorer(device='cuda:0')\n",
    "\n",
    "models = [\"llama-ft\",\"bart-ft\"]\n",
    "#num_examples = \"n6\"\n",
    "\n",
    "for model in models: \n",
    "    #df_res = pd.read_csv(f\"data/results/{model}-results.csv\")\n",
    "    for setting_key, ds_values in setting_ds_dict.items():\n",
    "        for ds in ds_values:\n",
    "            bart_scores = []\n",
    "            output_name = f\"{ds}-{setting_key}\"\n",
    "            df_gen = pd.read_csv(f\"../data/gen_predictions/predictions_{model}-{output_name}.csv\")\n",
    "            df_scores = create_scores_df(df_gen)\n",
    "        \n",
    "            for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "                reference = row['elaboration_sentence']  # reference text (r)\n",
    "                hypothesis = row['pred_elaboration']    # generated text (h)\n",
    "                \n",
    "                # precision (r → h)\n",
    "                precision_score = bart_scorer.score(\n",
    "                    srcs=[reference],  # r as source\n",
    "                    tgts=[hypothesis], # h as target\n",
    "                    batch_size=1\n",
    "                )[0]\n",
    "                \n",
    "                # recall (h → r)\n",
    "                recall_score = bart_scorer.score(\n",
    "                    srcs=[hypothesis],  # h as source\n",
    "                    tgts=[reference],   # r as target\n",
    "                    batch_size=1\n",
    "                )[0]\n",
    "                \n",
    "                # f1 score as the average of precision and recall\n",
    "                f1_score = (precision_score + recall_score) / 2\n",
    "                bart_scores.append(f1_score)\n",
    "            \n",
    "            # save result for each pair\n",
    "            df_scores[\"bartscore\"] = bart_scores\n",
    "            df_scores.to_csv(f\"../data/bart_scores/bart_scores_{model}-{output_name}.csv\",index=False)\n",
    "            print(f\"Results saved for {model}-{output_name}\")\n",
    "        \n",
    "            \"\"\"# average score\n",
    "            avg_score = np.mean(bart_scores)\n",
    "            idx = df_res.index[df_res[\"dataset\"] == ds].tolist()[0]\n",
    "            df_res.at[idx, f\"{setting_key}-{num_examples}-bartscore\"] = round(avg_score,3)\n",
    "            print(f\"{model}-{ds}-{setting_key}-{num_examples}: {round(avg_score,3)}\")\n",
    "    \n",
    "    df_res.to_csv(f\"data/results/{model}-results.csv\",index=False)\n",
    "    print(f\"Results saved for {model}\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586a887a-f36a-4031-8719-8515839ecf9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Prompt evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d9ebc-496e-43b3-a226-22362a2b4d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scores_df(df_gen):\n",
    "    df_scores = pd.DataFrame({\n",
    "        'source_text': df_gen['source_text'] if 'source_text' in df_gen else None,\n",
    "        'target_sentence': (\n",
    "            df_gen['target_sentence_4o'] if 'target_sentence_4o' in df_gen\n",
    "            else df_gen['target_sentence'] if 'target_sentence' in df_gen\n",
    "            else None\n",
    "        ),\n",
    "        'target_sentence_target': df_gen['target_sentence_target'] if 'target_sentence_target' in df_gen else None,\n",
    "        'subject': df_gen['subject'] if 'subject' in df_gen else None,\n",
    "        'target-phrase': df_gen['target-phrase'] if 'target-phrase' in df_gen else None,\n",
    "        'elaboration_sentence': df_gen['elaboration_sentence'],\n",
    "        'pred_elaboration': df_gen['pred_elaboration'],\n",
    "    })\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1fea1e-d333-4998-8a58-d65e0cb6f3a5",
   "metadata": {},
   "source": [
    "## BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6d55eed-5b5a-4299-9f91-a5f3d58eb1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 116/116 [00:00<00:00, 12417.10it/s]\n",
      "100%|██████████████████████████████████████| 116/116 [00:00<00:00, 19120.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from sacrebleu.tokenizers.tokenizer_13a import Tokenizer13a\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 13a tokenizer\n",
    "tokenizer = Tokenizer13a()\n",
    "smoothing_function = SmoothingFunction().method1\n",
    "\n",
    "# prompt evaluation\n",
    "models = [\"llama-instruct-few-shot\"]\n",
    "setting_ds_dict = {\n",
    "    \"short-n3\":{\"base\":[\"c2s\"]}, #{\"base\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"]},\n",
    "    \"medium-n6\":{\"base\":[\"c2s\"]}, #{\"base\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"]},\n",
    "    #\"long-n9\":{\"base\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"]},\n",
    "}\n",
    "\n",
    "for model in models: \n",
    "    #df_res = pd.read_csv(f\"../data/results/{model}-prompt-results.csv\")\n",
    "    for prompt_setting_key, setting_keys in setting_ds_dict.items():\n",
    "        for setting_key, ds_values in setting_keys.items():\n",
    "            for ds in ds_values:\n",
    "            \n",
    "                all_refs = []\n",
    "                all_preds = []\n",
    "                output_name = f\"{ds}-{setting_key}\"\n",
    "                num_examples = prompt_setting_key.split(\"-\")[-1]\n",
    "                # read-in right df\n",
    "                df_gen = pd.read_csv(f\"../data/gen_predictions/predictions_{model}-{output_name}-{num_examples}.csv\")\n",
    "     \n",
    "                for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "                    ref = row['elaboration_sentence']\n",
    "                    prediction = row['pred_elaboration'] \n",
    "                \n",
    "                    # Tokenize\n",
    "                    tokenized_ref = tokenizer(ref).split()\n",
    "                    tokenized_pred = tokenizer(prediction).split()\n",
    "                    \n",
    "                    all_refs.append([tokenized_ref]) \n",
    "                    all_preds.append(tokenized_pred)\n",
    "                \n",
    "                bleu1_score = corpus_bleu(all_refs, all_preds, weights=(1.0, 0, 0, 0), smoothing_function=smoothing_function)  # 1-gram\n",
    "                bleu2_score = corpus_bleu(all_refs, all_preds, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothing_function)  # 2-gram\n",
    "                bleu4_score = corpus_bleu(all_refs, all_preds, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothing_function)  # 4-gram\n",
    "    \n",
    "                \"\"\"idx = df_res.index[df_res[\"dataset\"] == ds].tolist()[0]\n",
    "                df_res.at[idx, f\"{prompt_setting_key}-b1\"] = round(bleu1_score*100,3)\n",
    "                df_res.at[idx, f\"{prompt_setting_key}-b2\"] = round(bleu2_score*100,3)\n",
    "                print(f\"{model}-{ds}-{prompt_setting_key} B1: {round(bleu1_score*100,3)}\")\n",
    "                print(f\"{model}-{ds}-{prompt_setting_key} B2: {round(bleu2_score*100,3)}\")\n",
    "        \n",
    "        df_res.to_csv(f\"../data/results/{model}-prompt-results.csv\",index=False)\n",
    "        print(f\"Results saved for {model}\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8048c72b-c83d-4a5b-b9b4-cd444aca238d",
   "metadata": {},
   "source": [
    "## BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ac165ff-8341-4681-a8a7-08c13e5bd762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6894f3d875b94eaf89a3883ee54379a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-instruct-few-shot-c2s-base-short-n3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35a31537c614122a21d59789069cb5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-instruct-few-shot-c2s-base-medium-n6\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from bert_score import BERTScorer\n",
    "from dataset_utils import create_scores_df\n",
    "import numpy as np\n",
    "from transformers import logging\n",
    "\n",
    "# suppress warnings\n",
    "#logging.set_verbosity_error()\n",
    "\n",
    "scorer = BERTScorer(model_type='bert-base-uncased',device='cuda:0')\n",
    "\n",
    "for model in models: \n",
    "    #df_res = pd.read_csv(f\"../data/results/{model}-prompt-results.csv\")\n",
    "    for prompt_setting_key, setting_keys in setting_ds_dict.items():\n",
    "        for setting_key, ds_values in setting_keys.items():\n",
    "            for ds in ds_values:\n",
    "            \n",
    "                bert_scores_precision = []\n",
    "                bert_scores_recall = []\n",
    "                bert_scores_f1 = []\n",
    "                \n",
    "                output_name = f\"{ds}-{setting_key}\"\n",
    "                # read-in right df\n",
    "                num_examples = prompt_setting_key.split(\"-\")[-1]\n",
    "                # read-in right df\n",
    "                df_gen = pd.read_csv(f\"../data/gen_predictions/predictions_{model}-{output_name}-{num_examples}.csv\")\n",
    "                df_scores = create_scores_df(df_gen)\n",
    "\n",
    "                #df_scores = create_scores_df(df_gen)\n",
    "                \n",
    "                for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "                    elaboration = row['elaboration_sentence']\n",
    "                    prediction = row['pred_elaboration']\n",
    "                    \n",
    "                    #  BERTScore for this pair\n",
    "                    P, R, F1 = scorer.score(\n",
    "                        cands=[prediction],  \n",
    "                        refs=[elaboration],              \n",
    "                    )\n",
    "                    \n",
    "                    bert_scores_precision.append(P.mean().item())\n",
    "                    bert_scores_recall.append(R.mean().item())\n",
    "                    bert_scores_f1.append(F1.mean().item())\n",
    "    \n",
    "                # save result for each pair\n",
    "                df_scores[\"bsf1\"] = bert_scores_f1\n",
    "                df_scores.to_csv(f\"../data/bert_scores/bert_scores_{model}-{output_name}-{prompt_setting_key}.csv\",index=False)\n",
    "                print(f\"Results saved for {model}-{output_name}-{prompt_setting_key}\")\n",
    "            \n",
    "                \n",
    "                \"\"\"avg_f1 = np.mean(bert_scores_f1)\n",
    "                idx = df_res.index[df_res[\"dataset\"] == ds].tolist()[0]\n",
    "                df_res.at[idx, f\"{prompt_setting_key}-bsf1\"] = round(avg_f1,3)\n",
    "                print(f\"{model}-{ds}-{prompt_setting_key}: {round(avg_f1,3)}\")\n",
    "    \n",
    "        df_res.to_csv(f\"../data/results/{model}-prompt-results.csv\",index=False)\n",
    "        print(f\"Results saved for {model}\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa16460-8fc0-47a0-a373-4d70741eadd0",
   "metadata": {},
   "source": [
    "## BARTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d35400d9-79e7-4542-946d-763811bb7632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d1c184d1014c6d9cc73eb1682972b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-instruct-few-shot-c2s-base-short-n3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e4ed6a335f4cc2943bf420f453cb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-instruct-few-shot-c2s-base-medium-n6\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath('..')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils.bart_score import BARTScorer\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "bart_scorer = BARTScorer(device='cuda:0')\n",
    "\n",
    "for model in models: \n",
    "    #df_res = pd.read_csv(f\"data/results/{model}-prompt-results.csv\")\n",
    "    for prompt_setting_key, setting_keys in setting_ds_dict.items():\n",
    "        for setting_key, ds_values in setting_keys.items():\n",
    "            for ds in ds_values:\n",
    "\n",
    "                bart_scores = []\n",
    "                output_name = f\"{ds}-{setting_key}\"\n",
    "                # read-in right df\n",
    "                num_examples = prompt_setting_key.split(\"-\")[-1]\n",
    "                # read-in right df\n",
    "                df_gen = pd.read_csv(f\"data/gen_predictions/predictions_{model}-{output_name}-{num_examples}.csv\")\n",
    "                df_scores = create_scores_df(df_gen)\n",
    "            \n",
    "                for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "                    reference = row['elaboration_sentence']  # reference text (r)\n",
    "                    hypothesis = row['pred_elaboration']    # generated text (h)\n",
    "                    \n",
    "                    # precision (r → h)\n",
    "                    precision_score = bart_scorer.score(\n",
    "                        srcs=[reference],  # r as source\n",
    "                        tgts=[hypothesis], # h as target\n",
    "                        batch_size=1\n",
    "                    )[0]\n",
    "                    \n",
    "                    # recall (h → r)\n",
    "                    recall_score = bart_scorer.score(\n",
    "                        srcs=[hypothesis],  # h as source\n",
    "                        tgts=[reference],   # r as target\n",
    "                        batch_size=1\n",
    "                    )[0]\n",
    "                    \n",
    "                    # f1 score as the average of precision and recall\n",
    "                    f1_score = (precision_score + recall_score) / 2\n",
    "                    bart_scores.append(f1_score)\n",
    "                \n",
    "                # save score result for each pair\n",
    "                df_scores[\"bartscore\"] = bart_scores\n",
    "                df_scores.to_csv(f\"data/bart_scores/bart_scores_{model}-{output_name}-{prompt_setting_key}.csv\",index=False)\n",
    "                print(f\"Results saved for {model}-{output_name}-{prompt_setting_key}\")\n",
    "    \n",
    "                # average score\n",
    "                \"\"\"avg_score = np.mean(bart_scores)\n",
    "                idx = df_res.index[df_res[\"dataset\"] == ds].tolist()[0]\n",
    "                df_res.at[idx, f\"{prompt_setting_key}-bartscore\"] = round(avg_score,3)\n",
    "                print(f\"{model}-{ds}-{prompt_setting_key}: {round(avg_score,3)}\")\n",
    "    \n",
    "                df_res.to_csv(f\"data/results/{model}-prompt-results.csv\",index=False)\n",
    "                print(f\"Results saved for {model}\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c47c65-4433-4c81-ba77-4739fe678a21",
   "metadata": {},
   "source": [
    "# Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cb484dd-c947-4e0e-ab15-f0350bc1d6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>short-b1</th>\n",
       "      <th>short-b2</th>\n",
       "      <th>long-b1</th>\n",
       "      <th>long-b2</th>\n",
       "      <th>random-b1</th>\n",
       "      <th>random-b2</th>\n",
       "      <th>short-bsf1</th>\n",
       "      <th>long-bsf1</th>\n",
       "      <th>random-bsf1</th>\n",
       "      <th>short-bartscore</th>\n",
       "      <th>long-bartscore</th>\n",
       "      <th>random-bartscore</th>\n",
       "      <th>random-n2-b1</th>\n",
       "      <th>random-n2-b2</th>\n",
       "      <th>random-n3-b1</th>\n",
       "      <th>random-n3-b2</th>\n",
       "      <th>random-n7-b1</th>\n",
       "      <th>random-n7-b2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c2s</td>\n",
       "      <td>15.899</td>\n",
       "      <td>3.588</td>\n",
       "      <td>15.161</td>\n",
       "      <td>4.712</td>\n",
       "      <td>14.945</td>\n",
       "      <td>2.894</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.436</td>\n",
       "      <td>-3.778</td>\n",
       "      <td>-3.843</td>\n",
       "      <td>-4.011</td>\n",
       "      <td>15.268</td>\n",
       "      <td>3.804</td>\n",
       "      <td>14.945</td>\n",
       "      <td>2.894</td>\n",
       "      <td>15.516</td>\n",
       "      <td>3.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c2sp</td>\n",
       "      <td>15.266</td>\n",
       "      <td>3.515</td>\n",
       "      <td>14.368</td>\n",
       "      <td>4.223</td>\n",
       "      <td>13.931</td>\n",
       "      <td>2.704</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.438</td>\n",
       "      <td>-3.849</td>\n",
       "      <td>-3.922</td>\n",
       "      <td>-4.003</td>\n",
       "      <td>14.364</td>\n",
       "      <td>3.875</td>\n",
       "      <td>13.931</td>\n",
       "      <td>2.704</td>\n",
       "      <td>15.282</td>\n",
       "      <td>3.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c4s</td>\n",
       "      <td>15.712</td>\n",
       "      <td>2.912</td>\n",
       "      <td>14.507</td>\n",
       "      <td>4.266</td>\n",
       "      <td>14.055</td>\n",
       "      <td>3.507</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.442</td>\n",
       "      <td>-3.884</td>\n",
       "      <td>-3.900</td>\n",
       "      <td>-4.023</td>\n",
       "      <td>12.869</td>\n",
       "      <td>3.313</td>\n",
       "      <td>14.055</td>\n",
       "      <td>3.507</td>\n",
       "      <td>13.452</td>\n",
       "      <td>3.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c4sp</td>\n",
       "      <td>15.233</td>\n",
       "      <td>1.652</td>\n",
       "      <td>13.268</td>\n",
       "      <td>3.145</td>\n",
       "      <td>13.595</td>\n",
       "      <td>3.055</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.435</td>\n",
       "      <td>-3.941</td>\n",
       "      <td>-3.954</td>\n",
       "      <td>-4.044</td>\n",
       "      <td>12.824</td>\n",
       "      <td>2.680</td>\n",
       "      <td>13.595</td>\n",
       "      <td>3.055</td>\n",
       "      <td>14.537</td>\n",
       "      <td>3.098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  short-b1  short-b2  long-b1  long-b2  random-b1  random-b2  \\\n",
       "0     c2s    15.899     3.588   15.161    4.712     14.945      2.894   \n",
       "1    c2sp    15.266     3.515   14.368    4.223     13.931      2.704   \n",
       "2     c4s    15.712     2.912   14.507    4.266     14.055      3.507   \n",
       "3    c4sp    15.233     1.652   13.268    3.145     13.595      3.055   \n",
       "\n",
       "   short-bsf1  long-bsf1  random-bsf1  short-bartscore  long-bartscore  \\\n",
       "0       0.475      0.446        0.436           -3.778          -3.843   \n",
       "1       0.456      0.439        0.438           -3.849          -3.922   \n",
       "2       0.461      0.443        0.442           -3.884          -3.900   \n",
       "3       0.447      0.434        0.435           -3.941          -3.954   \n",
       "\n",
       "   random-bartscore  random-n2-b1  random-n2-b2  random-n3-b1  random-n3-b2  \\\n",
       "0            -4.011        15.268         3.804        14.945         2.894   \n",
       "1            -4.003        14.364         3.875        13.931         2.704   \n",
       "2            -4.023        12.869         3.313        14.055         3.507   \n",
       "3            -4.044        12.824         2.680        13.595         3.055   \n",
       "\n",
       "   random-n7-b1  random-n7-b2  \n",
       "0        15.516         3.175  \n",
       "1        15.282         3.750  \n",
       "2        13.452         3.822  \n",
       "3        14.537         3.098  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a3102b2-71d4-4238-b7f5-125b84d55426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot\n"
     ]
    }
   ],
   "source": [
    "df_res.to_csv(f\"../data/results/{model}-prompt-results.csv\",index=False)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32495be-9d05-4b18-90b8-5395a57452d6",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f15d3e35-6f21-4db0-963a-2fd1de85b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    'source_text': df_gen['source_text'],\n",
    "    'elaboration_sentence': df_gen['elaboration_sentence'],\n",
    "    'pred_elaboration': df_gen['pred_elaboration'],\n",
    "    'bert-score-precision': bert_scores_precision,\n",
    "    'bert-score-recall': bert_scores_recall,\n",
    "    'bert-score-f1': bert_scores_f1\n",
    "})\n",
    "\n",
    "# bleu-scores\n",
    "#df_results.to_csv(\"../data/bleu_scores/bleu_scores_bart-ft-c2sp-masked.csv\", index=False)\n",
    "# bert-scores\n",
    "df_results.to_csv(f\"../data/bert_scores/bert_scores_{model}-test_ds-{output_name}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
