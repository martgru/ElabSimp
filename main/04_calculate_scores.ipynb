{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a2be0bc-d97f-4c46-9a67-919c1c7c936b",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b2e70ca-6f23-4931-9222-5bf9440f5de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"llama-ft\",\"bart-ft\",\"llama-instruct-few-shot\"]\n",
    "\n",
    "setting_ds_dict = {\n",
    "    \"base\": [\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"cs\",\"c2spo\",\"c4spo\",\"cso\"],\n",
    "    \"masked\": [\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"],\n",
    "    \"subject\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"c2spo\",\"c4spo\"],\n",
    "    \"target-phrase\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"c2spo\",\"c4spo\"],\n",
    "    \"target-sent\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"c2spo\",\"c4spo\"],\n",
    "    \"target-sent-target\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"cs\",\"cso\",\"c2spo\",\"c4spo\"],\n",
    "    \"target-sent-subject\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\",\"cs\",\"cso\",\"c2spo\",\"c4spo\"],\n",
    "}\n",
    "\n",
    "# for results inspection\n",
    "results_setting_ds_dict = {\n",
    "    \"base\": [\"cs\",\"c4s\"],\n",
    "    \"subject\":[\"c4s\"],\n",
    "    \"target-phrase\":[\"c4s\"],\n",
    "    \"target-sent\":[\"c4s\"],\n",
    "    \"target-sent-target\":[\"c4sp\"],\n",
    "    \"target-sent-subject\":[\"c2sp\",\"c4spo\"],\n",
    "}\n",
    "\n",
    "# additional calculation\n",
    "setting_ds_dict = {\n",
    "    \"target-phrase\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"],\n",
    "    \"target-sent\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"],\n",
    "    \"target-sent-target\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc34bc-1708-4887-9218-72243a75d666",
   "metadata": {},
   "source": [
    "# Load results df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c46aecf4-8edb-4071-8644-2f0d40b7b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bart_ft_res = pd.read_csv(\"../data/results/bart-ft-results.csv\")\n",
    "llama_ft_res = pd.read_csv(\"../data/results/llama-ft-results.csv\")\n",
    "llama_instr_res = pd.read_csv(\"../data/results/llama-instruct-few-shot-results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb11724e-fb2e-46ae-8975-b7d0d6010d34",
   "metadata": {},
   "source": [
    "# Initialize columns in results dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cfebfd-0147-41f5-b5bf-fcbe304930cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "439234a1-51ef-4105-8be3-defc589f27f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>base-b1</th>\n",
       "      <th>base-b2</th>\n",
       "      <th>masked-b1</th>\n",
       "      <th>masked-b2</th>\n",
       "      <th>subject-b1</th>\n",
       "      <th>subject-b2</th>\n",
       "      <th>target-phrase-b1</th>\n",
       "      <th>target-phrase-b2</th>\n",
       "      <th>target-sent-b1</th>\n",
       "      <th>...</th>\n",
       "      <th>target-sent-bs-rec</th>\n",
       "      <th>target-sent-target-bs-rec</th>\n",
       "      <th>target-sent-subject-bs-rec</th>\n",
       "      <th>base-bs-f1</th>\n",
       "      <th>masked-bs-f1</th>\n",
       "      <th>subject-bs-f1</th>\n",
       "      <th>target-phrase-bs-f1</th>\n",
       "      <th>target-sent-bs-f1</th>\n",
       "      <th>target-sent-target-bs-f1</th>\n",
       "      <th>target-sent-subject-bs-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c2s</td>\n",
       "      <td>15.899</td>\n",
       "      <td>3.588</td>\n",
       "      <td>15.258</td>\n",
       "      <td>3.309</td>\n",
       "      <td>22.277</td>\n",
       "      <td>8.939</td>\n",
       "      <td>18.347</td>\n",
       "      <td>5.923</td>\n",
       "      <td>17.417</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c2sp</td>\n",
       "      <td>15.266</td>\n",
       "      <td>3.515</td>\n",
       "      <td>15.757</td>\n",
       "      <td>3.567</td>\n",
       "      <td>23.580</td>\n",
       "      <td>9.417</td>\n",
       "      <td>18.686</td>\n",
       "      <td>5.726</td>\n",
       "      <td>18.003</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c4s</td>\n",
       "      <td>15.712</td>\n",
       "      <td>2.912</td>\n",
       "      <td>14.908</td>\n",
       "      <td>4.157</td>\n",
       "      <td>22.771</td>\n",
       "      <td>8.681</td>\n",
       "      <td>17.560</td>\n",
       "      <td>5.348</td>\n",
       "      <td>18.005</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c4sp</td>\n",
       "      <td>15.233</td>\n",
       "      <td>1.652</td>\n",
       "      <td>16.923</td>\n",
       "      <td>4.930</td>\n",
       "      <td>23.323</td>\n",
       "      <td>9.918</td>\n",
       "      <td>18.652</td>\n",
       "      <td>5.758</td>\n",
       "      <td>16.861</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs</td>\n",
       "      <td>19.650</td>\n",
       "      <td>6.692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c2spo</td>\n",
       "      <td>13.904</td>\n",
       "      <td>2.192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c4spo</td>\n",
       "      <td>13.147</td>\n",
       "      <td>1.519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  base-b1  base-b2  masked-b1  masked-b2  subject-b1  subject-b2  \\\n",
       "0     c2s   15.899    3.588     15.258      3.309      22.277       8.939   \n",
       "1    c2sp   15.266    3.515     15.757      3.567      23.580       9.417   \n",
       "2     c4s   15.712    2.912     14.908      4.157      22.771       8.681   \n",
       "3    c4sp   15.233    1.652     16.923      4.930      23.323       9.918   \n",
       "4      cs   19.650    6.692        NaN        NaN         NaN         NaN   \n",
       "5   c2spo   13.904    2.192        NaN        NaN         NaN         NaN   \n",
       "6   c4spo   13.147    1.519        NaN        NaN         NaN         NaN   \n",
       "\n",
       "   target-phrase-b1  target-phrase-b2  target-sent-b1  ...  \\\n",
       "0            18.347             5.923          17.417  ...   \n",
       "1            18.686             5.726          18.003  ...   \n",
       "2            17.560             5.348          18.005  ...   \n",
       "3            18.652             5.758          16.861  ...   \n",
       "4               NaN               NaN             NaN  ...   \n",
       "5               NaN               NaN             NaN  ...   \n",
       "6               NaN               NaN             NaN  ...   \n",
       "\n",
       "   target-sent-bs-rec  target-sent-target-bs-rec  target-sent-subject-bs-rec  \\\n",
       "0                None                       None                        None   \n",
       "1                None                       None                        None   \n",
       "2                None                       None                        None   \n",
       "3                None                       None                        None   \n",
       "4                None                       None                        None   \n",
       "5                None                       None                        None   \n",
       "6                None                       None                        None   \n",
       "\n",
       "   base-bs-f1  masked-bs-f1 subject-bs-f1 target-phrase-bs-f1  \\\n",
       "0        None          None          None                None   \n",
       "1        None          None          None                None   \n",
       "2        None          None          None                None   \n",
       "3        None          None          None                None   \n",
       "4        None          None          None                None   \n",
       "5        None          None          None                None   \n",
       "6        None          None          None                None   \n",
       "\n",
       "  target-sent-bs-f1 target-sent-target-bs-f1 target-sent-subject-bs-f1  \n",
       "0              None                     None                      None  \n",
       "1              None                     None                      None  \n",
       "2              None                     None                      None  \n",
       "3              None                     None                      None  \n",
       "4              None                     None                      None  \n",
       "5              None                     None                      None  \n",
       "6              None                     None                      None  \n",
       "\n",
       "[7 rows x 36 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = pd.read_csv(f\"../data/results/{model}-results.csv\")\n",
    "settings = list(dict.fromkeys([\"-\".join(col.split(\"-\")[:-1]) for col in df_res.columns if \"-\" in col]))\n",
    "cols_to_add = [f\"{col_name}-bs-prec\" for col_name in settings] + \\\n",
    "              [f\"{col_name}-bs-rec\" for col_name in settings] + \\\n",
    "              [f\"{col_name}-bs-f1\" for col_name in settings]\n",
    "for col in cols_to_add:\n",
    "    df_res[col] = None \n",
    "\n",
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224bf50f-ee93-4a57-859f-005911f22bca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## BARTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "137228e8-9392-4815-9439-a8b7e9968269",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama-ft\"#\"llama-instruct-few-shot\"\n",
    "df_res = pd.read_csv(f\"data/results/{model}-results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22f048c0-d472-4431-a36f-baaff602b058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dataset', 'base-b1', 'base-b2', 'masked-b1', 'masked-b2', 'subject-b1',\n",
      "       'subject-b2', 'target-phrase-b1', 'target-phrase-b2', 'target-sent-b1',\n",
      "       'target-sent-b2', 'target-sent-target-b1', 'target-sent-target-b2',\n",
      "       'target-sent-subject-b1', 'target-sent-subject-b2', 'base-bsprec',\n",
      "       'masked-bsprec', 'subject-bsprec', 'target-phrase-bsprec',\n",
      "       'target-sent-bsprec', 'target-sent-target-bsprec',\n",
      "       'target-sent-subject-bsprec', 'base-bsrec', 'masked-bsrec',\n",
      "       'subject-bsrec', 'target-phrase-bsrec', 'target-sent-bsrec',\n",
      "       'target-sent-target-bsrec', 'target-sent-subject-bsrec', 'base-bsf1',\n",
      "       'masked-bsf1', 'subject-bsf1', 'target-phrase-bsf1', 'target-sent-bsf1',\n",
      "       'target-sent-target-bsf1', 'target-sent-subject-bsf1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# rename certain columns\n",
    "df_res.columns = [\n",
    "    col.replace('-bs-rec', '-bsrec').replace('-bs-prec', '-bsprec').replace('-bs-f1', '-bsf1')\n",
    "    if col.endswith(('-bs-rec', '-bs-prec', '-bs-f1')) else col\n",
    "    for col in df_res.columns\n",
    "]\n",
    "\n",
    "print(df_res.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67beec04-6164-42b9-bcc8-ed134bf8bfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['base', 'masked', 'subject', 'target-phrase', 'target-sent', 'target-sent-target', 'target-sent-subject']\n",
      "\n",
      "Index(['dataset', 'base-b1', 'base-b2', 'masked-b1', 'masked-b2', 'subject-b1',\n",
      "       'subject-b2', 'target-phrase-b1', 'target-phrase-b2', 'target-sent-b1',\n",
      "       'target-sent-b2', 'target-sent-target-b1', 'target-sent-target-b2',\n",
      "       'target-sent-subject-b1', 'target-sent-subject-b2', 'base-bsprec',\n",
      "       'masked-bsprec', 'subject-bsprec', 'target-phrase-bsprec',\n",
      "       'target-sent-bsprec', 'target-sent-target-bsprec',\n",
      "       'target-sent-subject-bsprec', 'base-bsrec', 'masked-bsrec',\n",
      "       'subject-bsrec', 'target-phrase-bsrec', 'target-sent-bsrec',\n",
      "       'target-sent-target-bsrec', 'target-sent-subject-bsrec', 'base-bsf1',\n",
      "       'masked-bsf1', 'subject-bsf1', 'target-phrase-bsf1', 'target-sent-bsf1',\n",
      "       'target-sent-target-bsf1', 'target-sent-subject-bsf1', 'base-bartscore',\n",
      "       'masked-bartscore', 'subject-bartscore', 'target-phrase-bartscore',\n",
      "       'target-sent-bartscore', 'target-sent-target-bartscore',\n",
      "       'target-sent-subject-bartscore'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "settings = list(dict.fromkeys([\"-\".join(col.split(\"-\")[:-1]) for col in df_res.columns if \"-\" in col]))\n",
    "print(settings, end=\"\\n\\n\")\n",
    "cols_to_add = [f\"{col_name}-bartscore\" for col_name in settings]\n",
    "for col in cols_to_add:\n",
    "    df_res[col] = None\n",
    "print(df_res.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949ae5b4-331b-4df6-af1f-7eeb95d675cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## New dataset row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c61803c1-7b43-42c2-9b0b-ffccb11a14fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for model in models: \n",
    "    df_res = pd.read_csv(f\"../data/results/{model}-results.csv\")\n",
    "    df_res.loc[len(df_res), 'dataset'] = 'cso'\n",
    "    df_res.to_csv(f\"../data/results/{model}-results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b13ee6-504f-43ce-a3b2-1fbeb98705e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Map values for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23aec249-1216-4be3-baf8-7060defed26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models: \n",
    "    df_res = pd.read_csv(f\"../data/results/{model}-results.csv\")\n",
    "    dss = [\"cso\",\"cs\"]\n",
    "    settings_map = {\"target-sent-subject\":\"subject\",\"target-sent-target\":\"target-phrase\", \"base\":\"target-sent\"}\n",
    "    for ds in dss:\n",
    "        idx = df_res.index[df_res[\"dataset\"] == ds].tolist()[0]\n",
    "        for current_setting_key, target_setting_key in settings_map.items():\n",
    "            df_res.at[idx, f\"{target_setting_key}-b1\"] = df_res.loc[idx, f\"{current_setting_key}-b1\"]\n",
    "            df_res.at[idx, f\"{target_setting_key}-b2\"] = df_res.loc[idx, f\"{current_setting_key}-b2\"]\n",
    "            df_res.at[idx, f\"{target_setting_key}-bsprec\"] = df_res.loc[idx, f\"{current_setting_key}-bsprec\"]\n",
    "            df_res.at[idx, f\"{target_setting_key}-bsrec\"] = df_res.loc[idx, f\"{current_setting_key}-bsrec\"]\n",
    "            df_res.at[idx, f\"{target_setting_key}-bsf1\"] = df_res.loc[idx, f\"{current_setting_key}-bsf1\"]\n",
    "            df_res.at[idx, f\"{target_setting_key}-bartscore\"] = df_res.loc[idx, f\"{current_setting_key}-bartscore\"]\n",
    "    df_res.to_csv(f\"../data/results/{model}-results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a721dc-ab96-4a59-b2e4-83675cf82cec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Rename datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f815cef4-4eaf-460c-9e13-b52e165cbb24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed: predictions_bart-c4s-target-sent-subject.csv -> predictions_bart-ft-c4s-target-sent-subject.csv\n",
      "Renamed: predictions_bart-c2spo-base.csv -> predictions_bart-ft-c2spo-base.csv\n",
      "Renamed: predictions_bart-c2sp-subject.csv -> predictions_bart-ft-c2sp-subject.csv\n",
      "Renamed: predictions_bart-c4sp-target-sent-subject.csv -> predictions_bart-ft-c4sp-target-sent-subject.csv\n",
      "Renamed: predictions_bart-c4sp-subject.csv -> predictions_bart-ft-c4sp-subject.csv\n",
      "Renamed: predictions_bart-test.csv -> predictions_bart-ft-test.csv\n",
      "Renamed: predictions_bart-c2sp-target-sent-target.csv -> predictions_bart-ft-c2sp-target-sent-target.csv\n",
      "Renamed: predictions_bart-c2sp-target-sent-subject.csv -> predictions_bart-ft-c2sp-target-sent-subject.csv\n",
      "Renamed: predictions_bart-c2s-target-phrase.csv -> predictions_bart-ft-c2s-target-phrase.csv\n",
      "Renamed: predictions_bart-c2sp-base.csv -> predictions_bart-ft-c2sp-base.csv\n",
      "Renamed: predictions_bart-c2sp-masked.csv -> predictions_bart-ft-c2sp-masked.csv\n",
      "Renamed: predictions_bart-c2s-target-sent.csv -> predictions_bart-ft-c2s-target-sent.csv\n",
      "Renamed: predictions_bart-c2sp-target-phrase.csv -> predictions_bart-ft-c2sp-target-phrase.csv\n",
      "Renamed: predictions_bart-cs-target-sent-target.csv -> predictions_bart-ft-cs-target-sent-target.csv\n",
      "Renamed: predictions_bart-c4spo-base.csv -> predictions_bart-ft-c4spo-base.csv\n",
      "Renamed: predictions_bart-c2s-base.csv -> predictions_bart-ft-c2s-base.csv\n",
      "Renamed: predictions_bart-c4sp-base.csv -> predictions_bart-ft-c4sp-base.csv\n",
      "Renamed: predictions_bart-c4s-masked.csv -> predictions_bart-ft-c4s-masked.csv\n",
      "Renamed: predictions_bart-c2s-target-sent-subject.csv -> predictions_bart-ft-c2s-target-sent-subject.csv\n",
      "Renamed: predictions_bart-c4s-target-sent-target.csv -> predictions_bart-ft-c4s-target-sent-target.csv\n",
      "Renamed: predictions_bart-c4sp-target-sent.csv -> predictions_bart-ft-c4sp-target-sent.csv\n",
      "Renamed: predictions_bart-c2s-target-sent-target.csv -> predictions_bart-ft-c2s-target-sent-target.csv\n",
      "Renamed: predictions_bart-c4sp-target-phrase.csv -> predictions_bart-ft-c4sp-target-phrase.csv\n",
      "Renamed: predictions_bart-c2sp-target-sent.csv -> predictions_bart-ft-c2sp-target-sent.csv\n",
      "Renamed: predictions_bart-c4sp-masked.csv -> predictions_bart-ft-c4sp-masked.csv\n",
      "Renamed: predictions_bart-c4s-base.csv -> predictions_bart-ft-c4s-base.csv\n",
      "Renamed: predictions_bart-c4s-target-phrase.csv -> predictions_bart-ft-c4s-target-phrase.csv\n",
      "Renamed: predictions_bart-c4s-target-sent.csv -> predictions_bart-ft-c4s-target-sent.csv\n",
      "Renamed: predictions_bart-c4s-subject.csv -> predictions_bart-ft-c4s-subject.csv\n",
      "Renamed: predictions_bart-c4sp-target-sent-target.csv -> predictions_bart-ft-c4sp-target-sent-target.csv\n",
      "Renamed: predictions_bart-cs-base.csv -> predictions_bart-ft-cs-base.csv\n",
      "Renamed: predictions_bart-cs-target-sent-subject.csv -> predictions_bart-ft-cs-target-sent-subject.csv\n",
      "Renamed: predictions_bart-c2s-subject.csv -> predictions_bart-ft-c2s-subject.csv\n",
      "Renamed: predictions_bart-c2s-masked.csv -> predictions_bart-ft-c2s-masked.csv\n"
     ]
    }
   ],
   "source": [
    "# rename files\n",
    "import os\n",
    "\n",
    "directory = \"data/gen_predictions\"\n",
    "\n",
    "old_part = \"predictions_bart-\"\n",
    "new_part = \"predictions_bart-ft-\"\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "\n",
    "    if old_part in filename:\n",
    "        # new filename by replacing the old part\n",
    "        new_filename = filename.replace(old_part, new_part)\n",
    "        \n",
    "        # full paths for renaming\n",
    "        old_file_path = os.path.join(directory, filename)\n",
    "        new_file_path = os.path.join(directory, new_filename)\n",
    "        \n",
    "        # rename the file\n",
    "        os.rename(old_file_path, new_file_path)\n",
    "        print(f\"Renamed: {filename} -> {new_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10110f52-275c-410d-9a66-5b1eff822fd9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SARI - Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf6017c1-5cc3-4970-9b74-959d1f8884c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d7b27ee24e4e3785eb09aae20a09ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evaluate import load\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "sari_metric = load(\"sari\")\n",
    "sari_scores = []\n",
    "\n",
    "for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "    r_content = row['text'] \n",
    "    s_content = dataset['test'][index] \n",
    "    prediction = row['prediction']  \n",
    "    \n",
    "    sari_score = sari_metric.compute(\n",
    "        sources=[r_content],\n",
    "        predictions=[prediction],\n",
    "        references=[s_content['simplifications']]\n",
    "    )\n",
    "    \n",
    "    sari_scores.append(sari_score['sari'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0344dde9-0b12-448a-880c-9e82df722695",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SARI - EASSE package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21c93079-9b0a-45f4-8446-d83fad341431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fe8728a5b84524acb2902f9f54b345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'label_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/nlp/lib64/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m tqdm(df_gen\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(df_gen)):\n\u001b[1;32m      8\u001b[0m     r_content \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[0;32m----> 9\u001b[0m     s_content \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m  \n\u001b[1;32m     10\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m]  \n\u001b[1;32m     12\u001b[0m     sari_score_easse \u001b[38;5;241m=\u001b[39m corpus_sari(\n\u001b[1;32m     13\u001b[0m         orig_sents\u001b[38;5;241m=\u001b[39m[r_content],\n\u001b[1;32m     14\u001b[0m         sys_sents\u001b[38;5;241m=\u001b[39m[prediction],\n\u001b[1;32m     15\u001b[0m         refs_sents\u001b[38;5;241m=\u001b[39m[[s_content]]\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m#refs_sents=[[simp] for simp in s_content['simplifications']]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     )\n",
      "File \u001b[0;32m~/nlp/lib64/python3.9/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/nlp/lib64/python3.9/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/nlp/lib64/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label_text'"
     ]
    }
   ],
   "source": [
    "from easse.sari import corpus_sari\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "sari_scores_easse = []\n",
    "\n",
    "for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "    r_content = row['source_text'] \n",
    "    s_content = row['label_text']  \n",
    "    prediction = row['prediction']  \n",
    "    \n",
    "    sari_score_easse = corpus_sari(\n",
    "        orig_sents=[r_content],\n",
    "        sys_sents=[prediction],\n",
    "        refs_sents=[[s_content]]\n",
    "        #refs_sents=[[simp] for simp in s_content['simplifications']]\n",
    "    )\n",
    "    \n",
    "    sari_scores_easse.append(sari_score_easse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2a4dc924-dcdf-4996-a704-bc8fa62f053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SARI score: 36.46781896155372\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Average SARI score:\", np.mean(sari_scores_easse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48b68e-8dad-4ca5-a0f4-3059c107d5c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Operation scores (add, keep, delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebda0d28-3b07-4479-810f-4f321c9ed5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f328a3975ef64892b8a5039c8e60ccbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from easse.sari import get_corpus_sari_operation_scores\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "add_scores = []\n",
    "keep_scores = []\n",
    "del_scores = []\n",
    "\n",
    "for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "    r_content = row['source_text'] \n",
    "    s_content = row['label_text'] #dataset['test'][index]  \n",
    "    prediction = row['prediction']  \n",
    "    \n",
    "    add_score, keep_score, del_score = get_corpus_sari_operation_scores(\n",
    "        orig_sents=[r_content],\n",
    "        sys_sents=[prediction],\n",
    "        refs_sents=[[s_content]]\n",
    "        #refs_sents=[[simp] for simp in s_content['simplifications']] \n",
    "    )\n",
    "    \n",
    "    add_scores.append(add_score)\n",
    "    keep_scores.append(keep_score)\n",
    "    del_scores.append(del_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb0cbf1-18d1-4243-8d97-1a6da6cc55aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# BLEU-4 (EASSE package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0422bbeb-5d1b-4060-abd5-e14a5a0f5789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfa32888f4f4039acffa9021cc37531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score: 4.965\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from easse.bleu import corpus_bleu\n",
    "import numpy as np\n",
    "\n",
    "bleu_scores_easse = []\n",
    "\n",
    "for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "    s_content = row['elaboration_sentence'] \n",
    "    prediction = row['pred_elaboration'] # \"prediction\" for BART\n",
    "    \n",
    "    bleu_score_easse = corpus_bleu(\n",
    "        sys_sents=[prediction],\n",
    "        refs_sents=[[s_content]]\n",
    "    )\n",
    "    \n",
    "    bleu_scores_easse.append(bleu_score_easse)\n",
    "\n",
    "print(f\"Average BLEU score: {np.mean(bleu_scores_easse):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423467a1-bd5b-45a5-9c81-c4cca2be66b9",
   "metadata": {},
   "source": [
    "# BLEU-1 & BLEU-2 (nltk + tokenizer-13A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7021e9d-90fa-4477-9c0d-ca7d046ef283",
   "metadata": {},
   "source": [
    "## Corpus bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db64be6b-4a29-444a-8fd6-1fc8e9f1f940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 16480.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-ft-cso-base: 18.528\n",
      "llama-ft-cso-base: 6.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 25253.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-ft-c2spo-base: 16.764\n",
      "llama-ft-c2spo-base: 5.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 25875.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-ft-c4spo-base: 15.761\n",
      "llama-ft-c4spo-base: 4.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 24165.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-ft-c2spo-subject: 26.962\n",
      "llama-ft-c2spo-subject: 14.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 28811.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-ft-c4spo-subject: 29.417\n",
      "llama-ft-c4spo-subject: 15.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 26865.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-ft-c2spo-target-phrase: 21.212\n",
      "llama-ft-c2spo-target-phrase: 8.055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 29501.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-ft-c4spo-target-phrase: 20.194\n",
      "llama-ft-c4spo-target-phrase: 8.831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 28931.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-ft-c2spo-target-sent: 18.602\n",
      "llama-ft-c2spo-target-sent: 6.468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 29357.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-ft-c4spo-target-sent: 18.674\n",
      "llama-ft-c4spo-target-sent: 6.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 27401.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-ft-cso-target-sent-target: 20.885\n",
      "llama-ft-cso-target-sent-target: 8.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 33342.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-ft-c2spo-target-sent-target: 20.317\n",
      "llama-ft-c2spo-target-sent-target: 7.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 32785.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-ft-c4spo-target-sent-target: 20.799\n",
      "llama-ft-c4spo-target-sent-target: 8.749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 27261.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-ft-cso-target-sent-subject: 28.698\n",
      "llama-ft-cso-target-sent-subject: 14.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 28326.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-ft-c2spo-target-sent-subject: 27.214\n",
      "llama-ft-c2spo-target-sent-subject: 13.166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 31035.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-ft-c4spo-target-sent-subject: 26.375\n",
      "llama-ft-c4spo-target-sent-subject: 13.601\n",
      "Results saved for llama-ft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 25442.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-ft-cso-base: 17.727\n",
      "bart-ft-cso-base: 5.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 25054.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-ft-c2spo-base: 16.943\n",
      "bart-ft-c2spo-base: 3.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 25890.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-ft-c4spo-base: 16.532\n",
      "bart-ft-c4spo-base: 2.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 26668.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-ft-c2spo-subject: 28.003\n",
      "bart-ft-c2spo-subject: 17.341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 28510.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-ft-c4spo-subject: 29.767\n",
      "bart-ft-c4spo-subject: 18.499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 27209.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-ft-c2spo-target-phrase: 19.295\n",
      "bart-ft-c2spo-target-phrase: 6.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 28814.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-ft-c4spo-target-phrase: 19.756\n",
      "bart-ft-c4spo-target-phrase: 7.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 28318.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-ft-c2spo-target-sent: 17.935\n",
      "bart-ft-c2spo-target-sent: 3.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 28288.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-ft-c4spo-target-sent: 18.626\n",
      "bart-ft-c4spo-target-sent: 6.064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 26456.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-ft-cso-target-sent-target: 19.287\n",
      "bart-ft-cso-target-sent-target: 5.283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 31683.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-ft-c2spo-target-sent-target: 20.138\n",
      "bart-ft-c2spo-target-sent-target: 7.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 30909.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-ft-c4spo-target-sent-target: 19.709\n",
      "bart-ft-c4spo-target-sent-target: 7.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 28554.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-ft-cso-target-sent-subject: 30.57\n",
      "bart-ft-cso-target-sent-subject: 18.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 30246.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-ft-c2spo-target-sent-subject: 29.786\n",
      "bart-ft-c2spo-target-sent-subject: 18.353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 33176.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bart-ft-c4spo-target-sent-subject: 32.098\n",
      "bart-ft-c4spo-target-sent-subject: 20.242\n",
      "Results saved for bart-ft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 23917.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-cso-base: 16.894\n",
      "llama-instruct-few-shot-cso-base: 3.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 22497.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2spo-base: 13.904\n",
      "llama-instruct-few-shot-c2spo-base: 2.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 23508.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4spo-base: 13.147\n",
      "llama-instruct-few-shot-c4spo-base: 1.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 22688.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2spo-subject: 19.164\n",
      "llama-instruct-few-shot-c2spo-subject: 6.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 25007.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4spo-subject: 21.659\n",
      "llama-instruct-few-shot-c4spo-subject: 8.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 22141.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2spo-target-phrase: 17.8\n",
      "llama-instruct-few-shot-c2spo-target-phrase: 6.161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 23878.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4spo-target-phrase: 16.099\n",
      "llama-instruct-few-shot-c4spo-target-phrase: 4.862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 22763.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2spo-target-sent: 14.802\n",
      "llama-instruct-few-shot-c2spo-target-sent: 2.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 23888.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4spo-target-sent: 13.832\n",
      "llama-instruct-few-shot-c4spo-target-sent: 2.062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 22902.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-cso-target-sent-target: 18.521\n",
      "llama-instruct-few-shot-cso-target-sent-target: 6.846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 23101.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2spo-target-sent-target: 14.342\n",
      "llama-instruct-few-shot-c2spo-target-sent-target: 2.681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 24451.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4spo-target-sent-target: 14.36\n",
      "llama-instruct-few-shot-c4spo-target-sent-target: 2.841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 22640.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-cso-target-sent-subject: 22.549\n",
      "llama-instruct-few-shot-cso-target-sent-subject: 9.723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 23145.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2spo-target-sent-subject: 18.823\n",
      "llama-instruct-few-shot-c2spo-target-sent-subject: 7.435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 25084.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4spo-target-sent-subject: 20.699\n",
      "llama-instruct-few-shot-c4spo-target-sent-subject: 7.653\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from sacrebleu.tokenizers.tokenizer_13a import Tokenizer13a\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 13a tokenizer\n",
    "tokenizer = Tokenizer13a()\n",
    "smoothing_function = SmoothingFunction().method1\n",
    "\n",
    "for model in models: \n",
    "    df_res = pd.read_csv(f\"data/results/{model}-results.csv\")\n",
    "    for setting_key, ds_values in setting_ds_dict.items():\n",
    "        for ds in ds_values:\n",
    "            \n",
    "            all_refs = []\n",
    "            all_preds = []\n",
    "            output_name = f\"{ds}-{setting_key}\"\n",
    "            df_gen = pd.read_csv(f\"data/gen_predictions/predictions_{model}-{output_name}.csv\")\n",
    " \n",
    "            for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "                ref = row['elaboration_sentence']\n",
    "                prediction = row['pred_elaboration'] # \"prediction\" for BART\n",
    "            \n",
    "                # Tokenize\n",
    "                tokenized_ref = tokenizer(ref).split()\n",
    "                tokenized_pred = tokenizer(prediction).split()\n",
    "                \n",
    "                all_refs.append([tokenized_ref]) \n",
    "                all_preds.append(tokenized_pred)\n",
    "            \n",
    "            bleu1_score = corpus_bleu(all_refs, all_preds, weights=(1.0, 0, 0, 0), smoothing_function=smoothing_function)  # 1-gram\n",
    "            bleu2_score = corpus_bleu(all_refs, all_preds, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothing_function)  # 2-gram\n",
    "            bleu4_score = corpus_bleu(all_refs, all_preds, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothing_function)  # 4-gram\n",
    "\n",
    "            idx = df_res.index[df_res[\"dataset\"] == ds].tolist()[0]\n",
    "            df_res.at[idx, f\"{setting_key}-b1\"] = round(bleu1_score*100,3)\n",
    "            df_res.at[idx, f\"{setting_key}-b2\"] = round(bleu2_score*100,3)\n",
    "            print(f\"{model}-{ds}-{setting_key}: {round(bleu1_score*100,3)}\")\n",
    "            print(f\"{model}-{ds}-{setting_key}: {round(bleu2_score*100,3)}\")\n",
    "    \n",
    "    df_res.to_csv(f\"data/results/{model}-results.csv\",index=False)\n",
    "    print(f\"Results saved for {model}\")\n",
    "#print(f\"Corpus BLEU-1: {bleu1_score*100:.3f}\")\n",
    "#print(f\"Corpus BLEU-2: {bleu2_score*100:.3f}\")\n",
    "#print(f\"Corpus BLEU-4: {bleu4_score*100:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c8c158-b794-4632-abab-f663775172fd",
   "metadata": {},
   "source": [
    "## Sentence bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeb8fb3c-5bfc-4d81-8745-3153c048a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scores_df(df_gen):\n",
    "    df_scores = pd.DataFrame({\n",
    "        'source_text': df_gen['source_text'] if 'source_text' in df_gen else None,\n",
    "        'target_sentence': (\n",
    "            df_gen['target_sentence_4o'] if 'target_sentence_4o' in df_gen\n",
    "            else df_gen['target_sentence'] if 'target_sentence' in df_gen\n",
    "            else None\n",
    "        ),\n",
    "        'target_sentence_target': df_gen['target_sentence_target'] if 'target_sentence_target' in df_gen else None,\n",
    "        'subject': df_gen['subject'] if 'subject' in df_gen else None,\n",
    "        'target-phrase': df_gen['target-phrase'] if 'target-phrase' in df_gen else None,\n",
    "        'elaboration_sentence': df_gen['elaboration_sentence'],\n",
    "        'pred_elaboration': df_gen['pred_elaboration'],\n",
    "    })\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9afc752-4beb-4c50-afd4-a2375c16c867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1004930c1094d218971251920ae76aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa5d568f9554033a4060b54b0742617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63abd8b41fe74c7e89269d4b9abe849c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02a560816f34a84a61777a5c7deb738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dccc3d037914a51a731c931a99cd5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f0487b56b84d01acbb532bb8beb933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd5361e99df4b4495c09af1c4aa0ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15bad42bbcd4fc1a78e184245eba808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f948d853994eacbce760ee1b10b18e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cceeeec2aa4408088681bf27e713411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b7f1670bfd4572ab86db1ed86415e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db7e8543bbd462d97bc184eca5dfccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5535400bded2471c9c7c2d23f2091b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69204f9b9c2040e9ba1f6331d47c0ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5d0a28ffca4149be524451307a5949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa9467fed79468696d709c1f8155bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from sacrebleu.tokenizers.tokenizer_13a import Tokenizer13a\n",
    "from transformers import BartTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# 13a tokenizer\n",
    "tokenizer = Tokenizer13a()\n",
    "# bart tokenizer\n",
    "#tokenizer_b = BartTokenizer.from_pretrained('facebook/bart-base',use_fast=False) \n",
    "\n",
    "smoothing_function = SmoothingFunction().method1\n",
    "models = [\"llama-ft\",\"bart-ft\"]\n",
    "for model in models: \n",
    "    for setting_key, ds_values in setting_ds_dict.items():\n",
    "        for ds in ds_values:\n",
    "\n",
    "            bleu_scores_1 = []\n",
    "            bleu_scores_2 = []\n",
    "            bleu_scores_4 = []\n",
    "            \n",
    "            output_name = f\"{ds}-{setting_key}\"\n",
    "            df_gen = pd.read_csv(f\"../data/gen_predictions/predictions_{model}-{output_name}.csv\")\n",
    "            df_scores = create_scores_df(df_gen)\n",
    "            for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "                ref = row['elaboration_sentence']\n",
    "                prediction = row['pred_elaboration']\n",
    "            \n",
    "                # tokenize\n",
    "                tokenized_ref = tokenizer(ref).split()\n",
    "                tokenized_pred = tokenizer(prediction).split()\n",
    "                #tokenized_ref = tokenizer_b(ref)[\"input_ids\"]\n",
    "                #tokenized_pred = tokenizer_b(prediction)[\"input_ids\"]\n",
    "                    \n",
    "                bleu_score_1 = sentence_bleu([tokenized_ref],tokenized_pred,weights=(1, 0, 0, 0),smoothing_function=smoothing_function) # 1-gram\n",
    "                bleu_score_2 = sentence_bleu([tokenized_ref],tokenized_pred,weights=(0.5, 0.5, 0, 0), smoothing_function=smoothing_function) # 2-gram\n",
    "                bleu_score_4 = sentence_bleu([tokenized_ref],tokenized_pred,weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothing_function) # 4-gram\n",
    "                bleu_scores_1.append(round(bleu_score_1,3))\n",
    "                bleu_scores_2.append(round(bleu_score_2,3))\n",
    "                bleu_scores_4.append(bleu_score_4)\n",
    "\n",
    "            df_scores[\"b1\"] = bleu_scores_1\n",
    "            df_scores[\"b2\"] = bleu_scores_2\n",
    "            df_scores.to_csv(f\"../data/bleu_scores/bleu_scores_{model}-{output_name}.csv\",index=False)\n",
    "            print(f\"Results saved for {model}\")\n",
    "\n",
    "#import numpy as np\n",
    "#print(f\"Average BLEU-1 score: {np.mean(bleu_scores_1)*100:.3f}\")\n",
    "#print(f\"Average BLEU-2 score: {np.mean(bleu_scores_2)*100:.3f}\")\n",
    "#print(f\"Average BLEU-4 score: {np.mean(bleu_scores_4)*100:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360d3f12-d76c-4a6a-b0c9-ecbd5b6f8680",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd1d553d-8e8d-4e71-a276-692fe5505a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scores_df(df_gen):\n",
    "    df_scores = pd.DataFrame({\n",
    "        'source_text': df_gen['source_text'] if 'source_text' in df_gen else None,\n",
    "        'target_sentence': (\n",
    "            df_gen['target_sentence_4o'] if 'target_sentence_4o' in df_gen\n",
    "            else df_gen['target_sentence'] if 'target_sentence' in df_gen\n",
    "            else None\n",
    "        ),\n",
    "        'target_sentence_target': df_gen['target_sentence_target'] if 'target_sentence_target' in df_gen else None,\n",
    "        'subject': df_gen['subject'] if 'subject' in df_gen else None,\n",
    "        'target-phrase': df_gen['target-phrase'] if 'target-phrase' in df_gen else None,\n",
    "        'elaboration_sentence': df_gen['elaboration_sentence'],\n",
    "        'pred_elaboration': df_gen['pred_elaboration'],\n",
    "    })\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1be5f7b1-d0a0-4b93-9834-5b103dccb8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4bf929fa15c43cc925554d60b064762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7dbfb7a1a2c4b3ca95665a56bcf34e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916af50bc6144ef0950ac74aedffb95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654cd8467ce7422388b87a0389b858ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07bf278e18a444fb2b673838a99bf63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5640b32f6443b2b4c89cf1a6ae4bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99083835a1d0472fa60ab08629da0329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e081154a1fd84e948b003b943059d637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00430f16b4f04e8b9432c8ccc074cb19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a1653351a841bb9dd45b34110396c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5b604f20294648a846d0ab59ca7692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdb7f1fd01c48eca4f8cac2829246cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02bf1e62f5024a2b8c8fdf4f08fe9ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d012e28d4424ff6b5d55848444d5e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03bf4a7c85b43318d632ba521ad1b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfba8350bd54f5f85332dd8ca093341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from bert_score import BERTScorer\n",
    "import numpy as np\n",
    "from transformers import logging\n",
    "\n",
    "# suppress warnings\n",
    "#logging.set_verbosity_error()\n",
    "\n",
    "scorer = BERTScorer(model_type='bert-base-uncased',device='cuda:0')\n",
    "\n",
    "for model in models: \n",
    "    #df_res = pd.read_csv(f\"../data/results/{model}-results.csv\")\n",
    "    for setting_key, ds_values in setting_ds_dict.items():\n",
    "        for ds in ds_values:\n",
    "            \n",
    "            bert_scores_precision = []\n",
    "            bert_scores_recall = []\n",
    "            bert_scores_f1 = []\n",
    "            \n",
    "            output_name = f\"{ds}-{setting_key}\"\n",
    "            df_gen = pd.read_csv(f\"../data/gen_predictions/predictions_{model}-{output_name}.csv\")\n",
    "            df_scores = create_scores_df(df_gen)\n",
    "            \n",
    "            for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "                elaboration = row['elaboration_sentence']\n",
    "                prediction = row['pred_elaboration']\n",
    "                \n",
    "                #  BERTScore for this pair\n",
    "                P, R, F1 = scorer.score(\n",
    "                    cands=[prediction],  \n",
    "                    refs=[elaboration],              \n",
    "                )\n",
    "                \n",
    "                bert_scores_precision.append(P.mean().item())\n",
    "                bert_scores_recall.append(R.mean().item())\n",
    "                bert_scores_f1.append(F1.mean().item())\n",
    "\n",
    "            # save result for each pair\n",
    "            df_scores[\"bsprec\"] = bert_scores_precision\n",
    "            df_scores[\"bsrec\"] = bert_scores_recall\n",
    "            df_scores[\"bsf1\"] = bert_scores_f1\n",
    "            df_scores.to_csv(f\"../data/bert_scores/bert_scores_{model}-{output_name}.csv\",index=False)\n",
    "            print(f\"Results saved for {model}\")\n",
    "            \n",
    "            # save average scores to models general results \n",
    "            \"\"\"avg_precision = np.mean(bert_scores_precision)\n",
    "            avg_recall = np.mean(bert_scores_recall)\n",
    "            avg_f1 = np.mean(bert_scores_f1)\n",
    "\n",
    "            idx = df_res.index[df_res[\"dataset\"] == ds].tolist()[0]\n",
    "            df_res.at[idx, f\"{setting_key}-bsprec\"] = round(avg_precision,3)\n",
    "            df_res.at[idx, f\"{setting_key}-bsrec\"] = round(avg_recall,3)\n",
    "            df_res.at[idx, f\"{setting_key}-bsf1\"] = round(avg_f1,3)\n",
    "            print(f\"{model}-{ds}-{setting_key}: {round(avg_f1,3)}\")\n",
    "\n",
    "    df_res.to_csv(f\"data/results/{model}-results.csv\",index=False)\n",
    "    print(f\"Results saved for {model}\")\"\"\"\n",
    "#print(f\"Average BERTScore Precision: {avg_precision:.3f}\")\n",
    "#print(f\"Average BERTScore Recall: {avg_recall:.3f}\")\n",
    "#print(f\"Average BERTScore F1: {avg_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce7f11f-1b22-44da-a795-18d7c32ebf29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# BARTScore\n",
    "\n",
    "https://github.com/neulab/BARTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfd15a0c-5501-4d47-9779-c502fe7c28c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scores_df(df_gen):\n",
    "    df_scores = pd.DataFrame({\n",
    "        'source_text': df_gen['source_text'] if 'source_text' in df_gen else None,\n",
    "        'target_sentence': (\n",
    "            df_gen['target_sentence_4o'] if 'target_sentence_4o' in df_gen\n",
    "            else df_gen['target_sentence'] if 'target_sentence' in df_gen\n",
    "            else None\n",
    "        ),\n",
    "        'target_sentence_target': df_gen['target_sentence_target'] if 'target_sentence_target' in df_gen else None,\n",
    "        'subject': df_gen['subject'] if 'subject' in df_gen else None,\n",
    "        'target-phrase': df_gen['target-phrase'] if 'target-phrase' in df_gen else None,\n",
    "        'elaboration_sentence': df_gen['elaboration_sentence'],\n",
    "        'pred_elaboration': df_gen['pred_elaboration'],\n",
    "    })\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be4bdf9a-2abc-48d0-ae2f-bac7516bcc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203c9dbd9ebd49abaa9fffedc45ec68a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-cs-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bab0b1f2ffd409c8e90d0645fbec6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c4s-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789535eb46c14e2c908a69057e12e086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c4s-subject\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf3142569d14e8aa7dd05b369285369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c4s-target-phrase\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108e5a87df044f78a93948f14ac526bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c4s-target-sent\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8bcc252cf744d13a99d48c645c9d4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c4sp-target-sent-target\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abc1c19628c4313910d10fe352221f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c2sp-target-sent-subject\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec29d4f47394b5f9cbe39dc2dedeff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for llama-ft-c4spo-target-sent-subject\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ececdc1ba354f8aaac1c1797b4c9ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-cs-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08cde0d2a898406c8b824b074f034dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c4s-base\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0934d4e5f24ee1bb3fc2dba0af09fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c4s-subject\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186cf8b467354ab99198659a5ae8a8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c4s-target-phrase\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febe834a42954652bbaab3a4b466ae45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c4s-target-sent\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269f5feb19b248979b78861c8ac227b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c4sp-target-sent-target\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0274c3229cad4919b1fdcf66195b745b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c2sp-target-sent-subject\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56b780822b84f558bae61406e8e37bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved for bart-ft-c4spo-target-sent-subject\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath('..')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils.bart_score import BARTScorer\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "bart_scorer = BARTScorer(device='cuda:0')\n",
    "\n",
    "for model in models: \n",
    "    #df_res = pd.read_csv(f\"data/results/{model}-results.csv\")\n",
    "    for setting_key, ds_values in setting_ds_dict.items():\n",
    "        for ds in ds_values:\n",
    "            bart_scores = []\n",
    "            output_name = f\"{ds}-{setting_key}\"\n",
    "            df_gen = pd.read_csv(f\"data/gen_predictions/predictions_{model}-{output_name}.csv\")\n",
    "            df_scores = create_scores_df(df_gen)\n",
    "        \n",
    "            for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "                reference = row['elaboration_sentence']  # reference text (r)\n",
    "                hypothesis = row['pred_elaboration']    # generated text (h)\n",
    "                \n",
    "                # precision (r â†’ h)\n",
    "                precision_score = bart_scorer.score(\n",
    "                    srcs=[reference],  # r as source\n",
    "                    tgts=[hypothesis], # h as target\n",
    "                    batch_size=1\n",
    "                )[0]\n",
    "                \n",
    "                # recall (h â†’ r)\n",
    "                recall_score = bart_scorer.score(\n",
    "                    srcs=[hypothesis],  # h as source\n",
    "                    tgts=[reference],   # r as target\n",
    "                    batch_size=1\n",
    "                )[0]\n",
    "                \n",
    "                # f1 score as the average of precision and recall\n",
    "                f1_score = (precision_score + recall_score) / 2\n",
    "                bart_scores.append(f1_score)\n",
    "            \n",
    "            # save result for each pair\n",
    "            df_scores[\"bartscore\"] = bart_scores\n",
    "            df_scores.to_csv(f\"data/bart_scores/bart_scores_{model}-{output_name}.csv\",index=False)\n",
    "            print(f\"Results saved for {model}-{output_name}\")\n",
    "        \n",
    "            \"\"\"# average score\n",
    "            avg_score = np.mean(bart_scores)\n",
    "            idx = df_res.index[df_res[\"dataset\"] == ds].tolist()[0]\n",
    "            df_res.at[idx, f\"{setting_key}-bartscore\"] = round(avg_score,3)\n",
    "            print(f\"{model}-{ds}-{setting_key}: {round(avg_score,3)}\")\n",
    "    \n",
    "    df_res.to_csv(f\"data/results/{model}-results.csv\",index=False)\n",
    "    print(f\"Results saved for {model}\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586a887a-f36a-4031-8719-8515839ecf9e",
   "metadata": {},
   "source": [
    "# Prompt evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d9ebc-496e-43b3-a226-22362a2b4d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scores_df(df_gen):\n",
    "    df_scores = pd.DataFrame({\n",
    "        'source_text': df_gen['source_text'] if 'source_text' in df_gen else None,\n",
    "        'target_sentence': (\n",
    "            df_gen['target_sentence_4o'] if 'target_sentence_4o' in df_gen\n",
    "            else df_gen['target_sentence'] if 'target_sentence' in df_gen\n",
    "            else None\n",
    "        ),\n",
    "        'target_sentence_target': df_gen['target_sentence_target'] if 'target_sentence_target' in df_gen else None,\n",
    "        'subject': df_gen['subject'] if 'subject' in df_gen else None,\n",
    "        'target-phrase': df_gen['target-phrase'] if 'target-phrase' in df_gen else None,\n",
    "        'elaboration_sentence': df_gen['elaboration_sentence'],\n",
    "        'pred_elaboration': df_gen['pred_elaboration'],\n",
    "    })\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1fea1e-d333-4998-8a58-d65e0cb6f3a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d55eed-5b5a-4299-9f91-a5f3d58eb1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 12507.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2s-short: 15.899\n",
      "llama-instruct-few-shot-c2s-short: 3.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 17227.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2sp-short: 15.266\n",
      "llama-instruct-few-shot-c2sp-short: 3.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 18302.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4s-short: 15.712\n",
      "llama-instruct-few-shot-c4s-short: 2.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 17557.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4sp-short: 15.233\n",
      "llama-instruct-few-shot-c4sp-short: 1.652\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 15398.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2s-long: 15.161\n",
      "llama-instruct-few-shot-c2s-long: 4.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 16751.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2sp-long: 14.368\n",
      "llama-instruct-few-shot-c2sp-long: 4.223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 17745.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4s-long: 14.507\n",
      "llama-instruct-few-shot-c4s-long: 4.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 17717.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4sp-long: 13.268\n",
      "llama-instruct-few-shot-c4sp-long: 3.145\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 17960.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2s-random: 14.945\n",
      "llama-instruct-few-shot-c2s-random: 2.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 19517.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2sp-random: 13.931\n",
      "llama-instruct-few-shot-c2sp-random: 2.704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 17973.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4s-random: 14.055\n",
      "llama-instruct-few-shot-c4s-random: 3.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 116/116 [00:00<00:00, 20536.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4sp-random: 13.595\n",
      "llama-instruct-few-shot-c4sp-random: 3.055\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from sacrebleu.tokenizers.tokenizer_13a import Tokenizer13a\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 13a tokenizer\n",
    "tokenizer = Tokenizer13a()\n",
    "smoothing_function = SmoothingFunction().method1\n",
    "\n",
    "# prompt evaluation\n",
    "models = [\"llama-instruct-few-shot\"]\n",
    "setting_ds_dict = {\n",
    "    \"short\":{\"base\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"]},\n",
    "    \"long\":{\"base\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"]},\n",
    "    \"random\":{\"base\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"]},\n",
    "}\n",
    "\n",
    "for model in models: \n",
    "    df_res = pd.read_csv(f\"../data/results/{model}-prompt-results.csv\")\n",
    "    for prompt_setting_key, setting_keys in setting_ds_dict.items():\n",
    "        for setting_key, ds_values in setting_keys.items():\n",
    "            for ds in ds_values:\n",
    "            \n",
    "                all_refs = []\n",
    "                all_preds = []\n",
    "                output_name = f\"{ds}-{setting_key}\"\n",
    "                # read-in right df\n",
    "                if prompt_setting_key == \"long\":\n",
    "                    df_gen = pd.read_csv(f\"../data/gen_predictions/predictions_{model}-{output_name}_longprompt.csv\")\n",
    "                elif prompt_setting_key == \"random\":\n",
    "                    df_gen = pd.read_csv(f\"../data/gen_predictions/predictions_{model}-{output_name}_randomprompt.csv\")\n",
    "                else:\n",
    "                    df_gen = pd.read_csv(f\"../data/gen_predictions/predictions_{model}-{output_name}.csv\")\n",
    "     \n",
    "                for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "                    ref = row['elaboration_sentence']\n",
    "                    prediction = row['pred_elaboration'] \n",
    "                \n",
    "                    # Tokenize\n",
    "                    tokenized_ref = tokenizer(ref).split()\n",
    "                    tokenized_pred = tokenizer(prediction).split()\n",
    "                    \n",
    "                    all_refs.append([tokenized_ref]) \n",
    "                    all_preds.append(tokenized_pred)\n",
    "                \n",
    "                bleu1_score = corpus_bleu(all_refs, all_preds, weights=(1.0, 0, 0, 0), smoothing_function=smoothing_function)  # 1-gram\n",
    "                bleu2_score = corpus_bleu(all_refs, all_preds, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothing_function)  # 2-gram\n",
    "                bleu4_score = corpus_bleu(all_refs, all_preds, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothing_function)  # 4-gram\n",
    "    \n",
    "                idx = df_res.index[df_res[\"dataset\"] == ds].tolist()[0]\n",
    "                df_res.at[idx, f\"{prompt_setting_key}-b1\"] = round(bleu1_score*100,3)\n",
    "                df_res.at[idx, f\"{prompt_setting_key}-b2\"] = round(bleu2_score*100,3)\n",
    "                print(f\"{model}-{ds}-{prompt_setting_key} B1: {round(bleu1_score*100,3)}\")\n",
    "                print(f\"{model}-{ds}-{prompt_setting_key} B2: {round(bleu2_score*100,3)}\")\n",
    "        \n",
    "        df_res.to_csv(f\"../data/results/{model}-prompt-results.csv\",index=False)\n",
    "        print(f\"Results saved for {model}\")\n",
    "    #print(f\"Corpus BLEU-1: {bleu1_score*100:.3f}\")\n",
    "    #print(f\"Corpus BLEU-2: {bleu2_score*100:.3f}\")\n",
    "    #print(f\"Corpus BLEU-4: {bleu4_score*100:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8048c72b-c83d-4a5b-b9b4-cd444aca238d",
   "metadata": {},
   "source": [
    "## BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ac165ff-8341-4681-a8a7-08c13e5bd762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79470166d3ad4537a1c4b31c4a826323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2s-short: 0.475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba486840f6ac4ae0a5922e604f4e42ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2sp-short: 0.456\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d6fe288bbc4b0e985bcb85008ec626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4s-short: 0.461\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a5cb0929e145faa867bdac3081ee98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4sp-short: 0.447\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79dd239ab1e3488ebe609b1561dc3a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2s-long: 0.446\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973545d1915746a49afcb70902cecd7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2sp-long: 0.439\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243b58e465e44e00b5e3cb3a53496b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4s-long: 0.443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081cdb3b7d7340209ff903ccf49751b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4sp-long: 0.434\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f4fae3e88d4fe9b00bcf324195bb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2s-random: 0.436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8838e33552f42aaadc03c941533fb49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2sp-random: 0.438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1669f8822f3244d49136a00e14e45ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4s-random: 0.442\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47f1d2eb58644dda13783702afa8b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4sp-random: 0.435\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from bert_score import BERTScorer\n",
    "import numpy as np\n",
    "from transformers import logging\n",
    "\n",
    "# suppress warnings\n",
    "#logging.set_verbosity_error()\n",
    "\n",
    "scorer = BERTScorer(model_type='bert-base-uncased',device='cuda:0')\n",
    "\n",
    "# prompt evaluation\n",
    "models = [\"llama-instruct-few-shot\"]\n",
    "setting_ds_dict = {\n",
    "    \"short\":{\"base\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"]},\n",
    "    \"long\":{\"base\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"]},\n",
    "    \"random\":{\"base\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"]},\n",
    "}\n",
    "\n",
    "\n",
    "for model in models: \n",
    "    df_res = pd.read_csv(f\"../data/results/{model}-prompt-results.csv\")\n",
    "    for prompt_setting_key, setting_keys in setting_ds_dict.items():\n",
    "        for setting_key, ds_values in setting_keys.items():\n",
    "            for ds in ds_values:\n",
    "            \n",
    "                bert_scores_precision = []\n",
    "                bert_scores_recall = []\n",
    "                bert_scores_f1 = []\n",
    "                \n",
    "                output_name = f\"{ds}-{setting_key}\"\n",
    "                # read-in right df\n",
    "                if prompt_setting_key == \"long\":\n",
    "                    df_gen = pd.read_csv(f\"../data/gen_predictions/predictions_{model}-{output_name}_longprompt.csv\")\n",
    "                elif prompt_setting_key == \"random\":\n",
    "                    df_gen = pd.read_csv(f\"../data/gen_predictions/predictions_{model}-{output_name}_randomprompt.csv\")\n",
    "                else:\n",
    "                    df_gen = pd.read_csv(f\"../data/gen_predictions/predictions_{model}-{output_name}.csv\")\n",
    "\n",
    "                #df_scores = create_scores_df(df_gen)\n",
    "                \n",
    "                for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "                    elaboration = row['elaboration_sentence']\n",
    "                    prediction = row['pred_elaboration']\n",
    "                    \n",
    "                    #  BERTScore for this pair\n",
    "                    P, R, F1 = scorer.score(\n",
    "                        cands=[prediction],  \n",
    "                        refs=[elaboration],              \n",
    "                    )\n",
    "                    \n",
    "                    bert_scores_precision.append(P.mean().item())\n",
    "                    bert_scores_recall.append(R.mean().item())\n",
    "                    bert_scores_f1.append(F1.mean().item())\n",
    "    \n",
    "                # save result for each pair\n",
    "                #df_scores[\"bsprec\"] = bert_scores_precision\n",
    "                #df_scores[\"bsrec\"] = bert_scores_recall\n",
    "                #df_scores[\"bsf1\"] = bert_scores_f1\n",
    "                #df_scores.to_csv(f\"../data/bert_scores/bert_scores_{model}-{output_name}.csv\",index=False)\n",
    "                #print(f\"Results saved for {model}\")\n",
    "            \n",
    "                # save average scores to models general results \n",
    "                #avg_precision = np.mean(bert_scores_precision)\n",
    "                #avg_recall = np.mean(bert_scores_recall)\n",
    "                avg_f1 = np.mean(bert_scores_f1)\n",
    "    \n",
    "                idx = df_res.index[df_res[\"dataset\"] == ds].tolist()[0]\n",
    "                #df_res.at[idx, f\"{prompt_setting_key}-bsprec\"] = round(avg_precision,3)\n",
    "                #df_res.at[idx, f\"{prompt_setting_key}-bsrec\"] = round(avg_recall,3)\n",
    "                df_res.at[idx, f\"{prompt_setting_key}-bsf1\"] = round(avg_f1,3)\n",
    "                print(f\"{model}-{ds}-{prompt_setting_key}: {round(avg_f1,3)}\")\n",
    "    \n",
    "        df_res.to_csv(f\"../data/results/{model}-prompt-results.csv\",index=False)\n",
    "        print(f\"Results saved for {model}\")\n",
    "    #print(f\"Average BERTScore Precision: {avg_precision:.3f}\")\n",
    "    #print(f\"Average BERTScore Recall: {avg_recall:.3f}\")\n",
    "    #print(f\"Average BERTScore F1: {avg_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa16460-8fc0-47a0-a373-4d70741eadd0",
   "metadata": {},
   "source": [
    "## BARTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d35400d9-79e7-4542-946d-763811bb7632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af51d6190304096bf3b9cf77c121117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2s-short: -3.778\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53915c58da09400bb9858878b29f2288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2sp-short: -3.849\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef00377ee9244a12a38b4e22aac58afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4s-short: -3.884\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6d517724f9461a896a00399f720e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4sp-short: -3.941\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14901c8ff8104d5a8c434a435e8f1804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2s-long: -3.843\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79309f792e8411d9d18aef1e2b6b6ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2sp-long: -3.922\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99375a590b9424c9d71a6b13b89b531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4s-long: -3.9\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5839bbc28c44e68dfbe58dc3482c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4sp-long: -3.954\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39725665b9aa4176859796cf7843b115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2s-random: -4.011\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9fb031223a04feda1d6a03fb955f532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c2sp-random: -4.003\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512434ed07c049539aa28094aff2046c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4s-random: -4.023\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5387b7360547589d8b761ccecef828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot-c4sp-random: -4.044\n",
      "Results saved for llama-instruct-few-shot\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "parent_dir = os.path.abspath('..')\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils.bart_score import BARTScorer\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "bart_scorer = BARTScorer(device='cuda:0')\n",
    "\n",
    "# prompt evaluation\n",
    "models = [\"llama-instruct-few-shot\"]\n",
    "setting_ds_dict = {\n",
    "    \"short\":{\"base\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"]},\n",
    "    \"long\":{\"base\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"]},\n",
    "    \"random\":{\"base\":[\"c2s\",\"c2sp\",\"c4s\",\"c4sp\"]},\n",
    "}\n",
    "\n",
    "\n",
    "for model in models: \n",
    "    df_res = pd.read_csv(f\"data/results/{model}-prompt-results.csv\")\n",
    "    for prompt_setting_key, setting_keys in setting_ds_dict.items():\n",
    "        for setting_key, ds_values in setting_keys.items():\n",
    "            for ds in ds_values:\n",
    "\n",
    "                bart_scores = []\n",
    "                output_name = f\"{ds}-{setting_key}\"\n",
    "                # read-in right df\n",
    "                if prompt_setting_key == \"long\":\n",
    "                    df_gen = pd.read_csv(f\"data/gen_predictions/predictions_{model}-{output_name}_longprompt.csv\")\n",
    "                elif prompt_setting_key == \"random\":\n",
    "                    df_gen = pd.read_csv(f\"data/gen_predictions/predictions_{model}-{output_name}_randomprompt.csv\")\n",
    "                else:\n",
    "                    df_gen = pd.read_csv(f\"data/gen_predictions/predictions_{model}-{output_name}.csv\")\n",
    "\n",
    "                #df_scores = create_scores_df(df_gen)\n",
    "            \n",
    "                for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "                    reference = row['elaboration_sentence']  # reference text (r)\n",
    "                    hypothesis = row['pred_elaboration']    # generated text (h)\n",
    "                    \n",
    "                    # precision (r â†’ h)\n",
    "                    precision_score = bart_scorer.score(\n",
    "                        srcs=[reference],  # r as source\n",
    "                        tgts=[hypothesis], # h as target\n",
    "                        batch_size=1\n",
    "                    )[0]\n",
    "                    \n",
    "                    # recall (h â†’ r)\n",
    "                    recall_score = bart_scorer.score(\n",
    "                        srcs=[hypothesis],  # h as source\n",
    "                        tgts=[reference],   # r as target\n",
    "                        batch_size=1\n",
    "                    )[0]\n",
    "                    \n",
    "                    # f1 score as the average of precision and recall\n",
    "                    f1_score = (precision_score + recall_score) / 2\n",
    "                    bart_scores.append(f1_score)\n",
    "                \n",
    "                    # save score result for each pair\n",
    "                    #df_scores[\"bartscore\"] = bart_scores\n",
    "                    #df_scores.to_csv(f\"data/bart_scores/bart_scores_{model}-{output_name}.csv\",index=False)\n",
    "                    #print(f\"Results saved for {model}-{output_name}\")\n",
    "        \n",
    "                # average score\n",
    "                avg_score = np.mean(bart_scores)\n",
    "                idx = df_res.index[df_res[\"dataset\"] == ds].tolist()[0]\n",
    "                df_res.at[idx, f\"{prompt_setting_key}-bartscore\"] = round(avg_score,3)\n",
    "                print(f\"{model}-{ds}-{prompt_setting_key}: {round(avg_score,3)}\")\n",
    "    \n",
    "                df_res.to_csv(f\"data/results/{model}-prompt-results.csv\",index=False)\n",
    "                print(f\"Results saved for {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c47c65-4433-4c81-ba77-4739fe678a21",
   "metadata": {},
   "source": [
    "# Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cb484dd-c947-4e0e-ab15-f0350bc1d6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>short-b1</th>\n",
       "      <th>short-b2</th>\n",
       "      <th>long-b1</th>\n",
       "      <th>long-b2</th>\n",
       "      <th>random-b1</th>\n",
       "      <th>random-b2</th>\n",
       "      <th>short-bsf1</th>\n",
       "      <th>long-bsf1</th>\n",
       "      <th>random-bsf1</th>\n",
       "      <th>short-bartscore</th>\n",
       "      <th>long-bartscore</th>\n",
       "      <th>random-bartscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c2s</td>\n",
       "      <td>15.899</td>\n",
       "      <td>3.588</td>\n",
       "      <td>15.161</td>\n",
       "      <td>4.712</td>\n",
       "      <td>14.945</td>\n",
       "      <td>2.894</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.436</td>\n",
       "      <td>-3.778</td>\n",
       "      <td>-3.843</td>\n",
       "      <td>-4.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c2sp</td>\n",
       "      <td>15.266</td>\n",
       "      <td>3.515</td>\n",
       "      <td>14.368</td>\n",
       "      <td>4.223</td>\n",
       "      <td>13.931</td>\n",
       "      <td>2.704</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.438</td>\n",
       "      <td>-3.849</td>\n",
       "      <td>-3.922</td>\n",
       "      <td>-4.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c4s</td>\n",
       "      <td>15.712</td>\n",
       "      <td>2.912</td>\n",
       "      <td>14.507</td>\n",
       "      <td>4.266</td>\n",
       "      <td>14.055</td>\n",
       "      <td>3.507</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.442</td>\n",
       "      <td>-3.884</td>\n",
       "      <td>-3.900</td>\n",
       "      <td>-4.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c4sp</td>\n",
       "      <td>15.233</td>\n",
       "      <td>1.652</td>\n",
       "      <td>13.268</td>\n",
       "      <td>3.145</td>\n",
       "      <td>13.595</td>\n",
       "      <td>3.055</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.435</td>\n",
       "      <td>-3.941</td>\n",
       "      <td>-3.954</td>\n",
       "      <td>-4.044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  short-b1  short-b2  long-b1  long-b2  random-b1  random-b2  \\\n",
       "0     c2s    15.899     3.588   15.161    4.712     14.945      2.894   \n",
       "1    c2sp    15.266     3.515   14.368    4.223     13.931      2.704   \n",
       "2     c4s    15.712     2.912   14.507    4.266     14.055      3.507   \n",
       "3    c4sp    15.233     1.652   13.268    3.145     13.595      3.055   \n",
       "\n",
       "   short-bsf1  long-bsf1  random-bsf1  short-bartscore  long-bartscore  \\\n",
       "0       0.475      0.446        0.436           -3.778          -3.843   \n",
       "1       0.456      0.439        0.438           -3.849          -3.922   \n",
       "2       0.461      0.443        0.442           -3.884          -3.900   \n",
       "3       0.447      0.434        0.435           -3.941          -3.954   \n",
       "\n",
       "   random-bartscore  \n",
       "0            -4.011  \n",
       "1            -4.003  \n",
       "2            -4.023  \n",
       "3            -4.044  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a3102b2-71d4-4238-b7f5-125b84d55426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-instruct-few-shot\n"
     ]
    }
   ],
   "source": [
    "df_res.to_csv(f\"../data/results/{model}-prompt-results.csv\",index=False)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32495be-9d05-4b18-90b8-5395a57452d6",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f15d3e35-6f21-4db0-963a-2fd1de85b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    'source_text': df_gen['source_text'],\n",
    "    'elaboration_sentence': df_gen['elaboration_sentence'],\n",
    "    'pred_elaboration': df_gen['pred_elaboration'],\n",
    "    'bert-score-precision': bert_scores_precision,\n",
    "    'bert-score-recall': bert_scores_recall,\n",
    "    'bert-score-f1': bert_scores_f1\n",
    "})\n",
    "\n",
    "# bleu-scores\n",
    "#df_results.to_csv(\"../data/bleu_scores/bleu_scores_bart-ft-c2sp-masked.csv\", index=False)\n",
    "# bert-scores\n",
    "df_results.to_csv(f\"../data/bert_scores/bert_scores_{model}-test_ds-{output_name}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
