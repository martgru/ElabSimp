{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a2be0bc-d97f-4c46-9a67-919c1c7c936b",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2b2e70ca-6f23-4931-9222-5bf9440f5de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              0\n",
       "elaboration_sentence    0\n",
       "subject                 0\n",
       "target_sentence         0\n",
       "pred_elaboration        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ds = \"cs\"\n",
    "setting = \"target-sent-subject\"\n",
    "output_name = f\"{ds}-{setting}\"\n",
    "model = \"llama-instruct-few-shot\"\n",
    "test_ds_llama_ft_alpaca = pd.read_csv(f\"../data/gen_predictions/predictions_llama3.2-ft-alpaca-test_ds_{output_name}.csv\")\n",
    "test_ds_llama_instruct = pd.read_csv(f\"../data/gen_predictions/predictions_llama3.2-instruct-few-shot-test_ds_{output_name}.csv\")\n",
    "test_ds_bart = pd.read_csv(f\"../data/gen_predictions/predictions_bart-{output_name}.csv\")\n",
    "\n",
    "df_gen = test_ds_llama_instruct\n",
    "#df_gen = df_gen.fillna(\"\")\n",
    "df_gen.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc34bc-1708-4887-9218-72243a75d666",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Load results df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46aecf4-8edb-4071-8644-2f0d40b7b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_ft_res = pd.read_csv(\"../data/results/bart-ft-results.csv\")\n",
    "llama_ft_res = pd.read_csv(\"../data/results/llama-ft-results.csv\")\n",
    "llama_instr_res = pd.read_csv(\"../data/results/llama-instruct-few-shot-results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb11724e-fb2e-46ae-8975-b7d0d6010d34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Initialize columns in results dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "439234a1-51ef-4105-8be3-defc589f27f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>base-b1</th>\n",
       "      <th>base-b2</th>\n",
       "      <th>masked-b1</th>\n",
       "      <th>masked-b2</th>\n",
       "      <th>subject-b1</th>\n",
       "      <th>subject-b2</th>\n",
       "      <th>target-phrase-b1</th>\n",
       "      <th>target-phrase-b2</th>\n",
       "      <th>target-sent-b1</th>\n",
       "      <th>...</th>\n",
       "      <th>target-sent-bs-rec</th>\n",
       "      <th>target-sent-target-bs-rec</th>\n",
       "      <th>target-sent-subject-bs-rec</th>\n",
       "      <th>base-bs-f1</th>\n",
       "      <th>masked-bs-f1</th>\n",
       "      <th>subject-bs-f1</th>\n",
       "      <th>target-phrase-bs-f1</th>\n",
       "      <th>target-sent-bs-f1</th>\n",
       "      <th>target-sent-target-bs-f1</th>\n",
       "      <th>target-sent-subject-bs-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c2s</td>\n",
       "      <td>15.899</td>\n",
       "      <td>3.588</td>\n",
       "      <td>15.258</td>\n",
       "      <td>3.309</td>\n",
       "      <td>22.277</td>\n",
       "      <td>8.939</td>\n",
       "      <td>18.347</td>\n",
       "      <td>5.923</td>\n",
       "      <td>17.417</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c2sp</td>\n",
       "      <td>15.266</td>\n",
       "      <td>3.515</td>\n",
       "      <td>15.757</td>\n",
       "      <td>3.567</td>\n",
       "      <td>23.580</td>\n",
       "      <td>9.417</td>\n",
       "      <td>18.686</td>\n",
       "      <td>5.726</td>\n",
       "      <td>18.003</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c4s</td>\n",
       "      <td>15.712</td>\n",
       "      <td>2.912</td>\n",
       "      <td>14.908</td>\n",
       "      <td>4.157</td>\n",
       "      <td>22.771</td>\n",
       "      <td>8.681</td>\n",
       "      <td>17.560</td>\n",
       "      <td>5.348</td>\n",
       "      <td>18.005</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c4sp</td>\n",
       "      <td>15.233</td>\n",
       "      <td>1.652</td>\n",
       "      <td>16.923</td>\n",
       "      <td>4.930</td>\n",
       "      <td>23.323</td>\n",
       "      <td>9.918</td>\n",
       "      <td>18.652</td>\n",
       "      <td>5.758</td>\n",
       "      <td>16.861</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs</td>\n",
       "      <td>19.650</td>\n",
       "      <td>6.692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c2spo</td>\n",
       "      <td>13.904</td>\n",
       "      <td>2.192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c4spo</td>\n",
       "      <td>13.147</td>\n",
       "      <td>1.519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  base-b1  base-b2  masked-b1  masked-b2  subject-b1  subject-b2  \\\n",
       "0     c2s   15.899    3.588     15.258      3.309      22.277       8.939   \n",
       "1    c2sp   15.266    3.515     15.757      3.567      23.580       9.417   \n",
       "2     c4s   15.712    2.912     14.908      4.157      22.771       8.681   \n",
       "3    c4sp   15.233    1.652     16.923      4.930      23.323       9.918   \n",
       "4      cs   19.650    6.692        NaN        NaN         NaN         NaN   \n",
       "5   c2spo   13.904    2.192        NaN        NaN         NaN         NaN   \n",
       "6   c4spo   13.147    1.519        NaN        NaN         NaN         NaN   \n",
       "\n",
       "   target-phrase-b1  target-phrase-b2  target-sent-b1  ...  \\\n",
       "0            18.347             5.923          17.417  ...   \n",
       "1            18.686             5.726          18.003  ...   \n",
       "2            17.560             5.348          18.005  ...   \n",
       "3            18.652             5.758          16.861  ...   \n",
       "4               NaN               NaN             NaN  ...   \n",
       "5               NaN               NaN             NaN  ...   \n",
       "6               NaN               NaN             NaN  ...   \n",
       "\n",
       "   target-sent-bs-rec  target-sent-target-bs-rec  target-sent-subject-bs-rec  \\\n",
       "0                None                       None                        None   \n",
       "1                None                       None                        None   \n",
       "2                None                       None                        None   \n",
       "3                None                       None                        None   \n",
       "4                None                       None                        None   \n",
       "5                None                       None                        None   \n",
       "6                None                       None                        None   \n",
       "\n",
       "   base-bs-f1  masked-bs-f1 subject-bs-f1 target-phrase-bs-f1  \\\n",
       "0        None          None          None                None   \n",
       "1        None          None          None                None   \n",
       "2        None          None          None                None   \n",
       "3        None          None          None                None   \n",
       "4        None          None          None                None   \n",
       "5        None          None          None                None   \n",
       "6        None          None          None                None   \n",
       "\n",
       "  target-sent-bs-f1 target-sent-target-bs-f1 target-sent-subject-bs-f1  \n",
       "0              None                     None                      None  \n",
       "1              None                     None                      None  \n",
       "2              None                     None                      None  \n",
       "3              None                     None                      None  \n",
       "4              None                     None                      None  \n",
       "5              None                     None                      None  \n",
       "6              None                     None                      None  \n",
       "\n",
       "[7 rows x 36 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = pd.read_csv(f\"../data/results/{model}-results.csv\")\n",
    "settings = list(dict.fromkeys([\"-\".join(col.split(\"-\")[:-1]) for col in df_res.columns if \"-\" in col]))\n",
    "cols_to_add = [f\"{col_name}-bs-prec\" for col_name in settings] + \\\n",
    "              [f\"{col_name}-bs-rec\" for col_name in settings] + \\\n",
    "              [f\"{col_name}-bs-f1\" for col_name in settings]\n",
    "for col in cols_to_add:\n",
    "    df_res[col] = None \n",
    "\n",
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10110f52-275c-410d-9a66-5b1eff822fd9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SARI - Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf6017c1-5cc3-4970-9b74-959d1f8884c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d7b27ee24e4e3785eb09aae20a09ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/359 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evaluate import load\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "sari_metric = load(\"sari\")\n",
    "sari_scores = []\n",
    "\n",
    "for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "    r_content = row['text'] \n",
    "    s_content = dataset['test'][index] \n",
    "    prediction = row['prediction']  \n",
    "    \n",
    "    sari_score = sari_metric.compute(\n",
    "        sources=[r_content],\n",
    "        predictions=[prediction],\n",
    "        references=[s_content['simplifications']]\n",
    "    )\n",
    "    \n",
    "    sari_scores.append(sari_score['sari'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0344dde9-0b12-448a-880c-9e82df722695",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# SARI - EASSE package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21c93079-9b0a-45f4-8446-d83fad341431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fe8728a5b84524acb2902f9f54b345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'label_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/nlp/lib64/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m tqdm(df_gen\u001b[38;5;241m.\u001b[39miterrows(), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(df_gen)):\n\u001b[1;32m      8\u001b[0m     r_content \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[0;32m----> 9\u001b[0m     s_content \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m  \n\u001b[1;32m     10\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m]  \n\u001b[1;32m     12\u001b[0m     sari_score_easse \u001b[38;5;241m=\u001b[39m corpus_sari(\n\u001b[1;32m     13\u001b[0m         orig_sents\u001b[38;5;241m=\u001b[39m[r_content],\n\u001b[1;32m     14\u001b[0m         sys_sents\u001b[38;5;241m=\u001b[39m[prediction],\n\u001b[1;32m     15\u001b[0m         refs_sents\u001b[38;5;241m=\u001b[39m[[s_content]]\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m#refs_sents=[[simp] for simp in s_content['simplifications']]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     )\n",
      "File \u001b[0;32m~/nlp/lib64/python3.9/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/nlp/lib64/python3.9/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/nlp/lib64/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label_text'"
     ]
    }
   ],
   "source": [
    "from easse.sari import corpus_sari\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "sari_scores_easse = []\n",
    "\n",
    "for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "    r_content = row['source_text'] \n",
    "    s_content = row['label_text']  \n",
    "    prediction = row['prediction']  \n",
    "    \n",
    "    sari_score_easse = corpus_sari(\n",
    "        orig_sents=[r_content],\n",
    "        sys_sents=[prediction],\n",
    "        refs_sents=[[s_content]]\n",
    "        #refs_sents=[[simp] for simp in s_content['simplifications']]\n",
    "    )\n",
    "    \n",
    "    sari_scores_easse.append(sari_score_easse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2a4dc924-dcdf-4996-a704-bc8fa62f053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SARI score: 36.46781896155372\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Average SARI score:\", np.mean(sari_scores_easse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48b68e-8dad-4ca5-a0f4-3059c107d5c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Operation scores (add, keep, delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebda0d28-3b07-4479-810f-4f321c9ed5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f328a3975ef64892b8a5039c8e60ccbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from easse.sari import get_corpus_sari_operation_scores\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "add_scores = []\n",
    "keep_scores = []\n",
    "del_scores = []\n",
    "\n",
    "for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "    r_content = row['source_text'] \n",
    "    s_content = row['label_text'] #dataset['test'][index]  \n",
    "    prediction = row['prediction']  \n",
    "    \n",
    "    add_score, keep_score, del_score = get_corpus_sari_operation_scores(\n",
    "        orig_sents=[r_content],\n",
    "        sys_sents=[prediction],\n",
    "        refs_sents=[[s_content]]\n",
    "        #refs_sents=[[simp] for simp in s_content['simplifications']] \n",
    "    )\n",
    "    \n",
    "    add_scores.append(add_score)\n",
    "    keep_scores.append(keep_score)\n",
    "    del_scores.append(del_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb0cbf1-18d1-4243-8d97-1a6da6cc55aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# BLEU-4 (EASSE package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0422bbeb-5d1b-4060-abd5-e14a5a0f5789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfa32888f4f4039acffa9021cc37531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score: 4.965\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from easse.bleu import corpus_bleu\n",
    "import numpy as np\n",
    "\n",
    "bleu_scores_easse = []\n",
    "\n",
    "for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "    s_content = row['elaboration_sentence'] \n",
    "    prediction = row['pred_elaboration'] # \"prediction\" for BART\n",
    "    \n",
    "    bleu_score_easse = corpus_bleu(\n",
    "        sys_sents=[prediction],\n",
    "        refs_sents=[[s_content]]\n",
    "    )\n",
    "    \n",
    "    bleu_scores_easse.append(bleu_score_easse)\n",
    "\n",
    "print(f\"Average BLEU score: {np.mean(bleu_scores_easse):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423467a1-bd5b-45a5-9c81-c4cca2be66b9",
   "metadata": {},
   "source": [
    "### BLEU-1 & BLEU-2 (nltk + tokenizer-13A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7021e9d-90fa-4477-9c0d-ca7d046ef283",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Corpus bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "db64be6b-4a29-444a-8fd6-1fc8e9f1f940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 116/116 [00:00<00:00, 16134.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus BLEU-1: 13.147\n",
      "Corpus BLEU-2: 1.519\n",
      "Corpus BLEU-4: 0.126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "from sacrebleu.tokenizers.tokenizer_13a import Tokenizer13a\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 13a tokenizer\n",
    "tokenizer = Tokenizer13a()\n",
    "smoothing_function = SmoothingFunction().method1\n",
    "\n",
    "all_refs = []\n",
    "all_preds = []\n",
    "\n",
    "# Tokenize and collect references and predictions\n",
    "for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "    ref = row['elaboration_sentence']\n",
    "    prediction = row['pred_elaboration'] # \"prediction\" for BART\n",
    "\n",
    "    # Tokenize\n",
    "    tokenized_ref = tokenizer(ref).split()\n",
    "    tokenized_pred = tokenizer(prediction).split()\n",
    "    \n",
    "    all_refs.append([tokenized_ref]) \n",
    "    all_preds.append(tokenized_pred)\n",
    "\n",
    "bleu1_score = corpus_bleu(all_refs, all_preds, weights=(1.0, 0, 0, 0), smoothing_function=smoothing_function)  # 1-gram\n",
    "bleu2_score = corpus_bleu(all_refs, all_preds, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothing_function)  # 2-gram\n",
    "bleu4_score = corpus_bleu(all_refs, all_preds, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothing_function)  # 4-gram\n",
    "\n",
    "print(f\"Corpus BLEU-1: {bleu1_score*100:.3f}\")\n",
    "print(f\"Corpus BLEU-2: {bleu2_score*100:.3f}\")\n",
    "print(f\"Corpus BLEU-4: {bleu4_score*100:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c8c158-b794-4632-abab-f663775172fd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Sentence bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9afc752-4beb-4c50-afd4-a2375c16c867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 116/116 [00:00<00:00, 4293.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU-1 score: 16.922\n",
      "Average BLEU-2 score: 6.008\n",
      "Average BLEU-4 score: 3.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from sacrebleu.tokenizers.tokenizer_13a import Tokenizer13a\n",
    "from transformers import BartTokenizer\n",
    "\n",
    "bleu_scores_1 = []\n",
    "bleu_scores_2 = []\n",
    "bleu_scores_4 = []\n",
    "\n",
    "# 13a tokenizer\n",
    "tokenizer = Tokenizer13a()\n",
    "# bart tokenizer\n",
    "#tokenizer_b = BartTokenizer.from_pretrained('facebook/bart-base',use_fast=False) \n",
    "\n",
    "smoothing_function = SmoothingFunction().method1\n",
    "\n",
    "for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "    ref = row['elaboration_sentence']\n",
    "    prediction = row['pred_elaboration']\n",
    "\n",
    "    # tokenize\n",
    "    tokenized_ref = tokenizer(ref).split()\n",
    "    tokenized_pred = tokenizer(prediction).split()\n",
    "    #tokenized_ref = tokenizer_b(ref)[\"input_ids\"]\n",
    "    #tokenized_pred = tokenizer_b(prediction)[\"input_ids\"]\n",
    "        \n",
    "    bleu_score_1 = sentence_bleu([tokenized_ref],tokenized_pred,weights=(1, 0, 0, 0),smoothing_function=smoothing_function) # 1-gram\n",
    "    bleu_score_2 = sentence_bleu([tokenized_ref],tokenized_pred,weights=(0.5, 0.5, 0, 0), smoothing_function=smoothing_function) # 2-gram\n",
    "    bleu_score_4 = sentence_bleu([tokenized_ref],tokenized_pred,weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothing_function) # 4-gram\n",
    "    bleu_scores_1.append(bleu_score_1)\n",
    "    bleu_scores_2.append(bleu_score_2)\n",
    "    bleu_scores_4.append(bleu_score_4)\n",
    "\n",
    "import numpy as np\n",
    "print(f\"Average BLEU-1 score: {np.mean(bleu_scores_1)*100:.3f}\")\n",
    "print(f\"Average BLEU-2 score: {np.mean(bleu_scores_2)*100:.3f}\")\n",
    "print(f\"Average BLEU-4 score: {np.mean(bleu_scores_4)*100:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2287fea0-fcbe-451e-b08a-6583c6a51751",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    'elaboration_sentence': df_gen['elaboration_sentence'],\n",
    "    'pred_elaboration': df_gen['pred_elaboration'],\n",
    "    'bleu-1': bleu_scores_1,\n",
    "    'bleu-2': bleu_scores_2,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360d3f12-d76c-4a6a-b0c9-ecbd5b6f8680",
   "metadata": {},
   "source": [
    "# BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1be5f7b1-d0a0-4b93-9834-5b103dccb8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63f0743719e4e8f871329ff219e5473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BERTScore Precision: 0.505\n",
      "Average BERTScore Recall: 0.537\n",
      "Average BERTScore F1: 0.518\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from bert_score import BERTScorer\n",
    "import numpy as np\n",
    "from transformers import logging\n",
    "\n",
    "# suppress warnings\n",
    "#logging.set_verbosity_error()\n",
    "\n",
    "bert_scores_precision = []\n",
    "bert_scores_recall = []\n",
    "bert_scores_f1 = []\n",
    "\n",
    "scorer = BERTScorer(model_type='bert-base-uncased')\n",
    "\n",
    "for index, row in tqdm(df_gen.iterrows(), total=len(df_gen)):\n",
    "    elaboration = row['elaboration_sentence']\n",
    "    prediction = row['pred_elaboration']\n",
    "    \n",
    "    #  BERTScore for this pair\n",
    "    P, R, F1 = scorer.score(\n",
    "        cands=[prediction],  \n",
    "        refs=[elaboration],              \n",
    "    )\n",
    "    \n",
    "    bert_scores_precision.append(P.mean().item())\n",
    "    bert_scores_recall.append(R.mean().item())\n",
    "    bert_scores_f1.append(F1.mean().item())\n",
    "\n",
    "# average scores\n",
    "avg_precision = np.mean(bert_scores_precision)\n",
    "avg_recall = np.mean(bert_scores_recall)\n",
    "avg_f1 = np.mean(bert_scores_f1)\n",
    "\n",
    "idx = df_res.index[df_res[\"dataset\"] == ds].tolist()[0]\n",
    "df_res.at[idx, f\"{setting}-bs-prec\"] = round(avg_precision,3)\n",
    "df_res.at[idx, f\"{setting}-bs-rec\"] = round(avg_recall,3)\n",
    "df_res.at[idx, f\"{setting}-bs-f1\"] = round(avg_f1,3)\n",
    "\n",
    "print(f\"Average BERTScore Precision: {avg_precision:.3f}\")\n",
    "print(f\"Average BERTScore Recall: {avg_recall:.3f}\")\n",
    "print(f\"Average BERTScore F1: {avg_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce7f11f-1b22-44da-a795-18d7c32ebf29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# BARTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4bdf9a-2abc-48d0-ae2f-bac7516bcc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89c47c65-4433-4c81-ba77-4739fe678a21",
   "metadata": {},
   "source": [
    "# Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "66f7f255-2a60-4378-a948-2979f605f5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>base-b1</th>\n",
       "      <th>base-b2</th>\n",
       "      <th>masked-b1</th>\n",
       "      <th>masked-b2</th>\n",
       "      <th>subject-b1</th>\n",
       "      <th>subject-b2</th>\n",
       "      <th>target-phrase-b1</th>\n",
       "      <th>target-phrase-b2</th>\n",
       "      <th>target-sent-b1</th>\n",
       "      <th>...</th>\n",
       "      <th>target-sent-bs-rec</th>\n",
       "      <th>target-sent-target-bs-rec</th>\n",
       "      <th>target-sent-subject-bs-rec</th>\n",
       "      <th>base-bs-f1</th>\n",
       "      <th>masked-bs-f1</th>\n",
       "      <th>subject-bs-f1</th>\n",
       "      <th>target-phrase-bs-f1</th>\n",
       "      <th>target-sent-bs-f1</th>\n",
       "      <th>target-sent-target-bs-f1</th>\n",
       "      <th>target-sent-subject-bs-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c2s</td>\n",
       "      <td>15.899</td>\n",
       "      <td>3.588</td>\n",
       "      <td>15.258</td>\n",
       "      <td>3.309</td>\n",
       "      <td>22.277</td>\n",
       "      <td>8.939</td>\n",
       "      <td>18.347</td>\n",
       "      <td>5.923</td>\n",
       "      <td>17.417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c2sp</td>\n",
       "      <td>15.266</td>\n",
       "      <td>3.515</td>\n",
       "      <td>15.757</td>\n",
       "      <td>3.567</td>\n",
       "      <td>23.580</td>\n",
       "      <td>9.417</td>\n",
       "      <td>18.686</td>\n",
       "      <td>5.726</td>\n",
       "      <td>18.003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c4s</td>\n",
       "      <td>15.712</td>\n",
       "      <td>2.912</td>\n",
       "      <td>14.908</td>\n",
       "      <td>4.157</td>\n",
       "      <td>22.771</td>\n",
       "      <td>8.681</td>\n",
       "      <td>17.560</td>\n",
       "      <td>5.348</td>\n",
       "      <td>18.005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c4sp</td>\n",
       "      <td>15.233</td>\n",
       "      <td>1.652</td>\n",
       "      <td>16.923</td>\n",
       "      <td>4.930</td>\n",
       "      <td>23.323</td>\n",
       "      <td>9.918</td>\n",
       "      <td>18.652</td>\n",
       "      <td>5.758</td>\n",
       "      <td>16.861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cs</td>\n",
       "      <td>19.650</td>\n",
       "      <td>6.692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.487</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c2spo</td>\n",
       "      <td>13.904</td>\n",
       "      <td>2.192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.431</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c4spo</td>\n",
       "      <td>13.147</td>\n",
       "      <td>1.519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.43</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  base-b1  base-b2  masked-b1  masked-b2  subject-b1  subject-b2  \\\n",
       "0     c2s   15.899    3.588     15.258      3.309      22.277       8.939   \n",
       "1    c2sp   15.266    3.515     15.757      3.567      23.580       9.417   \n",
       "2     c4s   15.712    2.912     14.908      4.157      22.771       8.681   \n",
       "3    c4sp   15.233    1.652     16.923      4.930      23.323       9.918   \n",
       "4      cs   19.650    6.692        NaN        NaN         NaN         NaN   \n",
       "5   c2spo   13.904    2.192        NaN        NaN         NaN         NaN   \n",
       "6   c4spo   13.147    1.519        NaN        NaN         NaN         NaN   \n",
       "\n",
       "   target-phrase-b1  target-phrase-b2  target-sent-b1  ...  \\\n",
       "0            18.347             5.923          17.417  ...   \n",
       "1            18.686             5.726          18.003  ...   \n",
       "2            17.560             5.348          18.005  ...   \n",
       "3            18.652             5.758          16.861  ...   \n",
       "4               NaN               NaN             NaN  ...   \n",
       "5               NaN               NaN             NaN  ...   \n",
       "6               NaN               NaN             NaN  ...   \n",
       "\n",
       "   target-sent-bs-rec  target-sent-target-bs-rec  target-sent-subject-bs-rec  \\\n",
       "0               0.493                      0.499                       0.535   \n",
       "1               0.497                      0.511                       0.532   \n",
       "2               0.493                      0.499                       0.533   \n",
       "3               0.495                      0.512                       0.534   \n",
       "4                None                      0.491                       0.537   \n",
       "5                None                       None                        None   \n",
       "6                None                       None                        None   \n",
       "\n",
       "   base-bs-f1  masked-bs-f1 subject-bs-f1 target-phrase-bs-f1  \\\n",
       "0       0.475         0.462          0.51               0.488   \n",
       "1       0.456         0.466         0.515               0.494   \n",
       "2       0.461         0.469         0.513               0.485   \n",
       "3       0.447         0.456          0.52               0.491   \n",
       "4       0.487          None          None                None   \n",
       "5       0.431          None          None                None   \n",
       "6        0.43          None          None                None   \n",
       "\n",
       "  target-sent-bs-f1 target-sent-target-bs-f1 target-sent-subject-bs-f1  \n",
       "0             0.485                     0.49                     0.521  \n",
       "1             0.484                    0.498                     0.515  \n",
       "2             0.484                    0.487                     0.518  \n",
       "3             0.481                    0.499                     0.517  \n",
       "4              None                    0.481                     0.518  \n",
       "5              None                     None                      None  \n",
       "6              None                     None                      None  \n",
       "\n",
       "[7 rows x 36 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7a3102b2-71d4-4238-b7f5-125b84d55426",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_csv(f\"../data/results/{model}-results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32495be-9d05-4b18-90b8-5395a57452d6",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f15d3e35-6f21-4db0-963a-2fd1de85b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    'source_text': df_gen['source_text'],\n",
    "    'elaboration_sentence': df_gen['elaboration_sentence'],\n",
    "    'pred_elaboration': df_gen['pred_elaboration'],\n",
    "    'bert-score-precision': bert_scores_precision,\n",
    "    'bert-score-recall': bert_scores_recall,\n",
    "    'bert-score-f1': bert_scores_f1\n",
    "})\n",
    "\n",
    "# bleu-scores\n",
    "#df_results.to_csv(\"../data/bleu_scores/bleu_scores_bart-ft-c2sp-masked.csv\", index=False)\n",
    "# bert-scores\n",
    "df_results.to_csv(f\"../data/bert_scores/bert_scores_{model}-test_ds-{output_name}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
