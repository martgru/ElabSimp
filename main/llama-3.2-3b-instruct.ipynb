{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d5fd393-a8e5-478a-8553-b12063cd7713",
   "metadata": {},
   "source": [
    "# Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b72d3a1-b209-43b5-a99c-1b4cab65f174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2351aa3f854369ad4cd339637ee30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model_utils import LlamaAssistant\n",
    "\n",
    "assistant = LlamaAssistant(model_name=\"meta-llama/Llama-3.2-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93520b86-e775-4f93-9c9c-b13111de6303",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a87802bb-cd67-4269-b83d-d29eafa09238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"../data/elaborations\"\n",
    "test_ds_c2sp = \"test_ds_c2sp.csv\"\n",
    "test_ds_c2s = \"test_ds_c2s.csv\"\n",
    "test_ds_c2os = \"test_ds_c2os.csv\"\n",
    "test_ds_c4s = \"test_ds_c4s.csv\"\n",
    "test_ds_c4sp = \"test_ds_c4sp.csv\"\n",
    "test_ds_c2osp = \"test_ds_c2osp.csv\"\n",
    "test_ds_c4osp = \"test_ds_c4osp.csv\"\n",
    "test_df = pd.read_csv(os.path.join(data_path, \"test\", test_ds_c4osp))\n",
    "\n",
    "target_c2sp = \"elab-target-predictions_llama-instr-test_ds_c2sp-context_elab-together.csv\"\n",
    "target_c2s = \"elab-target-predictions_llama-instr-test_ds_c2s-context_elab-together.csv\"\n",
    "target_df = pd.read_csv(os.path.join(\"../data\", \"gen_predictions\",target_c2sp))\n",
    "print(len(test_df)==len(target_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd64322c-8afe-470e-ab78-d521b58a6174",
   "metadata": {},
   "source": [
    "# Create Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24db62a3-6776-4457-a31a-6b9a701492be",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a helpful assistant who generates exactly one short, simple explanatory sentence ( made up of around 10 words or fewer) in a plain English for a given context. \n",
    "Your task is to provide additional information related to a complex statement, term, action, or concept that is semantically missing from the context document.\n",
    "You may do this by offering a definition, examples, background knowledge, general statements, a description of the flow of actions, or an explanation of the reason or result of the target action.\n",
    "Also, specify the target of your explanation as found in the context text. The \"explanation target\" should be written as a simple, concise noun phrase, not as a complete sentence.\n",
    "Return your answer in the following format:\n",
    "{\"sentence\": \"<explanatory sentence text>\", \"target\": \"<explanation target>\"}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2660d425-3ee8-4906-98f3-052189d227ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TARGET = \"\"\"You are a helpful assistant whose task is to determine what the explanation sentence provided is explaining within the context text.\n",
    "Guidelines: \n",
    "- The \"explanation target\" should be a specific phrase, term, action, or concept in the context text provided. \n",
    "- The \"explanation target\" should be written as a noun phrase, not as a complete sentence.\n",
    "- If there are multiple possible targets, select the first target that you think is most appropriate.\n",
    "\n",
    "Return your answer in the following format:\n",
    "{\"sentence\":\"<provided explanation sentence>\", \"target\": \"<explanation target>\"}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f7f7a6-f2e6-4bb3-9db0-a83159e6499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TARGET_WITH_LABEL_TEXT = \"\"\"You are a helpful assistant whose task is to identify the subject of the provided explanation sentence. \n",
    "\n",
    "Guidelines:\n",
    "1. Return the subject of the explanation sentence as the \"explanation target.\"\n",
    "2. If the subject of the explanation sentence is a **pronoun (e.g., \"it,\" \"they,\" \"he,\" \"she\")**, determine what the pronoun is referring to within the context text and return the reference as the \"explanation target.\"\n",
    "3. The \"explanation target\" should be written as a **noun phrase**, not as a complete sentence.\n",
    "4. If there are multiple possible subjects, select the first one you think is most appropriate.\n",
    "5 Do not write any comments to the text!\n",
    "\n",
    "Return your answer in the following format:\n",
    "\"target\": \"<explanation target>\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c57a7cd3-a6a3-433e-b76a-b5ae40b838ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_WITH_ELAB_TARGET_PROVIDED = \"\"\"You are a helpful assistant who generates exactly one short, simple explanatory sentence in plain English (approximately 10 words or fewer) for a given context.\n",
    "\n",
    "Your task is to provide additional information specifically related to the \"explanation target\" provided. \n",
    "\n",
    "Guidelines:\n",
    "1. Keep the explanation concise and directly relevant to the \"explanation target.\"\n",
    "2. You may provide additional information by:\n",
    "   - Offering a definition.\n",
    "   - Giving examples.\n",
    "   - Providing background knowledge.\n",
    "   - Stating a general fact.\n",
    "   - Describing a sequence of actions.\n",
    "   - Explaining a reason or result connected to the \"explanation target.\"\n",
    "3. Do not restate the \"explanation target.\" Focus only on elaborating it.\n",
    "\n",
    "Return your answer in the following format:\n",
    "{\"sentence\": \"<explanatory sentence text>\"}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a2d1a7-1ce1-4a16-888d-558a3c180400",
   "metadata": {},
   "source": [
    "# Generate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941a586-3407-4786-a82f-0c11ed372fe4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get the elaboration targets \n",
    "\n",
    "1) Providing the context and elaboration sentence seperately.\n",
    "2) Providing the context and elaboration sentence in one text, pointing out the elaboration sentence.\n",
    "3) Identify which two sentences are linked by the elaboration sentence.\n",
    "4) Identify the subject in each elaboration sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43563be8-8eda-4fe3-ba11-41547e51a466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context text:  Collins wrote that he realized he was gay when he was 12. His twin brother was getting interested in girls, but he was not. His aunt was the first relative with whom he shared his secret. She was not surprised. She accepted him lovingly.\n",
      "\n",
      "Elaboration sentence:  His aunt was the first relative with whom he shared his secret.\n",
      "\n",
      "Error:  [{'generated_text': 'target\": Collins\\' aunt'}]\n"
     ]
    }
   ],
   "source": [
    "example = dataset[\"train\"][10]\n",
    "context = example[\"label_text\"]\n",
    "elab = example[\"elaboration_sentence\"]\n",
    "print(\"Context text: \", context, end=\"\\n\\n\")\n",
    "print(\"Elaboration sentence: \", elab,end=\"\\n\\n\")\n",
    "\n",
    "try:\n",
    "    response = assistant.find_explanation_target(SYSTEM_PROMPT_TARGET_WITH_LABEL_TEXT , context, elab)\n",
    "    sentence, target = assistant.extract_response(response)\n",
    "    \n",
    "    print(\"Generated Sentence:\", sentence)\n",
    "    print(\"Explanation Target:\", target)\n",
    "except:\n",
    "    print(\"Error: \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fc7acb-313d-4557-aa54-05808e2e88d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Identify the elaboration target when provided within the context text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d1364cb-773b-4d67-826f-780093b84368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 116/116 [00:22<00:00,  5.10it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_df[\"elaboration_target\"] = \"\"\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    context = row[\"label_text\"]\n",
    "    elab =  row[\"elaboration_sentence\"]   \n",
    "    try:\n",
    "        response = assistant.find_explanation_target(SYSTEM_PROMPT_TARGET_WITH_LABEL_TEXT, context, elab)\n",
    "        target = assistant.extract_response(response)\n",
    "        \n",
    "        test_df.at[index, \"elaboration_target\"] = target\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error ID: {index}\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        test_df.at[index, \"elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "533d14c4-5491-4ddc-9f76-930d2d9ffeb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"elaboration_target\"]==\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2c8bf55-8124-4657-89ff-0cc3bd9e5f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 116/116 [00:00<00:00, 229.17it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    if row[\"elaboration_target\"] == \"\":\n",
    "        context = row[\"label_text\"]\n",
    "        elab =  row[\"elaboration_sentence\"]   \n",
    "        try:\n",
    "            response = assistant.find_explanation_target(SYSTEM_PROMPT_TARGET_WITH_LABEL_TEXT, context, elab)\n",
    "            target = assistant.extract_response(response)\n",
    "            \n",
    "            test_df.at[index, \"elaboration_target\"] = target\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error ID: {index}\")\n",
    "            print(f\"Exception: {e}\")\n",
    "            test_df.at[index, \"elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6c3bb03-a4a7-4019-ad75-bc73c9919bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"elaboration_target\"]==\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "831e128f-865b-41b1-90dc-35f9f8ade63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_num</th>\n",
       "      <th>source_text</th>\n",
       "      <th>label_text</th>\n",
       "      <th>elaboration_sentence</th>\n",
       "      <th>contextual_specificity_rating</th>\n",
       "      <th>elaboration_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>They did not need special skills or a college ...</td>\n",
       "      <td>They did not need special skills or a college ...</td>\n",
       "      <td>Many do not have the money to get the training...</td>\n",
       "      <td>1</td>\n",
       "      <td>New Haven youth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>WASHINGTON – At least four people died in Midw...</td>\n",
       "      <td>WASHINGTON – At least four people died in Midw...</td>\n",
       "      <td>A gauge is a kind of measuring stick.</td>\n",
       "      <td>0</td>\n",
       "      <td>a gauge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>WASHINGTON – At least four people died in Midw...</td>\n",
       "      <td>WASHINGTON – At least four people died in Midw...</td>\n",
       "      <td>It sits in the water.</td>\n",
       "      <td>0</td>\n",
       "      <td>a gauge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Rescue crews swarmed into the ruins at Plaza T...</td>\n",
       "      <td>Rescue crews swarmed into the ruins at Plaza T...</td>\n",
       "      <td>They raced against the setting sun to search t...</td>\n",
       "      <td>1</td>\n",
       "      <td>rescue crews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>One half of Istanbul lies in Europe, while the...</td>\n",
       "      <td>One half of Istanbul lies in Europe, while the...</td>\n",
       "      <td>Turkey is larger than the state of Texas.</td>\n",
       "      <td>0</td>\n",
       "      <td>state of Turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1140</td>\n",
       "      <td>Some people are talking about it even more tha...</td>\n",
       "      <td>Some people are talking about it even more tha...</td>\n",
       "      <td>Like many mysteries, this one may not be solve...</td>\n",
       "      <td>2</td>\n",
       "      <td>the mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1147</td>\n",
       "      <td>Should kids play tackle football? Football is ...</td>\n",
       "      <td>Should kids play tackle football? Football is ...</td>\n",
       "      <td>Players get bounced around.</td>\n",
       "      <td>2</td>\n",
       "      <td>kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1163</td>\n",
       "      <td>Barnett made big changes at Capitol Records. H...</td>\n",
       "      <td>Barnett made big changes at Capitol Records. H...</td>\n",
       "      <td>Then the companies sell and promote the records.</td>\n",
       "      <td>0</td>\n",
       "      <td>record companies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1166</td>\n",
       "      <td>They also think it is wrong to force her to pe...</td>\n",
       "      <td>They also think it is wrong to force her to pe...</td>\n",
       "      <td>There are certainly good reasons to be worried.</td>\n",
       "      <td>2</td>\n",
       "      <td>good reasons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1175</td>\n",
       "      <td>In January, U.S. District Judge Callie Granade...</td>\n",
       "      <td>In January, U.S. District Judge Callie Granade...</td>\n",
       "      <td>Judge Granade's order was immediately challenged.</td>\n",
       "      <td>1</td>\n",
       "      <td>U.S District Judge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_num                                        source_text  \\\n",
       "0          6  They did not need special skills or a college ...   \n",
       "1         28  WASHINGTON – At least four people died in Midw...   \n",
       "2         28  WASHINGTON – At least four people died in Midw...   \n",
       "3         34  Rescue crews swarmed into the ruins at Plaza T...   \n",
       "4         67  One half of Istanbul lies in Europe, while the...   \n",
       "..       ...                                                ...   \n",
       "111     1140  Some people are talking about it even more tha...   \n",
       "112     1147  Should kids play tackle football? Football is ...   \n",
       "113     1163  Barnett made big changes at Capitol Records. H...   \n",
       "114     1166  They also think it is wrong to force her to pe...   \n",
       "115     1175  In January, U.S. District Judge Callie Granade...   \n",
       "\n",
       "                                            label_text  \\\n",
       "0    They did not need special skills or a college ...   \n",
       "1    WASHINGTON – At least four people died in Midw...   \n",
       "2    WASHINGTON – At least four people died in Midw...   \n",
       "3    Rescue crews swarmed into the ruins at Plaza T...   \n",
       "4    One half of Istanbul lies in Europe, while the...   \n",
       "..                                                 ...   \n",
       "111  Some people are talking about it even more tha...   \n",
       "112  Should kids play tackle football? Football is ...   \n",
       "113  Barnett made big changes at Capitol Records. H...   \n",
       "114  They also think it is wrong to force her to pe...   \n",
       "115  In January, U.S. District Judge Callie Granade...   \n",
       "\n",
       "                                  elaboration_sentence  \\\n",
       "0    Many do not have the money to get the training...   \n",
       "1                A gauge is a kind of measuring stick.   \n",
       "2                                It sits in the water.   \n",
       "3    They raced against the setting sun to search t...   \n",
       "4            Turkey is larger than the state of Texas.   \n",
       "..                                                 ...   \n",
       "111  Like many mysteries, this one may not be solve...   \n",
       "112                        Players get bounced around.   \n",
       "113   Then the companies sell and promote the records.   \n",
       "114    There are certainly good reasons to be worried.   \n",
       "115  Judge Granade's order was immediately challenged.   \n",
       "\n",
       "     contextual_specificity_rating  elaboration_target  \n",
       "0                                1     New Haven youth  \n",
       "1                                0             a gauge  \n",
       "2                                0             a gauge  \n",
       "3                                1        rescue crews  \n",
       "4                                0     state of Turkey  \n",
       "..                             ...                 ...  \n",
       "111                              2         the mystery  \n",
       "112                              2                kids  \n",
       "113                              0    record companies  \n",
       "114                              2        good reasons  \n",
       "115                              1  U.S District Judge  \n",
       "\n",
       "[116 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a2be145-992f-4b4c-8641-5f718f061252",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(os.path.join(\"../data\",\"gen_predictions\", \"elab-target-predictions_llama-instr-test_ds_c4sp-context_elab-together.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27be6ed-7858-40fe-9aad-e786fd66f835",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Indentify the elaboration target when provided seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b999f002-e85e-4b4b-85a1-7f701192c4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████▍                        | 48/116 [00:31<00:49,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error ID: 47\n",
      "Exception: 'NoneType' object has no attribute 'start'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 116/116 [01:14<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_df[\"elaboration_target\"] = \"\"\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    context = row[\"source_text\"]\n",
    "    elab =  row[\"elaboration_sentence\"]   \n",
    "    try:\n",
    "        response = assistant.find_explanation_target(SYSTEM_PROMPT_TARGET, context, elab)\n",
    "        sentence, target = assistant.extract_response(response)\n",
    "        \n",
    "        test_df.at[index, \"elaboration_target\"] = target\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error ID: {index}\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        test_df.at[index, \"elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ecd65ef-c7f6-4853-b7ba-f7b3e0cea2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"elaboration_target\"]==\"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf89886-f0ef-4dba-b2b0-90a68e79fec4",
   "metadata": {},
   "source": [
    "### Fill NaN fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "579a91c2-a4fa-4c7f-9dd5-6cd6164bb570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 116/116 [00:00<00:00, 133.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    if row[\"elaboration_target\"] == \"\":\n",
    "        context = row[\"source_text\"]\n",
    "        elab =  row[\"elaboration_sentence\"]   \n",
    "        try:\n",
    "            response = assistant.find_explanation_target(SYSTEM_PROMPT_TARGET, context, elab)\n",
    "            sentence, target = assistant.extract_response(response)\n",
    "            \n",
    "            test_df.at[index, \"elaboration_target\"] = target\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error ID: {index}\")\n",
    "            print(f\"Exception: {e}\")\n",
    "            test_df.at[index, \"elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fdae617-daf0-4d6c-ab78-0f78c7019f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"elaboration_target\"]==\"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec3b3fd-6b6c-4f48-a628-b1ba77afd7ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Generate elaboration example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d47244c9-c3ba-4c84-b1a9-ad3dfdb47865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context text:  The Internet helped Mark Zuckerberg start Facebook while still a college student.\n",
      "\n",
      "Target:  Mark Zuckerberg\n",
      "Generated Sentence: He created the social networking site after dropping out of Harvard.\n"
     ]
    }
   ],
   "source": [
    "idx = 11\n",
    "#example = dataset[\"train\"][idx]\n",
    "context = test_df.loc[idx,\"source_text\"]\n",
    "target = target_df.loc[idx,\"elaboration_target\"]\n",
    "print(\"Context text: \", context, end=\"\\n\\n\")\n",
    "print(\"Target: \", target)\n",
    "\n",
    "response = assistant.generate_explanation(SYSTEM_PROMPT_WITH_ELAB_TARGET_PROVIDED, context, target)\n",
    "sentence = assistant.extract_response(response)\n",
    "\n",
    "print(\"Generated Sentence:\", sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7858696-c5a3-48eb-b399-7669b7bb3ec8",
   "metadata": {},
   "source": [
    "## Context + elaboration target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a4874a93-3207-49ac-af78-85db5b6c4b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████▍                       | 51/116 [00:28<00:34,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error ID: 50\n",
      "Exception: 'NoneType' object has no attribute 'end'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 116/116 [01:04<00:00,  1.79it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_df[\"pred_elaboration\"] = \"\"\n",
    "test_df[\"elaboration_target\"] =\"\"\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    context = row[\"source_text\"]\n",
    "    target = target_df.loc[index,\"elaboration_target\"]\n",
    "    \n",
    "    try:\n",
    "        response = assistant.generate_explanation(SYSTEM_PROMPT_WITH_ELAB_TARGET_PROVIDED, context, target)\n",
    "        sentence = assistant.extract_response(response)\n",
    "        \n",
    "        test_df.at[index, \"pred_elaboration\"] = sentence\n",
    "        test_df.at[index, \"elaboration_target\"] = target\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error ID: {index}\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        test_df.at[index, \"pred_elaboration\"] = \"\"\n",
    "        test_df.at[index, \"elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafa76b4-f8b4-4e0d-bd63-b79ac04492f6",
   "metadata": {},
   "source": [
    "### Fill NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93ffd347-6bea-4703-b387-e353822c473e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 116/116 [00:00<00:00, 190.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error ID: 50\n",
      "Exception: 'NoneType' object has no attribute 'end'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    if row[\"pred_elaboration\"]==\"\":\n",
    "        context = row[\"source_text\"]\n",
    "        target = target_df.loc[index,\"elaboration_target\"]\n",
    "        try:\n",
    "            response = assistant.generate_explanation(SYSTEM_PROMPT_WITH_ELAB_TARGET_PROVIDED, context, target)\n",
    "            sentence = assistant.extract_response(response)\n",
    "            \n",
    "            test_df.at[index, \"pred_elaboration\"] = sentence\n",
    "            test_df.at[index, \"elaboration_target\"] = target\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error ID: {index}\")\n",
    "            print(f\"Exception: {e}\")\n",
    "            test_df.at[index, \"pred_elaboration\"] = \"\"\n",
    "            test_df.at[index, \"elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5053bee3-3869-42c1-ba6c-9568d6ca555e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"pred_elaboration\"]==\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40c70580-d0ac-4dfd-9e39-f0d225cc239e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_num</th>\n",
       "      <th>source_text</th>\n",
       "      <th>label_text</th>\n",
       "      <th>elaboration_sentence</th>\n",
       "      <th>contextual_specificity_rating</th>\n",
       "      <th>pred_elaboration</th>\n",
       "      <th>elaboration_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>New companies have come that need skilled work...</td>\n",
       "      <td>New companies have come that need skilled work...</td>\n",
       "      <td>Many do not have the money to get the training...</td>\n",
       "      <td>1</td>\n",
       "      <td>New Haven youth benefit from education and job...</td>\n",
       "      <td>New Haven youth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>But the death toll could have been higher. For...</td>\n",
       "      <td>But the death toll could have been higher. For...</td>\n",
       "      <td>A gauge is a kind of measuring stick.</td>\n",
       "      <td>0</td>\n",
       "      <td>A gauge is a device that measures water levels...</td>\n",
       "      <td>a gauge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Forecasters said more people could have died i...</td>\n",
       "      <td>Forecasters said more people could have died i...</td>\n",
       "      <td>It sits in the water.</td>\n",
       "      <td>0</td>\n",
       "      <td>A gauge is essentially a water level sensor.</td>\n",
       "      <td>a gauge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Helicopters were banned from flying over the s...</td>\n",
       "      <td>Helicopters were banned from flying over the s...</td>\n",
       "      <td>They raced against the setting sun to search t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Rescuers are the people who save those in need...</td>\n",
       "      <td>rescuers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>Istanbul is an important city for trade. Turke...</td>\n",
       "      <td>Istanbul is an important city for trade. Turke...</td>\n",
       "      <td>Turkey is larger than the state of Texas.</td>\n",
       "      <td>0</td>\n",
       "      <td>Turkey is a transcontinental country located i...</td>\n",
       "      <td>Turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1140</td>\n",
       "      <td>Instead of preparing for the Super Bowl, he ha...</td>\n",
       "      <td>Instead of preparing for the Super Bowl, he ha...</td>\n",
       "      <td>Like many mysteries, this one may not be solve...</td>\n",
       "      <td>2</td>\n",
       "      <td>Deflation of a football is when it loses air p...</td>\n",
       "      <td>the deflation of footballs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1147</td>\n",
       "      <td>Should kids play tackle football? Football is ...</td>\n",
       "      <td>Should kids play tackle football? Football is ...</td>\n",
       "      <td>Players get bounced around.</td>\n",
       "      <td>2</td>\n",
       "      <td>Children's brains are still developing, making...</td>\n",
       "      <td>players</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1163</td>\n",
       "      <td>He signed two of the biggest acts of last year...</td>\n",
       "      <td>He signed two of the biggest acts of last year...</td>\n",
       "      <td>Then the companies sell and promote the records.</td>\n",
       "      <td>0</td>\n",
       "      <td>Record companies are businesses that manage an...</td>\n",
       "      <td>record companies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1166</td>\n",
       "      <td>It worries about the spread of disease. It als...</td>\n",
       "      <td>It worries about the spread of disease. It als...</td>\n",
       "      <td>There are certainly good reasons to be worried.</td>\n",
       "      <td>2</td>\n",
       "      <td>These concerns highlight potential risks to th...</td>\n",
       "      <td>good reasons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1175</td>\n",
       "      <td>The Constitution lists laws that govern the wh...</td>\n",
       "      <td>The Constitution lists laws that govern the wh...</td>\n",
       "      <td>Judge Granade's order was immediately challenged.</td>\n",
       "      <td>1</td>\n",
       "      <td>He ordered the state to stop enforcing its gay...</td>\n",
       "      <td>Judge Granades order</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_num                                        source_text  \\\n",
       "0          6  New companies have come that need skilled work...   \n",
       "1         28  But the death toll could have been higher. For...   \n",
       "2         28  Forecasters said more people could have died i...   \n",
       "3         34  Helicopters were banned from flying over the s...   \n",
       "4         67  Istanbul is an important city for trade. Turke...   \n",
       "..       ...                                                ...   \n",
       "111     1140  Instead of preparing for the Super Bowl, he ha...   \n",
       "112     1147  Should kids play tackle football? Football is ...   \n",
       "113     1163  He signed two of the biggest acts of last year...   \n",
       "114     1166  It worries about the spread of disease. It als...   \n",
       "115     1175  The Constitution lists laws that govern the wh...   \n",
       "\n",
       "                                            label_text  \\\n",
       "0    New companies have come that need skilled work...   \n",
       "1    But the death toll could have been higher. For...   \n",
       "2    Forecasters said more people could have died i...   \n",
       "3    Helicopters were banned from flying over the s...   \n",
       "4    Istanbul is an important city for trade. Turke...   \n",
       "..                                                 ...   \n",
       "111  Instead of preparing for the Super Bowl, he ha...   \n",
       "112  Should kids play tackle football? Football is ...   \n",
       "113  He signed two of the biggest acts of last year...   \n",
       "114  It worries about the spread of disease. It als...   \n",
       "115  The Constitution lists laws that govern the wh...   \n",
       "\n",
       "                                  elaboration_sentence  \\\n",
       "0    Many do not have the money to get the training...   \n",
       "1                A gauge is a kind of measuring stick.   \n",
       "2                                It sits in the water.   \n",
       "3    They raced against the setting sun to search t...   \n",
       "4            Turkey is larger than the state of Texas.   \n",
       "..                                                 ...   \n",
       "111  Like many mysteries, this one may not be solve...   \n",
       "112                        Players get bounced around.   \n",
       "113   Then the companies sell and promote the records.   \n",
       "114    There are certainly good reasons to be worried.   \n",
       "115  Judge Granade's order was immediately challenged.   \n",
       "\n",
       "     contextual_specificity_rating  \\\n",
       "0                                1   \n",
       "1                                0   \n",
       "2                                0   \n",
       "3                                1   \n",
       "4                                0   \n",
       "..                             ...   \n",
       "111                              2   \n",
       "112                              2   \n",
       "113                              0   \n",
       "114                              2   \n",
       "115                              1   \n",
       "\n",
       "                                      pred_elaboration  \\\n",
       "0    New Haven youth benefit from education and job...   \n",
       "1    A gauge is a device that measures water levels...   \n",
       "2         A gauge is essentially a water level sensor.   \n",
       "3    Rescuers are the people who save those in need...   \n",
       "4    Turkey is a transcontinental country located i...   \n",
       "..                                                 ...   \n",
       "111  Deflation of a football is when it loses air p...   \n",
       "112  Children's brains are still developing, making...   \n",
       "113  Record companies are businesses that manage an...   \n",
       "114  These concerns highlight potential risks to th...   \n",
       "115  He ordered the state to stop enforcing its gay...   \n",
       "\n",
       "             elaboration_target  \n",
       "0               New Haven youth  \n",
       "1                       a gauge  \n",
       "2                       a gauge  \n",
       "3                      rescuers  \n",
       "4                        Turkey  \n",
       "..                          ...  \n",
       "111  the deflation of footballs  \n",
       "112                     players  \n",
       "113            record companies  \n",
       "114                good reasons  \n",
       "115        Judge Granades order  \n",
       "\n",
       "[116 rows x 7 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75bb7ee8-8b1c-425b-b071-956295f0fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(os.path.join(\"../data\",\"gen_predictions\", \"predictions_llama-instr-test_ds_c4osp-context_elab-provided.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4d769-dc6c-4245-8ee7-b6974ffb7b52",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Context only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcecb20b-8973-465f-bc3f-ee2343f3b7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 116/116 [01:23<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_df[\"pred_elaboration\"] = \"\"\n",
    "test_df[\"pred_elaboration_target\"] = \"\"\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    context = row[\"source_text\"]\n",
    "    \n",
    "    try:\n",
    "        response = assistant.generate_explanation(SYSTEM_PROMPT, context)\n",
    "        sentence, target = assistant.extract_response(response)\n",
    "        \n",
    "        test_df.at[index, \"pred_elaboration\"] = sentence\n",
    "        test_df.at[index, \"pred_elaboration_target\"] = target\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error ID: {index}\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        test_df.at[index, \"pred_elaboration\"] = \"\"\n",
    "        test_df.at[index, \"pred_elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f06976d-ee97-4a58-9ef5-bfc5463afd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"pred_elaboration\"]==\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24830b65-c5ea-43d6-8ab8-d24c2adeb092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"pred_elaboration_target\"]==\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "909ead6e-cf5b-4d07-83c9-4ecd471e2743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.81896551724138\n"
     ]
    }
   ],
   "source": [
    "print(test_df[\"pred_elaboration\"].dropna().apply(len).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89ea1072-f292-4aac-ad7b-aeb06fa5bdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.672413793103445\n"
     ]
    }
   ],
   "source": [
    "print(test_df[\"elaboration_sentence\"].dropna().apply(len).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cbae4a-4dbc-42e8-a099-28dd7343d3cb",
   "metadata": {},
   "source": [
    "### Fill NaN fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b49bf77-559a-4335-8430-b24734c090a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 116/116 [00:01<00:00, 79.83it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    if row[\"pred_elaboration\"]==\"\" or row[\"pred_elaboration_target\"]==\"\":\n",
    "        context = row[\"source_text\"]\n",
    "        try:\n",
    "            response = assistant.generate_explanation(SYSTEM_PROMPT, context)\n",
    "            sentence, target = assistant.extract_response(response)\n",
    "            \n",
    "            test_df.at[index, \"pred_elaboration\"] = sentence\n",
    "            test_df.at[index, \"pred_elaboration_target\"] = target\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error ID: {index}\")\n",
    "            print(f\"Exception: {e}\")\n",
    "            test_df.at[index, \"pred_elaboration\"] = \"\"\n",
    "            test_df.at[index, \"pred_elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8dff216-7a5c-4b46-9212-42b88de5c8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"pred_elaboration_target\"]==\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "693b1a30-1b6d-467b-8b61-703e9621d5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"pred_elaboration\"]==\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b82048b4-fbe4-4a78-8082-9a4efc35522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(os.path.join(\"../data\",\"gen_predictions\", \"predictions_llama-instr-test_ds_c2os-context_elab-seperately.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c10556-f60c-4c4b-9a3f-1366a87decde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
