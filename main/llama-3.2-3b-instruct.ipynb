{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d5fd393-a8e5-478a-8553-b12063cd7713",
   "metadata": {},
   "source": [
    "# Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b72d3a1-b209-43b5-a99c-1b4cab65f174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b7ed8dfd984dfdad43a2cc94ce165a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model_utils import LlamaAssistant\n",
    "\n",
    "assistant = LlamaAssistant(model_name=\"meta-llama/Llama-3.2-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93520b86-e775-4f93-9c9c-b13111de6303",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953649f8-4c85-4940-9115-63d404533c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_num', 'source_text', 'label_text', 'elaboration_sentence', 'contextual_specificity_rating'],\n",
      "        num_rows: 1049\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_num', 'source_text', 'label_text', 'elaboration_sentence', 'contextual_specificity_rating'],\n",
      "        num_rows: 134\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['doc_num', 'source_text', 'label_text', 'elaboration_sentence', 'contextual_specificity_rating'],\n",
      "        num_rows: 116\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "data_path = \"../data/elaborations\"\n",
    "\n",
    "data_files_c2sp = {\n",
    "    'train': os.path.join(data_path,\"train\",\"train_ds_c2sp.csv\"),      \n",
    "    'validation': os.path.join(data_path,\"validation\",\"valid_ds_c2sp.csv\"),  \n",
    "    'test': os.path.join(data_path,\"test\",\"test_ds_c2sp.csv\")         \n",
    "}\n",
    "dataset = load_dataset('csv', data_files=data_files_c2sp)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a87802bb-cd67-4269-b83d-d29eafa09238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"../data/elaborations\"\n",
    "test_ds_c2sp = \"test_ds_c2sp.csv\"\n",
    "test_ds_c2s = \"test_ds_c2s.csv\"\n",
    "test_ds_c4s = \"test_ds_c4s.csv\"\n",
    "test_ds_c4sp = \"test_ds_c4sp.csv\"\n",
    "test_df = pd.read_csv(os.path.join(data_path, \"test\", test_ds_c4sp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd64322c-8afe-470e-ab78-d521b58a6174",
   "metadata": {},
   "source": [
    "# Create Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24db62a3-6776-4457-a31a-6b9a701492be",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a helpful assistant who generates exactly one short, simple explanatory sentence ( made up of around 10 words or fewer) in a plain English for a given context. \n",
    "Your task is to provide additional information related to a complex statement, term, action, or concept that is semantically missing from the context document.\n",
    "You may do this by offering a definition, examples, background knowledge, general statements, a description of the flow of actions, or an explanation of the reason or result of the target action.\n",
    "Also, specify the target of your explanation as found in the context text. The \"explanation target\" should be written as a simple, concise noun phrase, not as a complete sentence.\n",
    "Return your answer in the following format:\n",
    "{\"sentence\": \"<explanatory sentence text>\", \"target\": \"<explanation target>\"}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2660d425-3ee8-4906-98f3-052189d227ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TARGET = \"\"\"You are a helpful assistant whose task is to determine what the explanation sentence provided is explaining within the context text.\n",
    "Gidelines: \n",
    "- The \"explanation target\" should be a specific phrase, term, action, or concept in the context text provided. \n",
    "- The \"explanation target\" should be written as a noun phrase, not as a complete sentence.\n",
    "- If there are multiple possible targets, select the first target that you think is most appropriate.\n",
    "\n",
    "Return your answer in the following format:\n",
    "{\"sentence\":\"<provided explanation sentence>\", \"target\": \"<explanation target>\"}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a2d1a7-1ce1-4a16-888d-558a3c180400",
   "metadata": {},
   "source": [
    "# Generate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941a586-3407-4786-a82f-0c11ed372fe4",
   "metadata": {},
   "source": [
    "## Get the elaboration targets \n",
    "\n",
    "1) Providing the context and elaboration sentence seperately.\n",
    "2) Providing the context and elaboration sentence in one text, pointing out the elaboration sentence.\n",
    "3) Identify which two sentences are linked by the elaboration sentence.\n",
    "4) Identify the subject in each elaboration sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43563be8-8eda-4fe3-ba11-41547e51a466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context text:  Two other girls were wounded. The Pakistani government sent Malala to England for treatment. One politician called Malala \"a beacon of knowledge.\" Pakistan's President Asif Ali Zardari said it was \"an attack on all girls in Pakistan, an attack on education, and on all civilized people.\"\n",
      "\n",
      "Elaboration sentence:  Many politicians called the gunmen \"beasts.\"\n",
      "\n",
      "Generated Sentence: Many politicians called you the 'beast' in the media.\n",
      "Explanation Target: beast\n"
     ]
    }
   ],
   "source": [
    "example = dataset[\"train\"][8]\n",
    "context = example[\"source_text\"]\n",
    "elab = example[\"elaboration_sentence\"]\n",
    "print(\"Context text: \", context, end=\"\\n\\n\")\n",
    "print(\"Elaboration sentence: \", elab,end=\"\\n\\n\")\n",
    "\n",
    "try:\n",
    "    response = assistant.find_explanation_target(SYSTEM_PROMPT_TARGET, context, elab)\n",
    "    sentence, target = assistant.extract_response(response)\n",
    "    \n",
    "    print(\"Generated Sentence:\", sentence)\n",
    "    print(\"Explanation Target:\", target)\n",
    "except:\n",
    "    print(\"Error: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b999f002-e85e-4b4b-85a1-7f701192c4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▎                                       | 9/116 [00:07<01:29,  1.20it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "100%|█████████████████████████████████████████| 116/116 [01:27<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_df[\"elaboration_target\"] = \"\"\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    context = row[\"source_text\"]\n",
    "    elab =  row[\"elaboration_sentence\"]   \n",
    "    try:\n",
    "        response = assistant.find_explanation_target(SYSTEM_PROMPT_TARGET, context, elab)\n",
    "        sentence, target = assistant.extract_response(response)\n",
    "        \n",
    "        test_df.at[index, \"elaboration_target\"] = target\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error ID: {index}\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        test_df.at[index, \"elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ecd65ef-c7f6-4853-b7ba-f7b3e0cea2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"elaboration_target\"]==\"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf89886-f0ef-4dba-b2b0-90a68e79fec4",
   "metadata": {},
   "source": [
    "### Fill NaN fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "579a91c2-a4fa-4c7f-9dd5-6cd6164bb570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 116/116 [00:02<00:00, 55.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    if row[\"elaboration_target\"] == \"\":\n",
    "        context = row[\"source_text\"]\n",
    "        elab =  row[\"elaboration_sentence\"]   \n",
    "        try:\n",
    "            response = assistant.find_explanation_target(SYSTEM_PROMPT_TARGET, context, elab)\n",
    "            sentence, target = assistant.extract_response(response)\n",
    "            \n",
    "            test_df.at[index, \"elaboration_target\"] = target\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error ID: {index}\")\n",
    "            print(f\"Exception: {e}\")\n",
    "            test_df.at[index, \"elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fdae617-daf0-4d6c-ab78-0f78c7019f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"elaboration_target\"]==\"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec3b3fd-6b6c-4f48-a628-b1ba77afd7ca",
   "metadata": {},
   "source": [
    "## Get the elaborations for given context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d47244c9-c3ba-4c84-b1a9-ad3dfdb47865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context text:  \"I can only hope that it's not going to get worse,\" Boudreau said. Illinois has laws about animal abuse and neglect. County animal control departments can issue fines. Rescue groups and volunteers may handle some abuse and neglect calls.\n",
      "\n",
      "Elaboration sentence:  The laws explain what state workers can do to deal with the cases.\n",
      "\n",
      "Generated Sentence: Illinois animal abuse laws allow county control and rescue groups to intervene and fine offenders.\n",
      "Explanation Target: animal abuse laws\n"
     ]
    }
   ],
   "source": [
    "example = dataset[\"train\"][11]\n",
    "context = example[\"source_text\"]\n",
    "elab = example[\"elaboration_sentence\"]\n",
    "print(\"Context text: \", context, end=\"\\n\\n\")\n",
    "print(\"Elaboration sentence: \", elab,end=\"\\n\\n\")\n",
    "\n",
    "response = assistant.generate_explanation(SYSTEM_PROMPT, context)\n",
    "sentence, target = assistant.extract_response(response)\n",
    "\n",
    "print(\"Generated Sentence:\", sentence)\n",
    "print(\"Explanation Target:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcecb20b-8973-465f-bc3f-ee2343f3b7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 116/116 [01:38<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_df[\"pred_elaboration\"] = \"\"\n",
    "test_df[\"pred_elaboration_target\"] = \"\"\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    context = row[\"source_text\"]\n",
    "    \n",
    "    try:\n",
    "        response = assistant.generate_explanation(SYSTEM_PROMPT, context)\n",
    "        sentence, target = assistant.extract_response(response)\n",
    "        \n",
    "        test_df.at[index, \"pred_elaboration\"] = sentence\n",
    "        test_df.at[index, \"pred_elaboration_target\"] = target\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error ID: {index}\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        test_df.at[index, \"pred_elaboration\"] = \"\"\n",
    "        test_df.at[index, \"pred_elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f06976d-ee97-4a58-9ef5-bfc5463afd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"pred_elaboration\"]==\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24830b65-c5ea-43d6-8ab8-d24c2adeb092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"pred_elaboration_target\"]==\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "909ead6e-cf5b-4d07-83c9-4ecd471e2743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.5603448275862\n"
     ]
    }
   ],
   "source": [
    "print(test_df[\"pred_elaboration\"].dropna().apply(len).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89ea1072-f292-4aac-ad7b-aeb06fa5bdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.672413793103445\n"
     ]
    }
   ],
   "source": [
    "print(test_df[\"elaboration_sentence\"].dropna().apply(len).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cbae4a-4dbc-42e8-a099-28dd7343d3cb",
   "metadata": {},
   "source": [
    "### Fill NaN fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b49bf77-559a-4335-8430-b24734c090a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 116/116 [00:00<00:00, 130.07it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    if row[\"pred_elaboration\"]==\"\" or row[\"pred_elaboration_target\"]==\"\":\n",
    "        context = row[\"source_text\"]\n",
    "        try:\n",
    "            response = assistant.generate_explanation(SYSTEM_PROMPT, context)\n",
    "            sentence, target = assistant.extract_response(response)\n",
    "            \n",
    "            test_df.at[index, \"pred_elaboration\"] = sentence\n",
    "            test_df.at[index, \"pred_elaboration_target\"] = target\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error ID: {index}\")\n",
    "            print(f\"Exception: {e}\")\n",
    "            test_df.at[index, \"pred_elaboration\"] = \"\"\n",
    "            test_df.at[index, \"pred_elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8dff216-7a5c-4b46-9212-42b88de5c8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"pred_elaboration_target\"]==\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "693b1a30-1b6d-467b-8b61-703e9621d5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"pred_elaboration\"]==\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b82048b4-fbe4-4a78-8082-9a4efc35522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(os.path.join(\"../data\",\"gen_predictions\", \"predictions_llama-instr-test_ds_c4sp-context_elab-seperately.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
