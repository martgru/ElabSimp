{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d5fd393-a8e5-478a-8553-b12063cd7713",
   "metadata": {},
   "source": [
    "# Load model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b72d3a1-b209-43b5-a99c-1b4cab65f174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9d8539306943ed86933909e5c1ef55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from model_utils import LlamaAssistant\n",
    "\n",
    "assistant = LlamaAssistant(model_name=\"meta-llama/Llama-3.2-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93520b86-e775-4f93-9c9c-b13111de6303",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "953649f8-4c85-4940-9115-63d404533c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_num', 'source_text', 'label_text', 'elaboration_sentence', 'contextual_specificity_rating'],\n",
      "        num_rows: 1049\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_num', 'source_text', 'label_text', 'elaboration_sentence', 'contextual_specificity_rating'],\n",
      "        num_rows: 134\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['doc_num', 'source_text', 'label_text', 'elaboration_sentence', 'contextual_specificity_rating'],\n",
      "        num_rows: 116\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "data_path = \"../data/elaborations\"\n",
    "\n",
    "data_files_c2sp = {\n",
    "    'train': os.path.join(data_path,\"train\",\"train_ds_c2sp.csv\"),      \n",
    "    'validation': os.path.join(data_path,\"validation\",\"valid_ds_c2sp.csv\"),  \n",
    "    'test': os.path.join(data_path,\"test\",\"test_ds_c2sp.csv\")         \n",
    "}\n",
    "dataset = load_dataset('csv', data_files=data_files_c2sp)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a87802bb-cd67-4269-b83d-d29eafa09238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"../data/elaborations\"\n",
    "test_ds_c2sp = \"test_ds_c2sp.csv\"\n",
    "test_ds_c2s = \"test_ds_c2s.csv\"\n",
    "test_ds_c2os = \"test_ds_c2os.csv\"\n",
    "test_ds_c4s = \"test_ds_c4s.csv\"\n",
    "test_ds_c4sp = \"test_ds_c4sp.csv\"\n",
    "test_ds_c2osp = \"test_ds_c2osp.csv\"\n",
    "test_ds_c4osp = \"test_ds_c4osp.csv\"\n",
    "test_df = pd.read_csv(os.path.join(data_path, \"test\", test_ds_c2osp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd64322c-8afe-470e-ab78-d521b58a6174",
   "metadata": {},
   "source": [
    "# Create Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24db62a3-6776-4457-a31a-6b9a701492be",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a helpful assistant who generates exactly one short, simple explanatory sentence ( made up of around 10 words or fewer) in a plain English for a given context. \n",
    "Your task is to provide additional information related to a complex statement, term, action, or concept that is semantically missing from the context document.\n",
    "You may do this by offering a definition, examples, background knowledge, general statements, a description of the flow of actions, or an explanation of the reason or result of the target action.\n",
    "Also, specify the target of your explanation as found in the context text. The \"explanation target\" should be written as a simple, concise noun phrase, not as a complete sentence.\n",
    "Return your answer in the following format:\n",
    "{\"sentence\": \"<explanatory sentence text>\", \"target\": \"<explanation target>\"}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2660d425-3ee8-4906-98f3-052189d227ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TARGET = \"\"\"You are a helpful assistant whose task is to determine what the explanation sentence provided is explaining within the context text.\n",
    "Gidelines: \n",
    "- The \"explanation target\" should be a specific phrase, term, action, or concept in the context text provided. \n",
    "- The \"explanation target\" should be written as a noun phrase, not as a complete sentence.\n",
    "- If there are multiple possible targets, select the first target that you think is most appropriate.\n",
    "\n",
    "Return your answer in the following format:\n",
    "{\"sentence\":\"<provided explanation sentence>\", \"target\": \"<explanation target>\"}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f7f7a6-f2e6-4bb3-9db0-a83159e6499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_TARGET_WITH_LABEL_TEXT = \"\"\"You are a helpful assistant whose task is to determine what the explanation sentence provided is explaining within the given text.\n",
    "Gidelines: \n",
    "- The \"explanation target\" should be a specific phrase, term, action, or concept present in the context text (sentences surrounding the explanation sentence). \n",
    "- The \"explanation target\" should be written as a noun phrase, not as a complete sentence.\n",
    "- If there are multiple possible targets, select the first target that you think is most appropriate.\n",
    "\n",
    "Return your answer in the following format:\n",
    "{\"sentence\":\"<provided explanation sentence>\", \"target\": \"<explanation target>\"}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a2d1a7-1ce1-4a16-888d-558a3c180400",
   "metadata": {},
   "source": [
    "# Generate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3941a586-3407-4786-a82f-0c11ed372fe4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Get the elaboration targets \n",
    "\n",
    "1) Providing the context and elaboration sentence seperately.\n",
    "2) Providing the context and elaboration sentence in one text, pointing out the elaboration sentence.\n",
    "3) Identify which two sentences are linked by the elaboration sentence.\n",
    "4) Identify the subject in each elaboration sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43563be8-8eda-4fe3-ba11-41547e51a466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context text:  Two other girls were wounded. The Pakistani government sent Malala to England for treatment. One politician called Malala \"a beacon of knowledge.\" Pakistan's President Asif Ali Zardari said it was \"an attack on all girls in Pakistan, an attack on education, and on all civilized people.\"\n",
      "\n",
      "Elaboration sentence:  Many politicians called the gunmen \"beasts.\"\n",
      "\n",
      "Generated Sentence: Many politicians called you the 'beast' in the media.\n",
      "Explanation Target: beast\n"
     ]
    }
   ],
   "source": [
    "example = dataset[\"train\"][8]\n",
    "context = example[\"source_text\"]\n",
    "elab = example[\"elaboration_sentence\"]\n",
    "print(\"Context text: \", context, end=\"\\n\\n\")\n",
    "print(\"Elaboration sentence: \", elab,end=\"\\n\\n\")\n",
    "\n",
    "try:\n",
    "    response = assistant.find_explanation_target(SYSTEM_PROMPT_TARGET, context, elab)\n",
    "    sentence, target = assistant.extract_response(response)\n",
    "    \n",
    "    print(\"Generated Sentence:\", sentence)\n",
    "    print(\"Explanation Target:\", target)\n",
    "except:\n",
    "    print(\"Error: \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fc7acb-313d-4557-aa54-05808e2e88d6",
   "metadata": {},
   "source": [
    "## Identify the elaboration target when provided within the context text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d1364cb-773b-4d67-826f-780093b84368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 116/116 [01:18<00:00,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_df[\"elaboration_target\"] = \"\"\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    context = row[\"label_text\"]\n",
    "    elab =  row[\"elaboration_sentence\"]   \n",
    "    try:\n",
    "        response = assistant.find_explanation_target(SYSTEM_PROMPT_TARGET_WITH_LABEL_TEXT, context, elab)\n",
    "        sentence, target = assistant.extract_response(response)\n",
    "        \n",
    "        test_df.at[index, \"elaboration_target\"] = target\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error ID: {index}\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        test_df.at[index, \"elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "533d14c4-5491-4ddc-9f76-930d2d9ffeb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"elaboration_target\"]==\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2c8bf55-8124-4657-89ff-0cc3bd9e5f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 116/116 [00:00<00:00, 133.32it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    if row[\"elaboration_target\"] == \"\":\n",
    "        context = row[\"label_text\"]\n",
    "        elab =  row[\"elaboration_sentence\"]   \n",
    "        try:\n",
    "            response = assistant.find_explanation_target(SYSTEM_PROMPT_TARGET_WITH_LABEL_TEXT, context, elab)\n",
    "            sentence, target = assistant.extract_response(response)\n",
    "            \n",
    "            test_df.at[index, \"elaboration_target\"] = target\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error ID: {index}\")\n",
    "            print(f\"Exception: {e}\")\n",
    "            test_df.at[index, \"elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6c3bb03-a4a7-4019-ad75-bc73c9919bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"elaboration_target\"]==\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "831e128f-865b-41b1-90dc-35f9f8ade63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_num</th>\n",
       "      <th>source_text</th>\n",
       "      <th>label_text</th>\n",
       "      <th>elaboration_sentence</th>\n",
       "      <th>contextual_specificity_rating</th>\n",
       "      <th>elaboration_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>They did not need special skills or a college ...</td>\n",
       "      <td>They did not need special skills or a college ...</td>\n",
       "      <td>Many do not have the money to get the training...</td>\n",
       "      <td>1</td>\n",
       "      <td>training they need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>WASHINGTON – At least four people died in Midw...</td>\n",
       "      <td>WASHINGTON – At least four people died in Midw...</td>\n",
       "      <td>A gauge is a kind of measuring stick.</td>\n",
       "      <td>0</td>\n",
       "      <td>gauge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>WASHINGTON – At least four people died in Midw...</td>\n",
       "      <td>WASHINGTON – At least four people died in Midw...</td>\n",
       "      <td>It sits in the water.</td>\n",
       "      <td>0</td>\n",
       "      <td>gauge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Rescue crews swarmed into the ruins at Plaza T...</td>\n",
       "      <td>Rescue crews swarmed into the ruins at Plaza T...</td>\n",
       "      <td>They raced against the setting sun to search t...</td>\n",
       "      <td>1</td>\n",
       "      <td>search the area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>One half of Istanbul lies in Europe, while the...</td>\n",
       "      <td>One half of Istanbul lies in Europe, while the...</td>\n",
       "      <td>Turkey is larger than the state of Texas.</td>\n",
       "      <td>0</td>\n",
       "      <td>state of Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1140</td>\n",
       "      <td>Some people are talking about it even more tha...</td>\n",
       "      <td>Some people are talking about it even more tha...</td>\n",
       "      <td>Like many mysteries, this one may not be solve...</td>\n",
       "      <td>2</td>\n",
       "      <td>mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1147</td>\n",
       "      <td>Should kids play tackle football? Football is ...</td>\n",
       "      <td>Should kids play tackle football? Football is ...</td>\n",
       "      <td>Players get bounced around.</td>\n",
       "      <td>2</td>\n",
       "      <td>bounced-around</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1163</td>\n",
       "      <td>Barnett made big changes at Capitol Records. H...</td>\n",
       "      <td>Barnett made big changes at Capitol Records. H...</td>\n",
       "      <td>Then the companies sell and promote the records.</td>\n",
       "      <td>0</td>\n",
       "      <td>records</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1166</td>\n",
       "      <td>They also think it is wrong to force her to pe...</td>\n",
       "      <td>They also think it is wrong to force her to pe...</td>\n",
       "      <td>There are certainly good reasons to be worried.</td>\n",
       "      <td>2</td>\n",
       "      <td>good reasons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1175</td>\n",
       "      <td>In January, U.S. District Judge Callie Granade...</td>\n",
       "      <td>In January, U.S. District Judge Callie Granade...</td>\n",
       "      <td>Judge Granade's order was immediately challenged.</td>\n",
       "      <td>1</td>\n",
       "      <td>order</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_num                                        source_text  \\\n",
       "0          6  They did not need special skills or a college ...   \n",
       "1         28  WASHINGTON – At least four people died in Midw...   \n",
       "2         28  WASHINGTON – At least four people died in Midw...   \n",
       "3         34  Rescue crews swarmed into the ruins at Plaza T...   \n",
       "4         67  One half of Istanbul lies in Europe, while the...   \n",
       "..       ...                                                ...   \n",
       "111     1140  Some people are talking about it even more tha...   \n",
       "112     1147  Should kids play tackle football? Football is ...   \n",
       "113     1163  Barnett made big changes at Capitol Records. H...   \n",
       "114     1166  They also think it is wrong to force her to pe...   \n",
       "115     1175  In January, U.S. District Judge Callie Granade...   \n",
       "\n",
       "                                            label_text  \\\n",
       "0    They did not need special skills or a college ...   \n",
       "1    WASHINGTON – At least four people died in Midw...   \n",
       "2    WASHINGTON – At least four people died in Midw...   \n",
       "3    Rescue crews swarmed into the ruins at Plaza T...   \n",
       "4    One half of Istanbul lies in Europe, while the...   \n",
       "..                                                 ...   \n",
       "111  Some people are talking about it even more tha...   \n",
       "112  Should kids play tackle football? Football is ...   \n",
       "113  Barnett made big changes at Capitol Records. H...   \n",
       "114  They also think it is wrong to force her to pe...   \n",
       "115  In January, U.S. District Judge Callie Granade...   \n",
       "\n",
       "                                  elaboration_sentence  \\\n",
       "0    Many do not have the money to get the training...   \n",
       "1                A gauge is a kind of measuring stick.   \n",
       "2                                It sits in the water.   \n",
       "3    They raced against the setting sun to search t...   \n",
       "4            Turkey is larger than the state of Texas.   \n",
       "..                                                 ...   \n",
       "111  Like many mysteries, this one may not be solve...   \n",
       "112                        Players get bounced around.   \n",
       "113   Then the companies sell and promote the records.   \n",
       "114    There are certainly good reasons to be worried.   \n",
       "115  Judge Granade's order was immediately challenged.   \n",
       "\n",
       "     contextual_specificity_rating  elaboration_target  \n",
       "0                                1  training they need  \n",
       "1                                0               gauge  \n",
       "2                                0               gauge  \n",
       "3                                1     search the area  \n",
       "4                                0      state of Texas  \n",
       "..                             ...                 ...  \n",
       "111                              2             mystery  \n",
       "112                              2      bounced-around  \n",
       "113                              0             records  \n",
       "114                              2        good reasons  \n",
       "115                              1               order  \n",
       "\n",
       "[116 rows x 6 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a2be145-992f-4b4c-8641-5f718f061252",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(os.path.join(\"../data\",\"gen_predictions\", \"elab-target-predictions_llama-instr-test_ds_c4sp-context_elab-together.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27be6ed-7858-40fe-9aad-e786fd66f835",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Indentify the elaboration target when provided seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b999f002-e85e-4b4b-85a1-7f701192c4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|█████████████████▍                        | 48/116 [00:31<00:49,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error ID: 47\n",
      "Exception: 'NoneType' object has no attribute 'start'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 116/116 [01:14<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_df[\"elaboration_target\"] = \"\"\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    context = row[\"source_text\"]\n",
    "    elab =  row[\"elaboration_sentence\"]   \n",
    "    try:\n",
    "        response = assistant.find_explanation_target(SYSTEM_PROMPT_TARGET, context, elab)\n",
    "        sentence, target = assistant.extract_response(response)\n",
    "        \n",
    "        test_df.at[index, \"elaboration_target\"] = target\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error ID: {index}\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        test_df.at[index, \"elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ecd65ef-c7f6-4853-b7ba-f7b3e0cea2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"elaboration_target\"]==\"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf89886-f0ef-4dba-b2b0-90a68e79fec4",
   "metadata": {},
   "source": [
    "### Fill NaN fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "579a91c2-a4fa-4c7f-9dd5-6cd6164bb570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 116/116 [00:00<00:00, 133.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    if row[\"elaboration_target\"] == \"\":\n",
    "        context = row[\"source_text\"]\n",
    "        elab =  row[\"elaboration_sentence\"]   \n",
    "        try:\n",
    "            response = assistant.find_explanation_target(SYSTEM_PROMPT_TARGET, context, elab)\n",
    "            sentence, target = assistant.extract_response(response)\n",
    "            \n",
    "            test_df.at[index, \"elaboration_target\"] = target\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error ID: {index}\")\n",
    "            print(f\"Exception: {e}\")\n",
    "            test_df.at[index, \"elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fdae617-daf0-4d6c-ab78-0f78c7019f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"elaboration_target\"]==\"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec3b3fd-6b6c-4f48-a628-b1ba77afd7ca",
   "metadata": {},
   "source": [
    "## Get the elaborations for given context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d47244c9-c3ba-4c84-b1a9-ad3dfdb47865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context text:  \"I can only hope that it's not going to get worse,\" Boudreau said. Illinois has laws about animal abuse and neglect. County animal control departments can issue fines. Rescue groups and volunteers may handle some abuse and neglect calls.\n",
      "\n",
      "Elaboration sentence:  The laws explain what state workers can do to deal with the cases.\n",
      "\n",
      "Generated Sentence: Illinois animal abuse laws allow county control and rescue groups to intervene and fine offenders.\n",
      "Explanation Target: animal abuse laws\n"
     ]
    }
   ],
   "source": [
    "example = dataset[\"train\"][11]\n",
    "context = example[\"source_text\"]\n",
    "elab = example[\"elaboration_sentence\"]\n",
    "print(\"Context text: \", context, end=\"\\n\\n\")\n",
    "print(\"Elaboration sentence: \", elab,end=\"\\n\\n\")\n",
    "\n",
    "response = assistant.generate_explanation(SYSTEM_PROMPT, context)\n",
    "sentence, target = assistant.extract_response(response)\n",
    "\n",
    "print(\"Generated Sentence:\", sentence)\n",
    "print(\"Explanation Target:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcecb20b-8973-465f-bc3f-ee2343f3b7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 116/116 [01:23<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_df[\"pred_elaboration\"] = \"\"\n",
    "test_df[\"pred_elaboration_target\"] = \"\"\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    context = row[\"source_text\"]\n",
    "    \n",
    "    try:\n",
    "        response = assistant.generate_explanation(SYSTEM_PROMPT, context)\n",
    "        sentence, target = assistant.extract_response(response)\n",
    "        \n",
    "        test_df.at[index, \"pred_elaboration\"] = sentence\n",
    "        test_df.at[index, \"pred_elaboration_target\"] = target\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error ID: {index}\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        test_df.at[index, \"pred_elaboration\"] = \"\"\n",
    "        test_df.at[index, \"pred_elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f06976d-ee97-4a58-9ef5-bfc5463afd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"pred_elaboration\"]==\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24830b65-c5ea-43d6-8ab8-d24c2adeb092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"pred_elaboration_target\"]==\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "909ead6e-cf5b-4d07-83c9-4ecd471e2743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.81896551724138\n"
     ]
    }
   ],
   "source": [
    "print(test_df[\"pred_elaboration\"].dropna().apply(len).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89ea1072-f292-4aac-ad7b-aeb06fa5bdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.672413793103445\n"
     ]
    }
   ],
   "source": [
    "print(test_df[\"elaboration_sentence\"].dropna().apply(len).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cbae4a-4dbc-42e8-a099-28dd7343d3cb",
   "metadata": {},
   "source": [
    "### Fill NaN fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b49bf77-559a-4335-8430-b24734c090a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 116/116 [00:01<00:00, 79.83it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "for index, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    if row[\"pred_elaboration\"]==\"\" or row[\"pred_elaboration_target\"]==\"\":\n",
    "        context = row[\"source_text\"]\n",
    "        try:\n",
    "            response = assistant.generate_explanation(SYSTEM_PROMPT, context)\n",
    "            sentence, target = assistant.extract_response(response)\n",
    "            \n",
    "            test_df.at[index, \"pred_elaboration\"] = sentence\n",
    "            test_df.at[index, \"pred_elaboration_target\"] = target\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error ID: {index}\")\n",
    "            print(f\"Exception: {e}\")\n",
    "            test_df.at[index, \"pred_elaboration\"] = \"\"\n",
    "            test_df.at[index, \"pred_elaboration_target\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8dff216-7a5c-4b46-9212-42b88de5c8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"pred_elaboration_target\"]==\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "693b1a30-1b6d-467b-8b61-703e9621d5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df[test_df[\"pred_elaboration\"]==\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b82048b4-fbe4-4a78-8082-9a4efc35522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(os.path.join(\"../data\",\"gen_predictions\", \"predictions_llama-instr-test_ds_c2os-context_elab-seperately.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c10556-f60c-4c4b-9a3f-1366a87decde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
