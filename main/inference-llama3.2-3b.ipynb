{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44d64ebf-f0ca-4096-ad2b-4347ae5065f1",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "d83499ca-d22e-4bd0-83e0-1ca3abb98f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_num', 'source_text', 'label_text', 'elaboration_sentence', 'contextual_specificity_rating'],\n",
      "        num_rows: 1049\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_num', 'source_text', 'label_text', 'elaboration_sentence', 'contextual_specificity_rating'],\n",
      "        num_rows: 134\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['doc_num', 'source_text', 'label_text', 'elaboration_sentence', 'contextual_specificity_rating'],\n",
      "        num_rows: 116\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_path = \"../data/elaborations\"\n",
    "\n",
    "data_files_c2s = {\n",
    "    'train': os.path.join(data_path,\"train\",\"train_ds_c2s.csv\"),      \n",
    "    'validation': os.path.join(data_path,\"validation\",\"valid_ds_c2s.csv\"),  \n",
    "    'test': os.path.join(data_path,\"test\",\"test_ds_c2s.csv\")         \n",
    "}\n",
    "\n",
    "data_files_c2s_masked = {\n",
    "    'train': os.path.join(data_path,\"train\",\"train_ds_c2s_masked_llama.csv\"),      \n",
    "    'validation': os.path.join(data_path,\"validation\",\"valid_ds_c2s_masked_llama.csv\"),  \n",
    "    'test': os.path.join(data_path,\"test\",\"test_ds_c2s_masked_llama.csv\")         \n",
    "}\n",
    "\n",
    "data_files_c2sp = {\n",
    "    'train': os.path.join(data_path,\"train\",\"train_ds_c2sp.csv\"),      \n",
    "    'validation': os.path.join(data_path,\"validation\",\"valid_ds_c2sp.csv\"),  \n",
    "    'test': os.path.join(data_path,\"test\",\"test_ds_c2sp.csv\")         \n",
    "}\n",
    "\n",
    "# complex only\n",
    "data_files_c2spo = {\n",
    "    'train': os.path.join(data_path,\"train\",\"train_ds_c2spo.csv\"),      \n",
    "    'validation': os.path.join(data_path,\"validation\",\"valid_ds_c2spo.csv\"),  \n",
    "    'test': os.path.join(data_path,\"test\",\"test_ds_c2spo.csv\")         \n",
    "}\n",
    "\n",
    "data_files_c2sp_masked = {\n",
    "    'train': os.path.join(data_path,\"train\",\"train_ds_c2sp_masked_llama.csv\"),      \n",
    "    'validation': os.path.join(data_path,\"validation\",\"valid_ds_c2sp_masked_llama.csv\"),  \n",
    "    'test': os.path.join(data_path,\"test\",\"test_ds_c2sp_masked_llama.csv\")         \n",
    "}\n",
    "\n",
    "data_files_c4s = {\n",
    "    'train': os.path.join(data_path,\"train\",\"train_ds_c4s.csv\"),      \n",
    "    'validation': os.path.join(data_path,\"validation\",\"valid_ds_c4s.csv\"),  \n",
    "    'test': os.path.join(data_path,\"test\",\"test_ds_c4s.csv\")         \n",
    "}\n",
    "\n",
    "data_files_c4s_masked = {\n",
    "    'train': os.path.join(data_path,\"train\",\"train_ds_c4s_masked_llama.csv\"),      \n",
    "    'validation': os.path.join(data_path,\"validation\",\"valid_ds_c4s_masked_llama.csv\"),  \n",
    "    'test': os.path.join(data_path,\"test\",\"test_ds_c4s_masked_llama.csv\")         \n",
    "}\n",
    "\n",
    "\n",
    "data_files_c2os = {\n",
    "    'train': os.path.join(data_path,\"train\",\"train_ds_c2os.csv\"),      \n",
    "    'validation': os.path.join(data_path,\"validation\",\"valid_ds_c2os.csv\"),  \n",
    "    'test': os.path.join(data_path,\"test\",\"test_ds_c2os.csv\")         \n",
    "}\n",
    "\n",
    "data_files_c2osp = {\n",
    "    'train': os.path.join(data_path,\"train\",\"train_ds_c2osp.csv\"),      \n",
    "    'validation': os.path.join(data_path,\"validation\",\"valid_ds_c2osp.csv\"),  \n",
    "    'test': os.path.join(data_path,\"test\",\"test_ds_c2osp.csv\")         \n",
    "}\n",
    "\n",
    "data_files_c4sp = {\n",
    "    'train': os.path.join(data_path,\"train\",\"train_ds_c4sp.csv\"),      \n",
    "    'validation': os.path.join(data_path,\"validation\",\"valid_ds_c4sp.csv\"),  \n",
    "    'test': os.path.join(data_path,\"test\",\"test_ds_c4sp.csv\")         \n",
    "}\n",
    "\n",
    "# complex only\n",
    "data_files_c4spo = {\n",
    "    'train': os.path.join(data_path,\"train\",\"train_ds_c4spo.csv\"),      \n",
    "    'validation': os.path.join(data_path,\"validation\",\"valid_ds_c4spo.csv\"),  \n",
    "    'test': os.path.join(data_path,\"test\",\"test_ds_c4spo.csv\")         \n",
    "}\n",
    "\n",
    "data_files_c4sp_masked = {\n",
    "    'train': os.path.join(data_path,\"train\",\"train_ds_c4sp_masked_llama.csv\"),      \n",
    "    'validation': os.path.join(data_path,\"validation\",\"valid_ds_c4sp_masked_llama.csv\"),  \n",
    "    'test': os.path.join(data_path,\"test\",\"test_ds_c4sp_masked_llama.csv\")         \n",
    "}\n",
    "\n",
    "data_files_c4osp = {\n",
    "    'train': os.path.join(data_path,\"train\",\"train_ds_c4osp.csv\"),      \n",
    "    'validation': os.path.join(data_path,\"validation\",\"valid_ds_c4osp.csv\"),  \n",
    "    'test': os.path.join(data_path,\"test\",\"test_ds_c4osp.csv\")         \n",
    "}\n",
    "\n",
    "dataset = load_dataset('csv', data_files=data_files_c4spo)\n",
    "output_name = \"c4spo\"\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b705767-facf-43d7-88b6-b4b84200d972",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Add subject and target info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "bf698348-63c2-42c5-8d25-1c1944158b9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_s = pd.read_csv(os.path.join(data_path, \"train_ds_s_subjects_targets.csv\"))\n",
    "df_train_sp = pd.read_csv(os.path.join(data_path, \"train_ds_sp_subjects_targets.csv\"))\n",
    "\n",
    "df_valid_s = pd.read_csv(os.path.join(data_path, \"validation_ds_s_subjects_targets.csv\"))\n",
    "df_valid_sp = pd.read_csv(os.path.join(data_path, \"validation_ds_sp_subjects_targets.csv\"))\n",
    "\n",
    "df_test_s = pd.read_csv(os.path.join(data_path, \"test_ds_s_subjects_targets.csv\"))\n",
    "df_test_sp = pd.read_csv(os.path.join(data_path, \"test_ds_sp_subjects_targets.csv\"))\n",
    "\n",
    "df_train = df_train_sp\n",
    "df_valid = df_valid_sp\n",
    "df_test = df_test_sp\n",
    "\n",
    "col_name = \"target_sentence_4o\" #\"target_sentence_target\"#\"target_sentence_4o\"\n",
    "\n",
    "dataset[\"train\"] = dataset[\"train\"].add_column(col_name, df_train[col_name])\n",
    "dataset[\"validation\"] = dataset[\"validation\"].add_column(col_name, df_valid[col_name])\n",
    "dataset[\"test\"] = dataset[\"test\"].add_column(col_name, df_test[col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "01905e65-a40d-4c1a-bc9e-1dc5a34089c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_num', 'source_text', 'label_text', 'elaboration_sentence', 'contextual_specificity_rating'],\n",
      "        num_rows: 1046\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_num', 'source_text', 'label_text', 'elaboration_sentence', 'contextual_specificity_rating'],\n",
      "        num_rows: 132\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['doc_num', 'source_text', 'label_text', 'elaboration_sentence', 'contextual_specificity_rating'],\n",
      "        num_rows: 116\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39018bf-ec83-4777-811d-5ede8d33edb8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Check length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85613e5a-ac65-42c2-b1b9-9cef364c7d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 0, 'validation': 0, 'test': 0}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_texts_over_word_limit(dataset_dict, column, word_limit=150):\n",
    "    word_count = {}\n",
    "\n",
    "    for split in dataset_dict:\n",
    "        dataset = dataset_dict[split]\n",
    "        count_over_limit = 0\n",
    "\n",
    "        for example in dataset:\n",
    "            try:\n",
    "                num_words = len(example[column].split()) # count on spaces\n",
    "                if num_words > word_limit:\n",
    "                    count_over_limit += 1\n",
    "            except AttributeError as e: \n",
    "                print(f\"Empty string in doc num: {example['doc_num']}\")\n",
    "                continue \n",
    "\n",
    "        word_count[split] = count_over_limit\n",
    "\n",
    "    return word_count\n",
    "\n",
    "count_texts_over_word_limit(dataset, column='source_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6b6f6-b982-4cf2-8b0a-d2357ed4ea9e",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8177410-3aa9-44fa-84f7-66c2d7f375a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49ef83121b544d2998361f092992c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from trl import setup_chat_format\n",
    "from trl.extras.dataset_formatting import conversations_formatting_function\n",
    "torch.cuda.empty_cache()\n",
    "# LLAMA 3.2 3B\n",
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', cache_dir=\"../models/llama/\") \n",
    "model =  AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct', cache_dir=\"../models/llama/\", device_map ={'':torch.cuda.current_device()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9062c07-ee30-4b0b-bbd9-98e2f64f55c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZERO_SHOT_SYSTEM_PROMPT = \"\"\"You are an expert in generating exactly one short explanatory sentence (made up of around 10 words or fewer) in a plain English for a given context text. \n",
    "Your task is to provide additional information related to the complex statement, term, action, or concept that is semantically missing from the context text.\n",
    "You may do this by offering a definition, examples, background knowledge, general statements, a description of the flow of actions, or an explanation of the reason or result of the target action.\n",
    "The tone should be plain and simple!\n",
    "Return only ONE short concise explanatory sentence!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f51472-05c5-43e7-b6d9-83576a1d732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text with elaboration sentence masked -> elaboration sentence\n",
    "SYSTEM_PROMPT_MASKED = \"\"\"You are an expert in generating exactly one short explanatory sentence (made up of around 10 words or fewer) in a plain English for a given context text. \n",
    "Your task is to provide additional information related to the complex statement, term, action, or concept that is semantically missing from the context text.\n",
    "You may do this by offering a definition, examples, background knowledge, general statements, a description of the flow of actions, or an explanation of the reason or result of the target action.\n",
    "Your task is to replace the `<explanatory sentence>` tag in the provided text with the explanation sentence you generate.\n",
    "Return only the explanation sentence itself, without any tags, formatting, or additional text.\n",
    "The tone should be plain and simple!\n",
    "Return only ONE short concise explanatory sentence!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e6539b-9475-40c9-aed3-e9b54584a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text with elaboration sentence masked -> text with filled-out elaboration sentence\n",
    "SYSTEM_PROMPT_MASKED2 = \"\"\"You are an expert in generating exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. \n",
    "Your task is to replace the `<explanatory sentence>` tag in the provided text with an explanation sentence that adds relevant information to clarify a complex statement, term, action, or concept that is semantically missing from the text.\n",
    "The tone should be plain and simple!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c9262f8-8fd8-4e81-a050-03f96a988a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_SHORT = \"\"\"You are an expert in generating exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. \n",
    "The tone should be plain and simple!\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb3f940-0400-4372-9c67-b9e89cb081e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ChatMLFormat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92029d21-5798-42d5-bb40-9adc2af65c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "formatting_func = conversations_formatting_function(tokenizer, \"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d453b47-f98c-4955-aa56-fe15c877bcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are an expert in generating exactly one short explanatory sentence (made up of around 10 words or fewer) in a plain English for a given context text. \n",
      "Your task is to provide additional information related to the complex statement, term, action, or concept that is semantically missing from the context text.\n",
      "You may do this by offering a definition, examples, background knowledge, general statements, a description of the flow of actions, or an explanation of the reason or result of the target action.\n",
      "Your task is to replace the `<explanatory sentence>` tag in the provided text with the explanation sentence you generate.\n",
      "Return only the explanation sentence itself, without any tags, formatting, or additional text.\n",
      "The tone should be plain and simple!\n",
      "Return only ONE short concise explanatory sentence!\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "Context: A watermark is an image that can be seen in the paper when you hold it up to the light. Investigators say Kellogg tried to copy the watermark. <explanatory sentence> First he printed the front side of the money on one piece of paper. He printed the back of the bill on a separate sheet.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Here's how they say he did it.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formatted_example = formatting_func(formatted_train_dataset[0])\n",
    "print(formatted_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0af7e840-2264-45ff-a5aa-e4c1698f0617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'You are an expert in generating exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. \\nThe tone should be plain and simple!',\n",
       "  'role': 'system'},\n",
       " {'content': \": Return the explanation sentence for the following context text: 'A watermark is an image that can be seen in the paper when you hold it up to the light. Investigators say Kellogg tried to copy the watermark.'. The subject of the explanation sentence should be: 'Investigators'.\",\n",
       "  'role': 'user'},\n",
       " {'content': \"Here's how they say he did it.\", 'role': 'assistant'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_train_dataset[0][\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9402afb9-7925-4046-a7b8-dfc05774e50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "243b6ff8-4f7c-49ad-bdd9-4cfd7f8e7bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2269396b346400b906c60fdd945290f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1046 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97ce3f05e8b4fd0a6abab572db69aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/132 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa80adc1ba3440d998c2fdc5d34fd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_user_message_subject(example):\n",
    "    return f\": Return the explanation sentence for the following context text: '{example['source_text']}'. The subject of the explanation sentence should be: '{example['subject']}'.\"\n",
    "\n",
    "\n",
    "def format_example(example):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT_SHORT},\n",
    "            {\"role\": \"user\", \"content\": create_user_message_subject(example)}, # Context or Text\n",
    "            {\"role\": \"assistant\", \"content\":  f\"{example['elaboration_sentence']}\"}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "\n",
    "def format_test_example(example):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT_SHORT},\n",
    "            {\"role\": \"user\", \"content\": create_user_message_subject(example)},\n",
    "             {\"role\": \"assistant\", \"content\":\"\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "formatted_train_dataset = dataset[\"train\"].map(format_example)\n",
    "formatted_validation_dataset = dataset[\"validation\"].map(format_example)\n",
    "formatted_test_dataset = dataset[\"test\"].map(format_test_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba143790-1f66-4aa2-9056-ebbe482dd684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length of messages: 28.91459528362014\n"
     ]
    }
   ],
   "source": [
    "def calculate_mean_message_length(dataset):\n",
    "    total_length = 0\n",
    "    message_count = 0\n",
    "\n",
    "    for entry in dataset:\n",
    "        messages = entry.get('messages', [])\n",
    "        for message in messages:\n",
    "            content = message.get('content', \"\")\n",
    "            total_length += len(content.split())  # Count words in the content\n",
    "            message_count += 1\n",
    "\n",
    "    return total_length / message_count if message_count > 0 else 0\n",
    "\n",
    "mean_length = calculate_mean_message_length(formatted_train_dataset)\n",
    "print(f\"Mean length of messages: {mean_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a2e794-dcce-419c-aa59-f89be8377bd0",
   "metadata": {},
   "source": [
    "## Alpaca format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b18901e-b3a3-4253-9817-5842eb2e92f0",
   "metadata": {},
   "source": [
    "#### BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "fb88a33f-34fe-4205-bbc8-78b0e64839d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def create_user_message(context):\n",
    "    return f\"Return an explanation sentence for the following context text: '{context}'.\"\n",
    "\n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
    "For example: \n",
    "context text: 'The environment is essential for sustaining life, providing clean air, water, and fertile soil. Protecting it ensures a healthier planet for future generations. '\n",
    "assistant: 'This includes reducing pollution and conserving resources.'\n",
    "\n",
    "context text: 'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from serene cherry blossom gardens to towering Mount Fuji.'\n",
    "assistant: 'Mount Fuji is the tallest mountain in Japan.'\n",
    "\n",
    "{}\\n### Assistant:\"\"\"\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    texts = []\n",
    "    for context in contexts:\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = test_alpaca_prompt.format(create_user_message(context)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "b866120e-12a0-407a-9b1e-2779f88fb9e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \\nFor example: \\ncontext text: \\'The environment is essential for sustaining life, providing clean air, water, and fertile soil. Protecting it ensures a healthier planet for future generations. \\'\\nassistant: \\'This includes reducing pollution and conserving resources.\\'\\n\\ncontext text: \\'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from serene cherry blossom gardens to towering Mount Fuji.\\'\\nassistant: \\'Mount Fuji is the tallest mountain in Japan.\\'\\n\\nReturn an explanation sentence for the following context text: \\'Factories have closed and their low-skill manufacturing jobs are long gone. The new companies in town require workers with a college degree or advanced training. But the turnaround will take more than just new companies moving to town; New Haven needs to invest in educating its youth so they will be qualified to do those high-skilled jobs when they become adults. The New Haven Promise is no one-way street. The New Haven Promise is no one-way street. Although the scholarship is available to all students, they must sign a pledge to \"do their best\" in certain vital areas of achievement. The goal is to create an expectation that all students can and will attend college.\\'.\\n### Assistant:'"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92129a-7f46-426d-9782-54be33bd78db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Masked version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "097819d9-92cb-4eb7-9b7d-45afb2b4c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def create_user_message(context):\n",
    "    return f\"Return the explanation sentence that could replace the `<explanatory sentence>` tag in the following text: '{context}'.\"\n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English that could replace the <explanatory sentence> tag in a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
    "For example: \n",
    "context text: 'The environment is essential for sustaining life, providing clean air, water, and fertile soil. <explanatory sentence> Protecting the environment ensures a healthier planet for future generations. '\n",
    "assistant: 'Fertile soil is ideal for growing plants.'\n",
    "\n",
    "context text: 'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from serene cherry blossom gardens to towering Mount Fuji. <explanatory sentence>'\n",
    "assistant: 'Mount Fuji is the tallest mountain in Japan.'\n",
    "\n",
    "{}\\n### Assistant:\"\"\"\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    texts = []\n",
    "    for context in contexts:\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = test_alpaca_prompt.format(create_user_message(context)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f7deab73-bc2a-4381-838a-485e7c54f315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English that could replace the <explanatory sentence> tag in a given context text. The tone should be plain and simple! Do not add any comments to your answer! \\nFor example: \\ncontext text: \\'The environment is essential for sustaining life, providing clean air, water, and fertile soil. <explanatory sentence> Protecting the environment ensures a healthier planet for future generations. \\'\\nassistant: \\'Fertile soil is ideal for growing plants.\\'\\n\\ncontext text: \\'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from serene cherry blossom gardens to towering Mount Fuji. <explanatory sentence>\\'\\nassistant: \\'Mount Fuji is the tallest mountain in Japan.\\'\\n\\nReturn the explanation sentence that could replace the `<explanatory sentence>` tag in the following text: \\'They did not need special skills or a college education to work there. Those factories are gone now. New companies have come that need skilled workers with more education. New Haven youth want those jobs, but they do not have the education or the skills. <explanatory sentence> That is where New Haven Promise comes in. It will make a difference by paying for college. New Haven Promise is no one-way street. The students have to sign a pledge to \"do their best.\"\\'.\\n### Assistant:'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f0762-c9e4-4a5e-ad9a-b356b79ad05e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Specifying subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "42af8e4f-6fd8-47f6-a995-b04cb8d07357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def create_user_message_subject(context, subject):\n",
    "    return f\"Return the explanation sentence for the following context text: '{context}'. The explanation sentence should refer to the subject='{subject}'.\"\n",
    "print(tokenizer.eos_token )\n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
    "For example: \n",
    "context text: 'The environment is essential for sustaining life, providing clean air, water, and fertile soil. Protecting it ensures a healthier planet for future generations. '\n",
    "subject='protecting the environment'\n",
    "assistant: 'This includes reducing pollution and conserving resources.'\n",
    "\n",
    "context text: 'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from serene cherry blossom gardens to towering Mount Fuji.'\n",
    "subject='Mount Fuji'\n",
    "assistant: 'Mount Fuji is the tallest mountain in Japan.'\n",
    "\n",
    "{}\\n### Assistant:\"\"\"\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    subjects = examples[\"subject\"]\n",
    "    texts = []\n",
    "    for context, subject in zip(contexts, subjects):\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = test_alpaca_prompt.format(create_user_message_subject(context, subject)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f1b41f91-b3ca-424b-b5ce-3f9adc50a9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \\nFor example: \\ncontext text: \\'The environment is essential for sustaining life, providing clean air, water, and fertile soil. Protecting it ensures a healthier planet for future generations. \\'\\nsubject=\\'protecting the environment\\'\\nassistant: \\'This includes reducing pollution and conserving resources.\\'\\n\\ncontext text: \\'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from serene cherry blossom gardens to towering Mount Fuji.\\'\\nsubject=\\'Mount Fuji\\'\\nassistant: \\'Mount Fuji is the tallest mountain in Japan.\\'\\n\\nReturn the explanation sentence for the following context text: \\'They did not need special skills or a college education to work there. Those factories are gone now. New companies have come that need skilled workers with more education. New Haven youth want those jobs, but they do not have the education or the skills. That is where New Haven Promise comes in. It will make a difference by paying for college. New Haven Promise is no one-way street. The students have to sign a pledge to \"do their best.\"\\'. The explanation sentence should refer to the subject=\\'Many (youth)\\'.\\n### Assistant:'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c6525d-4d22-484e-bb65-897d8065674d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Specifying the target phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "078aedb1-8ac3-4029-bd70-b12baf9c2f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def create_user_message_target(context, target):\n",
    "    return f\"Return the explanation sentence for the following context text: '{context}'. The explanation sentence should clarify the {target}.\"\n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
    "For example: \n",
    "context text: 'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from cherry blossom gardens to towering Mount Fuji.'\n",
    "target_phrase='cultural heritage'\n",
    "Assistant: This heritage includes traditional arts like tea ceremony or calligraphy. \n",
    "\n",
    "context text: 'One of the most thrilling events in winter sports is ski jumping. Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
    "target_phrase='glide down'\n",
    "Assistant: As they glide down, they gain speed, which helps them jump higher into the air.\n",
    "\n",
    "{}\\n### Assistant:\"\"\"\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    targets = examples[\"target_sentence_target\"]\n",
    "    texts = []\n",
    "    for context, target in zip(contexts, targets):\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = test_alpaca_prompt.format(create_user_message_target(context, target)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "391ec16b-c476-4c9d-93e5-d3f500f580db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \\nFor example: \\ncontext text: \\'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from cherry blossom gardens to towering Mount Fuji.\\'\\ntarget_phrase=\\'cultural heritage\\'\\nAssistant: This heritage includes traditional arts like tea ceremony or calligraphy. \\n\\ncontext text: \\'One of the most thrilling events in winter sports is ski jumping. Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.\\'\\ntarget_phrase=\\'glide down\\'\\nAssistant: As they glide down, they gain speed, which helps them jump higher into the air.\\n\\nReturn the explanation sentence for the following context text: \\'They did not need special skills or a college education to work there. Those factories are gone now. New companies have come that need skilled workers with more education. New Haven youth want those jobs, but they do not have the education or the skills. That is where New Haven Promise comes in. It will make a difference by paying for college. New Haven Promise is no one-way street. The students have to sign a pledge to \"do their best.\"\\'. The explanation sentence should clarify the target_phrase=\\'do not have the education or the skills\\'.\\n### Assistant:'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec81b72e-6aa7-41b9-8532-9e2bb9518809",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Specifying the target sentence for clarification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "11f1b2c3-58f8-4d85-a82c-e868d092e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def create_user_message_target(context, target):\n",
    "    return f\"Return the explanation sentence for the following context text: '{context}'. The explanation sentence should specifically clarify the {target}.\"\n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
    "For example: \n",
    "context text: 'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from cherry blossom gardens to towering Mount Fuji.'\n",
    "target_sentence='Japan is known for its rich cultural heritage and advanced technology.'\n",
    "Assistant: This heritage includes traditional arts like tea ceremony or calligraphy. \n",
    "\n",
    "context text: 'One of the most thrilling events in winter sports is ski jumping. Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
    "target_sentence='Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
    "Assistant: As they glide down, they gain speed, which helps them jump higher into the air.\n",
    "\n",
    "{}\\n### Assistant:\"\"\"\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    targets = examples[\"target_sentence_4o\"]\n",
    "    texts = []\n",
    "    for context, target in zip(contexts, targets):\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = test_alpaca_prompt.format(create_user_message_target(context, target)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9f2e3a61-6a56-4a5e-8f10-904b94cef3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \\nFor example: \\ncontext text: \\'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from cherry blossom gardens to towering Mount Fuji.\\'\\ntarget_sentence=\\'Japan is known for its rich cultural heritage and advanced technology.\\'\\nAssistant: This heritage includes traditional arts like tea ceremony or calligraphy. \\n\\ncontext text: \\'One of the most thrilling events in winter sports is ski jumping. Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.\\'\\ntarget_sentence=\\'Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.\\'\\nAssistant: As they glide down, they gain speed, which helps them jump higher into the air.\\n\\nReturn the explanation sentence for the following context text: \\'They did not need special skills or a college education to work there. Those factories are gone now. New companies have come that need skilled workers with more education. New Haven youth want those jobs, but they do not have the education or the skills. That is where New Haven Promise comes in. It will make a difference by paying for college. New Haven Promise is no one-way street. The students have to sign a pledge to \"do their best.\"\\'. The explanation sentence should specifically clarify the target_sentence=\\'New Haven youth want those jobs, but they do not have the education or the skills.\\'.\\n### Assistant:'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff533823-631a-4975-ba34-cbf7670cade1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Specifying both the target phrase/ subject and the target sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "03d92cb0-23c4-4cfd-b4af-82e2681310e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def create_user_message_target(context, target,target_sentence):\n",
    "    return f\"Return the explanation sentence for the following context text: '{context}'. The explanation sentence should specifically clarify the {target_sentence} by referring to the subject='{target}'.\"\n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \n",
    "For example: \n",
    "context text: 'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from cherry blossom gardens to towering Mount Fuji.'\n",
    "target_sentence='Japan is known for its rich cultural heritage and advanced technology.'\n",
    "subject='heritage'\n",
    "Assistant: This heritage includes traditional arts like tea ceremony or calligraphy. \n",
    "\n",
    "context text: 'One of the most thrilling events in winter sports is ski jumping. Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
    "target_sentence='Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
    "subject='the athletes'\n",
    "Assistant: As they glide down, they gain speed, which helps them jump higher into the air.\n",
    "\n",
    "{}\\n### Assistant:\"\"\"\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    targets = examples[\"subject\"] # target_sentence_target\n",
    "    target_sents = examples[\"target_sentence_4o\"]\n",
    "    texts = []\n",
    "    for context, target, target_sent in zip(contexts, targets, target_sents):\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = test_alpaca_prompt.format(create_user_message_target(context, target, target_sent)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "e5f3828e-894a-4210-97e0-9bdfcfb00d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! Do not add any comments to your answer! \\nFor example: \\ncontext text: \\'Japan is known for its rich cultural heritage and advanced technology. Its landscapes range from cherry blossom gardens to towering Mount Fuji.\\'\\ntarget_sentence=\\'Japan is known for its rich cultural heritage and advanced technology.\\'\\nsubject=\\'heritage\\'\\nAssistant: This heritage includes traditional arts like tea ceremony or calligraphy. \\n\\ncontext text: \\'One of the most thrilling events in winter sports is ski jumping. Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.\\'\\ntarget_sentence=\\'Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.\\'\\nsubject=\\'the athletes\\'\\nAssistant: As they glide down, they gain speed, which helps them jump higher into the air.\\n\\nReturn the explanation sentence for the following context text: \\'They did not need special skills or a college education to work there. Those factories are gone now. New companies have come that need skilled workers with more education. New Haven youth want those jobs, but they do not have the education or the skills. That is where New Haven Promise comes in. It will make a difference by paying for college. New Haven Promise is no one-way street. The students have to sign a pledge to \"do their best.\"\\'. The explanation sentence should specifically clarify the target_sentence=\\'New Haven youth want those jobs, but they do not have the education or the skills.\\' by referring to the subject=\\'Many (youth)\\'.\\n### Assistant:'"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd2e69e-4875-4ef6-b975-f1c9c0a6b40c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Specifying both the target phrase (from the target sentence) and the target sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a3ffba-9b3a-47f1-9839-687218469c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "alpaca_prompt = \"\"\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! {}\\n### Assistant: {}\"\"\"\n",
    "\n",
    "def create_user_message_target(context, target, target_sentence):\n",
    "    return f\"Return the explanation sentence for the following context text: '{context}'. The explanation sentence should specifically clarify the {target_sentence} by referring to the {target}.\"\n",
    "print(tokenizer.eos_token )\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    targets = examples[\"target_sentence_target\"]\n",
    "    target_sents = examples[\"target_sentence_4o\"]\n",
    "    elab_sentences = examples[\"elaboration_sentence\"]\n",
    "    texts = []\n",
    "    for context, target, target_sent, elab_sent in zip(contexts, targets, target_sents, elab_sentences):\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = alpaca_prompt.format(create_user_message_target(context, target, target_sent), elab_sent) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! {}\\n### Assistant:\"\"\"\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    targets = examples[\"target_sentence_target\"]\n",
    "    target_sents = examples[\"target_sentence_4o\"]\n",
    "    texts = []\n",
    "    for context, target, target_sent in zip(contexts, targets, target_sents):\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = test_alpaca_prompt.format(create_user_message_target(context, target, target_sent)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "596825aa-a5f4-4613-80f8-4ec8a6475116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. The tone should be plain and simple! Return the explanation sentence for the following context text: 'New companies have come that need skilled workers with more education. New Haven youth want those jobs, but they do not have the education or the skills.'. The explanation sentence should specifically clarify the target_sentence='New Haven youth want those jobs, but they do not have the education or the skills.' by referring to the target_phrase='do not have the education or the skills'.\\n### Assistant:\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b125b1-9f2b-4d2b-97ef-cc8a35f9752d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Target sentence -> elaboration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ad575a39-e350-45af-b4e7-081e084bc7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def create_user_message(context):\n",
    "    return f\"Return the clarification sentence for the {context}. \"\n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: Your task is to generate exactly ONE short concise clarification sentence (made up of around 10 words or fewer) in a plain English for a given sentence. The tone should be plain and simple! Do not add any comments to your answer! \n",
    "For example:\n",
    "target_sentence='Japan\\'slandscapes range from serene cherry blossom gardens to towering Mount Fuji.'\n",
    "Assistant: Mount Fuji is the tallest mountain in Japan.\n",
    "\n",
    "target_sentence='Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
    "Assistant: As they glide down, they gain speed, which helps them jump higher into the air.\n",
    "\n",
    "{}\\n### Assistant:\"\"\"\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"target_sentence_4o\"]\n",
    "    texts = []\n",
    "    for context in contexts:\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = test_alpaca_prompt.format(create_user_message(context)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "22a700af-2493-4f5a-9552-78ce6ff0f8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### User: Your task is to generate exactly ONE short concise clarification sentence (made up of around 10 words or fewer) in a plain English for a given sentence. The tone should be plain and simple! Do not add any comments to your answer! \\nFor example:\\ntarget_sentence='Japan'slandscapes range from serene cherry blossom gardens to towering Mount Fuji.'\\nAssistant: Mount Fuji is the tallest mountain in Japan.\\n\\ntarget_sentence='Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\\nAssistant: As they glide down, they gain speed, which helps them jump higher into the air.\\n\\nReturn the clarification sentence for the target_sentence='New Haven youth want those jobs, but they do not have the education or the skills.'. \\n### Assistant:\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f254e-e425-43f6-a4fa-1dcd59de1eb0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Target sentence + target phrase/subject -> elaboration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7914c481-72d0-434d-af4d-68636774cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the pad_token for llama 3.2 3B\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def create_user_message(context, target):\n",
    "    return f\"Return the clarification sentence for the {context}. The explanation sentence should refer to the {target}.\" \n",
    "\n",
    "test_alpaca_prompt = \"\"\"### User: Your task is to generate exactly ONE short concise clarification sentence (made up of around 10 words or fewer) in a plain English for a given sentence. The tone should be plain and simple! Do not add any comments to your answer! \n",
    "For example:\n",
    "target_sentence='Japan\\'slandscapes range from serene cherry blossom gardens to towering Mount Fuji.'\n",
    "target_phrase='Mount Fuji'\n",
    "Assistant: Mount Fuji is the tallest mountain in Japan.\n",
    "\n",
    "target_sentence='Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\n",
    "target_phrase='glide down'\n",
    "Assistant: As they glide down, they gain speed, which helps them jump higher into the air.\n",
    "\n",
    "{}\\n### Assistant:\"\"\"\n",
    "\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"target_sentence_4o\"]\n",
    "    targets = examples[\"target_sentence_target\"]\n",
    "    texts = []\n",
    "    for context, target in zip(contexts,targets):\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = test_alpaca_prompt.format(create_user_message(context, target)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f49aaa8d-82f3-4617-9c01-460ad7508c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### User: Your task is to generate exactly ONE short concise clarification sentence (made up of around 10 words or fewer) in a plain English for a given sentence. The tone should be plain and simple! Do not add any comments to your answer! \\nFor example:\\ntarget_sentence='Japan'slandscapes range from serene cherry blossom gardens to towering Mount Fuji.'\\ntarget_phrase='Mount Fuji'\\nAssistant: Mount Fuji is the tallest mountain in Japan.\\n\\ntarget_sentence='Ski jumping is a winter sport where athletes glide down a ramp and jump to achieve maximum distance.'\\ntarget_phrase='glide down'\\nAssistant: As they glide down, they gain speed, which helps them jump higher into the air.\\n\\nReturn the clarification sentence for the target_sentence='New Haven youth want those jobs, but they do not have the education or the skills.'. The explanation sentence should refer to the target_phrase='do not have the education or the skills'.\\n### Assistant:\""
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c520e3-867f-43a5-89cd-e2891ad05e84",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### For testing the model trained with the subject or target info  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76507e12-1f19-4099-862e-07847aeccb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_message(context):\n",
    "    return f\"Return the explanation sentence for the following context text: '{context}'.\"\n",
    "\n",
    "def formatting_test_prompts_func(examples):\n",
    "    contexts = examples[\"source_text\"]\n",
    "    texts = []\n",
    "    for context in contexts:\n",
    "        # must add EOS_TOKEN, otherwise the generation wont stop\n",
    "        text = test_alpaca_prompt.format(create_user_message(context)) \n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "412c4275-58f7-445c-8e21-23c7bb6b2b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. \\nThe tone should be plain and simple! Return the explanation sentence for the following context text: 'They did not need special skills or a college education to work there. Those factories are gone now. New companies have come that need skilled workers with more education. New Haven youth want those jobs, but they do not have the education or the skills.'.\\n### Assistant:\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb732d3c-51c3-4780-914f-441e5faf7044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('###', 14711), ('User', 2724), (':', 25), ('Your', 4718), ('task', 3465), ('is', 374), ('to', 311), ('generate', 7068), ('exactly', 7041), ('ONE', 25002), ('short', 2875), ('concise', 64694), ('explanation', 16540), ('sentence', 11914), ('(', 320), ('made', 28010), ('up', 709), ('of', 315), ('around', 2212), ('', 220), ('10', 605), ('words', 4339), ('or', 477), ('fewer', 17162), (')', 8), ('in', 304), ('a', 264), ('plain', 14733), ('English', 6498), ('for', 369), ('a', 264), ('given', 2728), ('context', 2317), ('text', 1495), ('.', 13), ('The', 578), ('tone', 16630), ('should', 1288), ('be', 387), ('plain', 14733), ('and', 323), ('simple', 4382), ('!', 0), ('Return', 3494), ('the', 279), ('explanation', 16540), ('sentence', 11914), ('for', 369), ('the', 279), ('following', 2768), ('context', 2317), ('text', 1495), (':', 25), (\"'\", 364), ('A', 32), ('watermark', 89106), ('is', 374), ('an', 459), ('image', 2217), ('that', 430), ('can', 649), ('be', 387), ('seen', 3970), ('in', 304), ('the', 279), ('paper', 5684), ('when', 994), ('you', 499), ('hold', 3412), ('it', 433), ('up', 709), ('to', 311), ('the', 279), ('light', 3177), ('.', 13), ('Investigators', 96852), ('say', 2019), ('Kel', 28263), ('logg', 94469), ('tried', 6818), ('to', 311), ('copy', 3048), ('the', 279), ('watermark', 89106), ('.', 13), ('First', 5629), ('he', 568), ('printed', 17124), ('the', 279), ('front', 4156), ('side', 3185), ('of', 315), ('the', 279), ('money', 3300), ('on', 389), ('one', 832), ('piece', 6710), ('of', 315), ('paper', 5684), ('.', 13), ('He', 1283), ('printed', 17124), ('the', 279), ('back', 1203), ('of', 315), ('the', 279), ('bill', 4121), ('on', 389), ('a', 264), ('separate', 8821), ('sheet', 11071), (\".'.\", 37049), ('The', 578), ('subject', 3917), ('of', 315), ('the', 279), ('explanation', 16540), ('sentence', 11914), ('should', 1288), ('refer', 8464), ('to', 311), (':', 551), (\"'\", 364), ('Investigators', 88280), (\"'.\", 24482), ('###', 14711), ('Assistant', 22103), (':', 25), ('Here', 5810), (\"'s\", 596), ('how', 1268), ('they', 814), ('say', 2019), ('he', 568), ('did', 1550), ('it', 433), ('.', 13), ('<|end_of_text|>', 128001)]\n"
     ]
    }
   ],
   "source": [
    "def print_tokens_with_ids(txt):\n",
    "    tokens = tokenizer.tokenize(txt, add_special_tokens=False)\n",
    "    token_ids = tokenizer.encode(txt, add_special_tokens=False)\n",
    "    print(list(zip(tokens, token_ids)))\n",
    "\n",
    "formatted_ds = formatting_prompts_func(dataset[\"train\"])\n",
    "prompt = formatted_ds[0]\n",
    "print_tokens_with_ids(prompt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ec86548-bf9d-474a-ba83-3ac8ac702f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('###', 14711), ('Assistant', 22103), (':', 25)]\n"
     ]
    }
   ],
   "source": [
    "response_template = \"### Assistant:\"\n",
    "print_tokens_with_ids(response_template) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d28e00-7289-4b1a-a145-e0b28b712807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. \\nThe tone should be plain and simple! Return the explanation sentence for the following context text: 'New companies have come that need skilled workers with more education. New Haven youth want those jobs, but they do not have the education or the skills. That is where New Haven Promise comes in. It will make a difference by paying for college.'. The subject of the explanation sentence should refer to : 'Many (youth)'.\\n### Assistant:\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_test_dataset = formatting_test_prompts_func(dataset[\"test\"])\n",
    "formatted_test_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fc09ce-cea6-42ac-923f-ee4439ef2098",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d8114a3-d6ac-4018-b525-9adfffcd6f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory does not exist: ../models/llama3.2-news-ft/logs/logs-c2osp\n"
     ]
    }
   ],
   "source": [
    "from model_utils import clear_directory\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "del model, trainer, tokenizer, data_collator\n",
    "clear_directory(logs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14720cf-289f-4966-a7fe-fb7c44cba331",
   "metadata": {},
   "source": [
    "# Generate predictions\n",
    "\n",
    "https://github.com/NielsRogge/Transformers-Tutorials/blob/master/Mistral/Supervised_fine_tuning_(SFT)_of_an_LLM_using_Hugging_Face_tooling.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf09a9-2254-4e79-95cb-99fd71423fe7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf8eefee-d1d1-491d-9a25-3c6537224d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "formatting_func = conversations_formatting_function(tokenizer, \"messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ded004-8ee1-4a7c-982b-9e3c8133ab47",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "2b0b34c5-94cf-4f1e-97ee-0f4345f78b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, StoppingCriteria, StoppingCriteriaList\n",
    "import torch\n",
    "\n",
    "class RefinedEndSentenceStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, tokenizer, sentence_end_tokens):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sentence_end_token_ids = [\n",
    "            self.tokenizer.convert_tokens_to_ids(token) for token in sentence_end_tokens\n",
    "        ]\n",
    "        self.eos_token_id = tokenizer.eos_token_id  # Include eos_token_id\n",
    "\n",
    "    def is_valid_stop(self, input_ids):\n",
    "        # Get the last token and the one before it\n",
    "        if len(input_ids[0]) < 2:\n",
    "            return False  # Not enough tokens to decide\n",
    "        last_token_id = input_ids[0, -1].item()\n",
    "        second_last_token_id = input_ids[0, -2].item()\n",
    "\n",
    "        # Decode tokens to check context\n",
    "        last_token = self.tokenizer.decode([last_token_id])\n",
    "        second_last_token = self.tokenizer.decode([second_last_token_id])\n",
    "\n",
    "        # Stop if it's a sentence-ending token and not part of an abbreviation\n",
    "        if (\n",
    "            last_token in [\".\", \"!\", \"?\"]  # Check if it's a sentence-ending token\n",
    "            and len(second_last_token) > 1  # Ensure not part of an abbreviation\n",
    "            and not second_last_token.isupper()  # Ensure it's not \"U.S.\" or similar\n",
    "        ):\n",
    "            return True\n",
    "\n",
    "        # Include end-of-sequence token\n",
    "        return last_token_id == self.eos_token_id\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        return self.is_valid_stop(input_ids)\n",
    "\n",
    "\n",
    "sentence_end_tokens = [\".\",\"\\n\",\"!\", \"?\"]\n",
    "stopping_criteria = StoppingCriteriaList([RefinedEndSentenceStoppingCriteria(tokenizer, sentence_end_tokens)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c76997f-f044-4050-99fa-668f6fcfcc17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Generate with ChatML format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1d2374f-5a00-42db-93af-7a78b98af28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_assistant_response(conversation, keyword=\"assistant\"):\n",
    "    \"\"\"\n",
    "    Extracts the response under the given keyword from a conversation.\n",
    "    \"\"\"\n",
    "    # split the conversation by lines\n",
    "    lines = conversation.strip().split(\"\\n\")\n",
    "    # iterate over the lines to find the assistant's response\n",
    "    for i, line in enumerate(lines):\n",
    "        if line == keyword:\n",
    "            if i + 1 < len(lines):\n",
    "                return \" \".join(lines[(i + 2):])\n",
    "    \n",
    "    # an empty string if no response is found\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10f646f1-8a75-425f-a0fe-c45cd37ade50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "You are an expert in generating exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. \n",
      "The tone should be plain and simple!\n",
      "user\n",
      ": Return the explanation sentence for the following context text: 'But it is far more than just a nice thing to wear. It shows a person's importance.'. The subject of the explanation sentence should be: 'a gift'.\n",
      "assistant\n",
      "\n",
      ": The subject should be in the following format: 'A gift is a...'. The verb should be 'to be'. The subject and verb should NOT be\n",
      "Extracted Response: : The subject should be in the following format: 'A gift is a...'. The verb should be 'to be'. The subject and verb should NOT be\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "example = random.choice(formatted_test_dataset)\n",
    "\n",
    "input_text = formatting_func(example)\n",
    "inputs = tokenizer(\n",
    "    input_text,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512  # Adjust max_length as needed\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=32,  # 32 for elaboration-only generation\n",
    "        min_length=10,\n",
    "        do_sample=False,  # Greedy decoding\n",
    "        temperature=None,  # not used in greedy decoding\n",
    "        top_p=None,  # not used in greedy decoding\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=3,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        stopping_criteria=stopping_criteria\n",
    "    )\n",
    "\n",
    "generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(generated_text)\n",
    "response = extract_assistant_response(generated_text)\n",
    "print(\"Extracted Response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c77de2-c8d2-489e-a4ad-e375f5df8fff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Generate with alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b3bb735-03e5-4475-a260-36926ca2a5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### User: Your task is to generate exactly ONE short concise explanation sentence (made up of around 10 words or fewer) in a plain English for a given context text. \n",
      "The tone should be plain and simple! Return the explanation sentence for the following context text: 'Brown was a black teenager without a weapon who was shot by a white police officer. He was killed in August in Ferguson, Missouri, near St. Louis. The shooting set off nearly nightly protests and violence. The black community felt that Brown wouldn't have been killed if he was white.'.\n",
      "### Assistant: The officer was not charged with a crime.\n",
      "Extracted Response: The officer was not charged with a crime.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "example = random.choice(formatted_test_dataset)\n",
    "\n",
    "inputs = tokenizer(\n",
    "    example, #input_text,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512  # Adjust max_length as needed\n",
    ").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=32,  # 32 for elaboration-only generation\n",
    "        min_length=10,\n",
    "        do_sample=False,  # Greedy decoding\n",
    "        temperature=None,  # not used in greedy decoding\n",
    "        top_p=None,  # not used in greedy decoding\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=3,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        stopping_criteria=stopping_criteria\n",
    "    )\n",
    "\n",
    "generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(generated_text)\n",
    "response = extract_response(generated_text)\n",
    "print(\"Extracted Response:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7357a1-1764-4a16-bc66-2a0865bc0dae",
   "metadata": {},
   "source": [
    "## Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "6df5044b-d2e2-42f5-ac8a-1152449e425e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfba787f0b0943a2bc8c8b9bd17ff24b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs:  0\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def extract_response(text, prefix = \"### Assistant:\"):\n",
    "    if prefix in text:\n",
    "        return text.split(prefix, 1)[1].strip()\n",
    "    return None\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.config.use_cache = True\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'source_text': dataset['test']['source_text'],\n",
    "    #'target_sentence': dataset['test']['target_sentence_4o'], \n",
    "    'elaboration_sentence': dataset['test']['elaboration_sentence'],\n",
    "    #'subject':dataset['test']['subject'],\n",
    "    #'target_sentence_target': dataset['test']['target_sentence_target'],\n",
    "    #'target_sentence': dataset['test']['target_sentence_4o'],\n",
    "    'pred_elaboration': \"\"\n",
    "})\n",
    "\n",
    "\n",
    "for idx, row in tqdm(df_results.iterrows(),total=len(df_results)):\n",
    "    if row[\"pred_elaboration\"]==\"\":\n",
    "        # chatML format\n",
    "        #input_text = formatting_func(formatted_test_dataset[idx])\n",
    "        inputs = tokenizer(\n",
    "            formatted_test_dataset[idx], #input_text,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=1024 # 512 \n",
    "        ).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                max_new_tokens=32,  # 32 for elaboration-only generation\n",
    "                min_length=10,\n",
    "                do_sample=False,  # Greedy decoding\n",
    "                temperature=None,  # not used in greedy decoding\n",
    "                top_p=None,# not used in greedy decoding\n",
    "                num_beams = 4,\n",
    "                early_stopping = True,\n",
    "                num_return_sequences=1,\n",
    "                no_repeat_ngram_size=3,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                stopping_criteria=stopping_criteria\n",
    "            )\n",
    "        \n",
    "        generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        response = extract_response(generated_text) #extract_assistant_response(generated_text) -> chatML\n",
    "        df_results.at[idx,\"pred_elaboration\"] = response\n",
    "\n",
    "print(\"NaNs: \", len(df_results[df_results[\"pred_elaboration\"]==\"\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba68c018-360a-41dc-9877-4e52a5aa7d5f",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "99a25ce7-851d-440a-ba32-fd10cc07c70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c4spo\n"
     ]
    }
   ],
   "source": [
    "df_results.to_csv(f\"../data/gen_predictions/predictions_llama3.2-instruct-few-shot-test_ds_{output_name}.csv\")\n",
    "print(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "3a343657-9d59-49ea-afa5-78aa27baf17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He was released from Cuban prison after a US deal.'"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.loc[103,\"pred_elaboration\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
